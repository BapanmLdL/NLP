{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c77d7291ae3aff7ea714d3b19d708d455de016c",
    "id": "lSY4R5Pa4Zs2"
   },
   "source": [
    "We cannot work with the text data in machine learning so we need to convert them into numerical vectors, As a part of this practice exercise you will implement different techniques to do the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b77a3ffeea9399d8ff4ed783b11d325c8a47ba7",
    "id": "MnEqJoGl4Zs4"
   },
   "source": [
    "In this notebook we are going to understand some basic text cleaning steps and techniques for encoding text data. We are going to learn about\n",
    "1. **Understanding the data** - See what's data is all about. what should be considered for cleaning for data (Punctuations , stopwords etc..).\n",
    "2. **Basic Cleaning** -We will see what parameters need to be considered for cleaning of data (like Punctuations , stopwords etc..)  and its code.\n",
    "3. **Techniques for Encoding** - All the popular techniques that are used for encoding that I personally came across.\n",
    "    *           **Bag of Words**\n",
    "    *           **Binary Bag of Words**\n",
    "    *           **Bigram, Ngram**\n",
    "    *           **TF-IDF**( **T**erm  **F**requency - **I**nverse **D**ocument **F**requency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3e9b8360f72e16b27f4ba5e353d412900fc4d5be",
    "id": "jplSqGVx4Zs5"
   },
   "source": [
    "# 1.Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjyMG_z46P9b"
   },
   "source": [
    "Libraries used in this notebook along with their version:\n",
    "\n",
    "google\t2.0.3\n",
    "\n",
    "nltk\t3.2.5\n",
    "\n",
    "numpy\t1.18.3\n",
    "\n",
    "pandas\t1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AFdnXXocGihA"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from six import string_types\n",
    "from nltk.corpus import reuters\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqD5wboL06eJ"
   },
   "source": [
    "# 2.Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtkF2UiMA7HA"
   },
   "source": [
    "We will employ a text categorization dataset based on Reviews. Each article is assigned a specific captegory. \n",
    "###Implement the code to load the dataset.(Hint: Use the pandas library to load the csv file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "J9YUPlX1GkMw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:2000,:]\n",
    "df.shape   # since program was not able to run and consuming lots of  memory ,so  reduced the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Score\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e77faa28f4d4807e716f4bff26f8ff49c3fb2bd",
    "id": "0A1RO0fw4ZtI"
   },
   "source": [
    "1. **Understanding the data**\n",
    "\n",
    "Our main objective from the dataset is to predict whether a review is **Positive** or **Negative** based on the Text.\n",
    " \n",
    "If we see the Score column, it has values 1,2,3,4,5 .  Considering 1, 2 as Negative reviews and 4, 5 as Positive reviews.\n",
    " For Score = 3 we will consider it as Neutral review and lets delete the rows that are neutral, so that we can predict either Positive or Negative\n",
    " \n",
    "HelpfulnessNumerator says about number of people found that review usefull and HelpfulnessDenominator is about usefull review count + not so usefull count.\n",
    "So, from this we can see that HelfulnessNumerator is always less than or equal to HelpfulnesDenominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =df[df.Score !=3]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data.HelpfulnessNumerator<= data.HelpfulnessDenominator]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klzR7v6uGoP-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26eda6bf2503287bf92a5b3139fa3d7a9dd8b101",
    "id": "Yn9k5hzP4ZtM"
   },
   "source": [
    "Converting Score values into class label either Positive or Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1XTy80ShGprW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] = data['Score'].apply(lambda x: 0 if (x==1 or x==2) else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11da101e437e715e7e900eae0daf683fa5129140",
    "id": "44rlIgeA4ZtR"
   },
   "source": [
    "2. **Basic Cleaning**\n",
    " \n",
    "**Deduplication** means removing duplicate rows, It is necessary to remove duplicates in order to get unbaised results. Checking duplicates based on UserId, ProfileName, Time, Text. If all these values are equal then we will remove those records. (No user can type a review on same exact time for different products.)\n",
    "\n",
    "\n",
    "We have seen that HelpfulnessNumerator should always be less than or equal to HelpfulnessDenominator so checking this condition and removing those records also.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mHCQeMoyGrSx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0QdvtLFA7HF"
   },
   "source": [
    "###Create a function called \"complaint_to_words\" to convert each consumer complaint narrative to individual tokens.(Hint: Use regular expression based tokenizer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwVN_hQ_09r0"
   },
   "source": [
    "# 3.Basic Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlUDtA7hA7HG"
   },
   "source": [
    "We will use the above function here to create a list of list that will store each complaint tokenized into separate words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPJesTws2BN6"
   },
   "source": [
    "## 3.1.Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ba6QhP9XGt9T"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1838,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = data['Text']\n",
    "report.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I have bought several of the Vitality canned d...\n",
       "1       Product arrived labeled as Jumbo Salted Peanut...\n",
       "2       This is a confection that has been around a fe...\n",
       "3       If you are looking for the secret ingredient i...\n",
       "4       Great taffy at a great price.  There was a wid...\n",
       "                              ...                        \n",
       "1995    I have to laugh at the reviews that said it wa...\n",
       "1996    I had read some favorable reviews of this panc...\n",
       "1997    I was expecting great things based on the revi...\n",
       "1998    I love this pancake mix.  I bought my first ca...\n",
       "1999    What can i say??  They are wonderful, and the ...\n",
       "Name: Text, Length: 1838, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = []\n",
    "for file_id in report:\n",
    "    words = word_tokenize(file_id)\n",
    "    word.extend(words)\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aleHavwG1Ihn"
   },
   "source": [
    "## 3.2.Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wPeZ0cqkGvUq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161075"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_tokens = [w.lower() for w in word]\n",
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFzCpnAr9Bw0"
   },
   "source": [
    "## 3.3.Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rishabh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V3POzrb2hfU"
   },
   "source": [
    "### 3.3.1.Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_7g7RP7WGwiu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161075\n",
      "150693\n"
     ]
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "  \n",
    "#stop_words = set(stopwords.words('english')) \n",
    "puncList = [\";\",\":\",\"!\",\"?\",\"/\",\"\\\\\",\",\",\"#\",\"@\",\"$\",\"&\",\")\",\"(\",\"\\\"\"]\n",
    "\n",
    "#word_tokens = word_tokenize(text_tokens) \n",
    "  \n",
    "filtered_sentence = [w for w in text_tokens if not w in puncList] \n",
    "  \n",
    "Punc_filtered_sentence = [] \n",
    "  \n",
    "for w in text_tokens: \n",
    "    if w not in puncList: \n",
    "        Punc_filtered_sentence.append(w) \n",
    "  \n",
    "print(len(text_tokens) )\n",
    "print(len(Punc_filtered_sentence) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdaaR23Z1Kop"
   },
   "source": [
    "### 3.3.2.Removing the Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3KX4ANEdGyry"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bapan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84583"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "    \n",
    "stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "filtered_sentence = [w for w in Punc_filtered_sentence if not w in stop_words] \n",
    "  \n",
    "len(filtered_sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnQytxul1N7Z"
   },
   "source": [
    "## 3.4.Stemming & Lemitization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOCGBspF1VNJ"
   },
   "source": [
    "### 3.4.1.Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ud5MmKwbG0wu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought',\n",
       " 'sever',\n",
       " 'vital',\n",
       " 'can',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'product',\n",
       " 'found',\n",
       " 'good',\n",
       " 'qualiti',\n",
       " '.',\n",
       " 'product',\n",
       " 'look',\n",
       " 'like',\n",
       " 'stew',\n",
       " 'process',\n",
       " 'meat',\n",
       " 'smell',\n",
       " 'better',\n",
       " '.',\n",
       " 'labrador',\n",
       " 'finicki',\n",
       " 'appreci',\n",
       " 'product',\n",
       " 'better',\n",
       " '.',\n",
       " 'product',\n",
       " 'arriv',\n",
       " 'label',\n",
       " 'jumbo',\n",
       " 'salt',\n",
       " 'peanut',\n",
       " '...',\n",
       " 'peanut',\n",
       " 'actual',\n",
       " 'small',\n",
       " 'size',\n",
       " 'unsalt',\n",
       " '.',\n",
       " 'sure',\n",
       " 'error',\n",
       " 'vendor',\n",
       " 'intend',\n",
       " 'repres',\n",
       " 'product',\n",
       " '``',\n",
       " 'jumbo',\n",
       " \"''\",\n",
       " '.',\n",
       " 'confect',\n",
       " 'around',\n",
       " 'centuri',\n",
       " '.',\n",
       " 'light',\n",
       " 'pillowi',\n",
       " 'citru',\n",
       " 'gelatin',\n",
       " 'nut',\n",
       " '-',\n",
       " 'case',\n",
       " 'filbert',\n",
       " '.',\n",
       " 'cut',\n",
       " 'tini',\n",
       " 'squar',\n",
       " 'liber',\n",
       " 'coat',\n",
       " 'powder',\n",
       " 'sugar',\n",
       " '.',\n",
       " 'tini',\n",
       " 'mouth',\n",
       " 'heaven',\n",
       " '.',\n",
       " 'chewi',\n",
       " 'flavor',\n",
       " '.',\n",
       " 'highli',\n",
       " 'recommend',\n",
       " 'yummi',\n",
       " 'treat',\n",
       " '.',\n",
       " 'familiar',\n",
       " 'stori',\n",
       " 'c.',\n",
       " '.',\n",
       " 'lewi',\n",
       " \"'\",\n",
       " '``',\n",
       " 'lion',\n",
       " 'witch',\n",
       " 'wardrob',\n",
       " \"''\",\n",
       " '-',\n",
       " 'treat',\n",
       " 'seduc',\n",
       " 'edmund',\n",
       " 'sell',\n",
       " 'brother',\n",
       " 'sister',\n",
       " 'witch',\n",
       " '.',\n",
       " 'look',\n",
       " 'secret',\n",
       " 'ingredi',\n",
       " 'robitussin',\n",
       " 'believ',\n",
       " 'found',\n",
       " '.',\n",
       " 'got',\n",
       " 'addit',\n",
       " 'root',\n",
       " 'beer',\n",
       " 'extract',\n",
       " 'order',\n",
       " 'good',\n",
       " 'made',\n",
       " 'cherri',\n",
       " 'soda',\n",
       " '.',\n",
       " 'flavor',\n",
       " 'medicin',\n",
       " '.',\n",
       " 'great',\n",
       " 'taffi',\n",
       " 'great',\n",
       " 'price',\n",
       " '.',\n",
       " 'wide',\n",
       " 'assort',\n",
       " 'yummi',\n",
       " 'taffi',\n",
       " '.',\n",
       " 'deliveri',\n",
       " 'quick',\n",
       " '.',\n",
       " 'taffi',\n",
       " 'lover',\n",
       " 'deal',\n",
       " '.',\n",
       " 'got',\n",
       " 'wild',\n",
       " 'hair',\n",
       " 'taffi',\n",
       " 'order',\n",
       " 'five',\n",
       " 'pound',\n",
       " 'bag',\n",
       " '.',\n",
       " 'taffi',\n",
       " 'enjoy',\n",
       " 'mani',\n",
       " 'flavor',\n",
       " 'watermelon',\n",
       " 'root',\n",
       " 'beer',\n",
       " 'melon',\n",
       " 'peppermint',\n",
       " 'grape',\n",
       " 'etc',\n",
       " '.',\n",
       " 'complaint',\n",
       " 'bit',\n",
       " 'much',\n",
       " 'red/black',\n",
       " 'licorice-flavor',\n",
       " 'piec',\n",
       " 'particular',\n",
       " 'favorit',\n",
       " '.',\n",
       " 'kid',\n",
       " 'husband',\n",
       " 'last',\n",
       " 'two',\n",
       " 'week',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'brand',\n",
       " 'taffi',\n",
       " '--',\n",
       " 'delight',\n",
       " 'treat',\n",
       " '.',\n",
       " 'saltwat',\n",
       " 'taffi',\n",
       " 'great',\n",
       " 'flavor',\n",
       " 'soft',\n",
       " 'chewi',\n",
       " '.',\n",
       " 'candi',\n",
       " 'individu',\n",
       " 'wrap',\n",
       " 'well',\n",
       " '.',\n",
       " 'none',\n",
       " 'candi',\n",
       " 'stuck',\n",
       " 'togeth',\n",
       " 'happen',\n",
       " 'expens',\n",
       " 'version',\n",
       " 'fraling',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'would',\n",
       " 'highli',\n",
       " 'recommend',\n",
       " 'candi',\n",
       " 'serv',\n",
       " 'beach-them',\n",
       " 'parti',\n",
       " 'everyon',\n",
       " 'love',\n",
       " 'taffi',\n",
       " 'good',\n",
       " '.',\n",
       " 'soft',\n",
       " 'chewi',\n",
       " '.',\n",
       " 'flavor',\n",
       " 'amaz',\n",
       " '.',\n",
       " 'would',\n",
       " 'definit',\n",
       " 'recommend',\n",
       " 'buy',\n",
       " '.',\n",
       " 'satisfi',\n",
       " 'right',\n",
       " \"'m\",\n",
       " 'mostli',\n",
       " 'sprout',\n",
       " 'cat',\n",
       " 'eat',\n",
       " 'grass',\n",
       " '.',\n",
       " 'love',\n",
       " '.',\n",
       " 'rotat',\n",
       " 'around',\n",
       " 'wheatgrass',\n",
       " 'rye',\n",
       " 'healthi',\n",
       " 'dog',\n",
       " 'food',\n",
       " '.',\n",
       " 'good',\n",
       " 'digest',\n",
       " '.',\n",
       " 'also',\n",
       " 'good',\n",
       " 'small',\n",
       " 'puppi',\n",
       " '.',\n",
       " 'dog',\n",
       " 'eat',\n",
       " 'requir',\n",
       " 'amount',\n",
       " 'everi',\n",
       " 'feed',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"'s\",\n",
       " 'cactu',\n",
       " 'tequila',\n",
       " 'uniqu',\n",
       " 'combin',\n",
       " 'ingredi',\n",
       " 'flavour',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " 'make',\n",
       " 'one',\n",
       " 'kind',\n",
       " 'pick',\n",
       " 'bottl',\n",
       " 'trip',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'home',\n",
       " 'us',\n",
       " 'total',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'realiz',\n",
       " 'simpli',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'find',\n",
       " 'anywher',\n",
       " 'citi',\n",
       " 'bummed.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'magic',\n",
       " 'internet',\n",
       " 'case',\n",
       " 'sauc',\n",
       " 'ecstat',\n",
       " 'it.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'love',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " '..',\n",
       " 'mean',\n",
       " 'realli',\n",
       " 'love',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'sauc',\n",
       " 'tastelessli',\n",
       " 'burn',\n",
       " 'throat',\n",
       " 'grab',\n",
       " 'bottl',\n",
       " 'tequila',\n",
       " 'picant',\n",
       " 'gourmet',\n",
       " 'de',\n",
       " 'inclan',\n",
       " '.',\n",
       " 'realiz',\n",
       " 'tast',\n",
       " 'never',\n",
       " 'want',\n",
       " 'use',\n",
       " 'sauce.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'incred',\n",
       " 'servic',\n",
       " 'one',\n",
       " 'boy',\n",
       " 'need',\n",
       " 'lose',\n",
       " 'weight',\n",
       " \"n't\",\n",
       " '.',\n",
       " 'put',\n",
       " 'food',\n",
       " 'floor',\n",
       " 'chubbi',\n",
       " 'guy',\n",
       " 'protein-rich',\n",
       " 'by-product',\n",
       " 'food',\n",
       " 'higher',\n",
       " 'skinni',\n",
       " 'boy',\n",
       " 'jump',\n",
       " '.',\n",
       " 'higher',\n",
       " 'food',\n",
       " 'sit',\n",
       " 'go',\n",
       " 'stale',\n",
       " '.',\n",
       " 'realli',\n",
       " 'go',\n",
       " 'food',\n",
       " '.',\n",
       " 'chubbi',\n",
       " 'boy',\n",
       " 'lose',\n",
       " 'ounc',\n",
       " 'week',\n",
       " '.',\n",
       " 'cat',\n",
       " 'happili',\n",
       " 'eat',\n",
       " 'felida',\n",
       " 'platinum',\n",
       " 'two',\n",
       " 'year',\n",
       " '.',\n",
       " 'got',\n",
       " 'new',\n",
       " 'bag',\n",
       " 'shape',\n",
       " 'food',\n",
       " 'differ',\n",
       " '.',\n",
       " 'tri',\n",
       " 'new',\n",
       " 'food',\n",
       " 'first',\n",
       " 'put',\n",
       " 'bowl',\n",
       " 'bowl',\n",
       " 'sit',\n",
       " 'full',\n",
       " 'kitti',\n",
       " 'touch',\n",
       " 'food',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'notic',\n",
       " 'similar',\n",
       " 'review',\n",
       " 'relat',\n",
       " 'formula',\n",
       " 'chang',\n",
       " 'past',\n",
       " '.',\n",
       " 'unfortun',\n",
       " 'need',\n",
       " 'find',\n",
       " 'new',\n",
       " 'food',\n",
       " 'cat',\n",
       " 'eat',\n",
       " '.',\n",
       " 'good',\n",
       " 'flavor',\n",
       " 'came',\n",
       " 'secur',\n",
       " 'pack',\n",
       " '...',\n",
       " 'fresh',\n",
       " 'delici',\n",
       " 'love',\n",
       " 'twizzler',\n",
       " 'strawberri',\n",
       " 'twizzler',\n",
       " 'guilti',\n",
       " 'pleasur',\n",
       " '-',\n",
       " 'yummi',\n",
       " '.',\n",
       " 'six',\n",
       " 'pound',\n",
       " 'around',\n",
       " 'son',\n",
       " '.',\n",
       " 'daughter',\n",
       " 'love',\n",
       " 'twizzler',\n",
       " 'shipment',\n",
       " 'six',\n",
       " 'pound',\n",
       " 'realli',\n",
       " 'hit',\n",
       " 'spot',\n",
       " '.',\n",
       " \"'s\",\n",
       " 'exactli',\n",
       " 'would',\n",
       " 'expect',\n",
       " '...',\n",
       " 'six',\n",
       " 'packag',\n",
       " 'strawberri',\n",
       " 'twizzler',\n",
       " '.',\n",
       " 'love',\n",
       " 'eat',\n",
       " 'good',\n",
       " 'watch',\n",
       " 'tv',\n",
       " 'look',\n",
       " 'movi',\n",
       " 'sweet',\n",
       " '.',\n",
       " 'like',\n",
       " 'transfer',\n",
       " 'zip',\n",
       " 'lock',\n",
       " 'baggi',\n",
       " 'stay',\n",
       " 'fresh',\n",
       " 'take',\n",
       " 'time',\n",
       " 'eat',\n",
       " '.',\n",
       " 'satisfi',\n",
       " 'twizzler',\n",
       " 'purchas',\n",
       " '.',\n",
       " 'share',\n",
       " 'other',\n",
       " 'enjoy',\n",
       " '.',\n",
       " 'definit',\n",
       " 'order',\n",
       " '.',\n",
       " 'twizzler',\n",
       " 'strawberri',\n",
       " 'childhood',\n",
       " 'favorit',\n",
       " 'candi',\n",
       " 'made',\n",
       " 'lancast',\n",
       " 'pennsylvania',\n",
       " 'candi',\n",
       " 'inc.',\n",
       " 'one',\n",
       " 'oldest',\n",
       " 'confectioneri',\n",
       " 'firm',\n",
       " 'unit',\n",
       " 'state',\n",
       " 'subsidiari',\n",
       " 'hershey',\n",
       " 'compani',\n",
       " 'compani',\n",
       " 'establish',\n",
       " '1845',\n",
       " 'young',\n",
       " 'smyli',\n",
       " 'also',\n",
       " 'make',\n",
       " 'appl',\n",
       " 'licoric',\n",
       " 'twist',\n",
       " 'green',\n",
       " 'color',\n",
       " 'blue',\n",
       " 'raspberri',\n",
       " 'licoric',\n",
       " 'twist',\n",
       " 'like',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'keep',\n",
       " 'dri',\n",
       " 'cool',\n",
       " 'place',\n",
       " 'recommend',\n",
       " 'put',\n",
       " 'fridg',\n",
       " '.',\n",
       " 'accord',\n",
       " 'guin',\n",
       " 'book',\n",
       " 'record',\n",
       " 'longest',\n",
       " 'licoric',\n",
       " 'twist',\n",
       " 'ever',\n",
       " 'made',\n",
       " 'measur',\n",
       " '1.200',\n",
       " 'feet',\n",
       " '370',\n",
       " 'weight',\n",
       " '100',\n",
       " 'pound',\n",
       " '45',\n",
       " 'kg',\n",
       " 'made',\n",
       " 'candi',\n",
       " 'inc',\n",
       " '.',\n",
       " 'record-break',\n",
       " 'twist',\n",
       " 'becam',\n",
       " 'guin',\n",
       " 'world',\n",
       " 'record',\n",
       " 'juli',\n",
       " '19',\n",
       " '1998',\n",
       " '.',\n",
       " 'product',\n",
       " 'kosher',\n",
       " 'thank',\n",
       " 'candi',\n",
       " 'deliv',\n",
       " 'fast',\n",
       " 'purchas',\n",
       " 'reason',\n",
       " 'price',\n",
       " '.',\n",
       " 'home',\n",
       " 'bound',\n",
       " 'unabl',\n",
       " 'get',\n",
       " 'store',\n",
       " 'perfect',\n",
       " '.',\n",
       " 'husband',\n",
       " 'twizzler',\n",
       " 'addict',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'bought',\n",
       " 'mani',\n",
       " 'time',\n",
       " 'amazon',\n",
       " \"'re\",\n",
       " 'govern',\n",
       " 'employe',\n",
       " 'live',\n",
       " 'oversea',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'get',\n",
       " 'countri',\n",
       " 'assign',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'alway',\n",
       " 'fresh',\n",
       " 'tasti',\n",
       " 'pack',\n",
       " 'well',\n",
       " 'arriv',\n",
       " 'time',\n",
       " 'manner',\n",
       " '.',\n",
       " 'bought',\n",
       " 'husband',\n",
       " 'current',\n",
       " 'oversea',\n",
       " '.',\n",
       " 'love',\n",
       " 'appar',\n",
       " 'staff',\n",
       " 'like',\n",
       " 'also.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'gener',\n",
       " 'amount',\n",
       " 'twizzler',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'well',\n",
       " 'worth',\n",
       " 'price',\n",
       " '.',\n",
       " '<',\n",
       " 'href=',\n",
       " \"''\",\n",
       " 'http',\n",
       " '//www.amazon.com/gp/product/b001gvisjm',\n",
       " \"''\",\n",
       " '>',\n",
       " 'twizzler',\n",
       " 'strawberri',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'pack',\n",
       " '6',\n",
       " '<',\n",
       " '/a',\n",
       " '>',\n",
       " 'rememb',\n",
       " 'buy',\n",
       " 'candi',\n",
       " 'kid',\n",
       " 'qualiti',\n",
       " \"n't\",\n",
       " 'drop',\n",
       " 'year',\n",
       " '.',\n",
       " 'still',\n",
       " 'superb',\n",
       " 'product',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappoint',\n",
       " '.',\n",
       " 'love',\n",
       " 'candi',\n",
       " '.',\n",
       " 'weight',\n",
       " 'watcher',\n",
       " 'cut',\n",
       " 'back',\n",
       " 'still',\n",
       " 'crave',\n",
       " '.',\n",
       " 'live',\n",
       " 'us',\n",
       " '7',\n",
       " 'yr',\n",
       " 'miss',\n",
       " 'twizzler',\n",
       " 'go',\n",
       " 'back',\n",
       " 'visit',\n",
       " 'someon',\n",
       " 'visit',\n",
       " 'alway',\n",
       " 'stock',\n",
       " '.',\n",
       " 'say',\n",
       " 'yum',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'sell',\n",
       " 'mexico',\n",
       " 'faith',\n",
       " 'buyer',\n",
       " 'often',\n",
       " \"'m\",\n",
       " 'abl',\n",
       " 'buy',\n",
       " 'right',\n",
       " '.',\n",
       " 'product',\n",
       " 'receiv',\n",
       " 'advertised.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'href=',\n",
       " \"''\",\n",
       " 'http',\n",
       " '//www.amazon.com/gp/product/b001gvisjm',\n",
       " \"''\",\n",
       " '>',\n",
       " 'twizzler',\n",
       " 'strawberri',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'pack',\n",
       " '6',\n",
       " '<',\n",
       " '/a',\n",
       " '>',\n",
       " 'candi',\n",
       " 'red',\n",
       " 'flavor',\n",
       " '.',\n",
       " 'plan',\n",
       " 'chewi',\n",
       " '.',\n",
       " 'would',\n",
       " 'never',\n",
       " 'buy',\n",
       " 'glad',\n",
       " 'amazon',\n",
       " 'carri',\n",
       " 'batteri',\n",
       " '.',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'find',\n",
       " 'elsewher',\n",
       " 'uniqu',\n",
       " 'size',\n",
       " '.',\n",
       " 'need',\n",
       " 'garag',\n",
       " 'door',\n",
       " 'opener.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'great',\n",
       " 'deal',\n",
       " 'price',\n",
       " '.',\n",
       " 'got',\n",
       " 'mum',\n",
       " 'diabet',\n",
       " 'need',\n",
       " 'watch',\n",
       " 'sugar',\n",
       " 'intak',\n",
       " 'father',\n",
       " 'simpli',\n",
       " 'choos',\n",
       " 'limit',\n",
       " 'unnecessari',\n",
       " 'sugar',\n",
       " 'intak',\n",
       " '-',\n",
       " \"'s\",\n",
       " 'one',\n",
       " 'sweet',\n",
       " 'tooth',\n",
       " '-',\n",
       " 'love',\n",
       " 'toffe',\n",
       " 'would',\n",
       " 'never',\n",
       " 'guess',\n",
       " \"'re\",\n",
       " 'sugar-fre',\n",
       " \"'s\",\n",
       " 'great',\n",
       " 'eat',\n",
       " 'pretti',\n",
       " 'much',\n",
       " 'guilt',\n",
       " 'free',\n",
       " 'impress',\n",
       " \"'ve\",\n",
       " 'order',\n",
       " 'w',\n",
       " 'dark',\n",
       " 'chocol',\n",
       " 'take',\n",
       " 'offic',\n",
       " \"'ll\",\n",
       " 'eat',\n",
       " 'instead',\n",
       " 'snack',\n",
       " 'sugari',\n",
       " 'sweets.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'excel',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"'s\",\n",
       " 'cactu',\n",
       " 'tequila',\n",
       " 'uniqu',\n",
       " 'combin',\n",
       " 'ingredi',\n",
       " 'flavour',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " 'make',\n",
       " 'one',\n",
       " 'kind',\n",
       " 'pick',\n",
       " 'bottl',\n",
       " 'trip',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'home',\n",
       " 'us',\n",
       " 'total',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'realiz',\n",
       " 'simpli',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'find',\n",
       " 'anywher',\n",
       " 'citi',\n",
       " 'bummed.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'magic',\n",
       " 'internet',\n",
       " 'case',\n",
       " 'sauc',\n",
       " 'ecstat',\n",
       " 'it.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'love',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " '..',\n",
       " 'mean',\n",
       " 'realli',\n",
       " 'love',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'sauc',\n",
       " 'tastelessli',\n",
       " 'burn',\n",
       " 'throat',\n",
       " 'grab',\n",
       " 'bottl',\n",
       " 'tequila',\n",
       " 'picant',\n",
       " 'gourmet',\n",
       " 'de',\n",
       " 'inclan',\n",
       " '.',\n",
       " 'realiz',\n",
       " 'tast',\n",
       " 'never',\n",
       " 'want',\n",
       " 'use',\n",
       " 'sauce.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'incred',\n",
       " 'servic',\n",
       " 'never',\n",
       " 'huge',\n",
       " 'coffe',\n",
       " 'fan',\n",
       " '.',\n",
       " 'howev',\n",
       " 'mother',\n",
       " 'purchas',\n",
       " 'littl',\n",
       " 'machin',\n",
       " 'talk',\n",
       " 'tri',\n",
       " 'latt',\n",
       " 'macciato',\n",
       " '.',\n",
       " 'coffe',\n",
       " 'shop',\n",
       " 'better',\n",
       " 'one',\n",
       " 'like',\n",
       " 'product',\n",
       " 'usual',\n",
       " 'non-coffe',\n",
       " 'drinker',\n",
       " '.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'littl',\n",
       " 'dolch',\n",
       " 'guesto',\n",
       " 'machin',\n",
       " 'super',\n",
       " 'easi',\n",
       " 'use',\n",
       " 'prepar',\n",
       " 'realli',\n",
       " 'good',\n",
       " 'coffee/latte/cappuccino/etc',\n",
       " 'less',\n",
       " 'minut',\n",
       " 'water',\n",
       " 'heat',\n",
       " '.',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'dolc',\n",
       " 'gusto',\n",
       " 'anyon',\n",
       " '.',\n",
       " 'good',\n",
       " 'price',\n",
       " \"i'am\",\n",
       " 'get',\n",
       " 'one',\n",
       " 'offer',\n",
       " 'great',\n",
       " 'price',\n",
       " 'great',\n",
       " 'tast',\n",
       " 'thank',\n",
       " 'amazon',\n",
       " 'sell',\n",
       " 'product.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'staral',\n",
       " 'mccann',\n",
       " \"'s\",\n",
       " 'instant',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "filtered_sentence = list(map(lambda x : porter.stem(x),filtered_sentence))\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBHm5uBT1XAQ"
   },
   "source": [
    "### 3.4.2.Lemitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TXtHWUN5G2a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought',\n",
       " 'sev',\n",
       " 'vit',\n",
       " 'can',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'produc',\n",
       " 'found',\n",
       " 'good',\n",
       " 'qualit',\n",
       " '.',\n",
       " 'produc',\n",
       " 'look',\n",
       " 'lik',\n",
       " 'stew',\n",
       " 'process',\n",
       " 'meat',\n",
       " 'smel',\n",
       " 'bet',\n",
       " '.',\n",
       " 'labrad',\n",
       " 'finick',\n",
       " 'apprec',\n",
       " 'produc',\n",
       " 'bet',\n",
       " '.',\n",
       " 'produc',\n",
       " 'ar',\n",
       " 'label',\n",
       " 'jumbo',\n",
       " 'salt',\n",
       " 'peanut',\n",
       " '...',\n",
       " 'peanut',\n",
       " 'act',\n",
       " 'smal',\n",
       " 'siz',\n",
       " 'unsalt',\n",
       " '.',\n",
       " 'sur',\n",
       " 'er',\n",
       " 'vend',\n",
       " 'intend',\n",
       " 'repr',\n",
       " 'produc',\n",
       " '``',\n",
       " 'jumbo',\n",
       " \"''\",\n",
       " '.',\n",
       " 'confect',\n",
       " 'around',\n",
       " 'centur',\n",
       " '.',\n",
       " 'light',\n",
       " 'pillow',\n",
       " 'citru',\n",
       " 'gelatin',\n",
       " 'nut',\n",
       " '-',\n",
       " 'cas',\n",
       " 'filbert',\n",
       " '.',\n",
       " 'cut',\n",
       " 'tin',\n",
       " 'squ',\n",
       " 'lib',\n",
       " 'coat',\n",
       " 'powd',\n",
       " 'sug',\n",
       " '.',\n",
       " 'tin',\n",
       " 'mou',\n",
       " 'heav',\n",
       " '.',\n",
       " 'chew',\n",
       " 'flav',\n",
       " '.',\n",
       " 'highl',\n",
       " 'recommend',\n",
       " 'yumm',\n",
       " 'tre',\n",
       " '.',\n",
       " 'famili',\n",
       " 'stor',\n",
       " 'c.',\n",
       " '.',\n",
       " 'lew',\n",
       " \"'\",\n",
       " '``',\n",
       " 'lion',\n",
       " 'witch',\n",
       " 'wardrob',\n",
       " \"''\",\n",
       " '-',\n",
       " 'tre',\n",
       " 'seduc',\n",
       " 'edmund',\n",
       " 'sel',\n",
       " 'broth',\n",
       " 'sist',\n",
       " 'witch',\n",
       " '.',\n",
       " 'look',\n",
       " 'secret',\n",
       " 'ingred',\n",
       " 'robitussin',\n",
       " 'believ',\n",
       " 'found',\n",
       " '.',\n",
       " 'got',\n",
       " 'addit',\n",
       " 'root',\n",
       " 'beer',\n",
       " 'extract',\n",
       " 'ord',\n",
       " 'good',\n",
       " 'mad',\n",
       " 'cherr',\n",
       " 'sod',\n",
       " '.',\n",
       " 'flav',\n",
       " 'medicin',\n",
       " '.',\n",
       " 'gre',\n",
       " 'taff',\n",
       " 'gre',\n",
       " 'pric',\n",
       " '.',\n",
       " 'wid',\n",
       " 'assort',\n",
       " 'yumm',\n",
       " 'taff',\n",
       " '.',\n",
       " 'deliver',\n",
       " 'quick',\n",
       " '.',\n",
       " 'taff',\n",
       " 'lov',\n",
       " 'deal',\n",
       " '.',\n",
       " 'got',\n",
       " 'wild',\n",
       " 'hair',\n",
       " 'taff',\n",
       " 'ord',\n",
       " 'fiv',\n",
       " 'pound',\n",
       " 'bag',\n",
       " '.',\n",
       " 'taff',\n",
       " 'enjoy',\n",
       " 'man',\n",
       " 'flav',\n",
       " 'watermelon',\n",
       " 'root',\n",
       " 'beer',\n",
       " 'melon',\n",
       " 'peppermint',\n",
       " 'grap',\n",
       " 'etc',\n",
       " '.',\n",
       " 'complaint',\n",
       " 'bit',\n",
       " 'much',\n",
       " 'red/black',\n",
       " 'licorice-flavor',\n",
       " 'piec',\n",
       " 'particul',\n",
       " 'favorit',\n",
       " '.',\n",
       " 'kid',\n",
       " 'husband',\n",
       " 'last',\n",
       " 'two',\n",
       " 'week',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'brand',\n",
       " 'taff',\n",
       " '--',\n",
       " 'delight',\n",
       " 'tre',\n",
       " '.',\n",
       " 'saltw',\n",
       " 'taff',\n",
       " 'gre',\n",
       " 'flav',\n",
       " 'soft',\n",
       " 'chew',\n",
       " '.',\n",
       " 'cand',\n",
       " 'individu',\n",
       " 'wrap',\n",
       " 'wel',\n",
       " '.',\n",
       " 'non',\n",
       " 'cand',\n",
       " 'stuck',\n",
       " 'toge',\n",
       " 'hap',\n",
       " 'exp',\n",
       " 'vert',\n",
       " 'fral',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'would',\n",
       " 'highl',\n",
       " 'recommend',\n",
       " 'cand',\n",
       " 'serv',\n",
       " 'beach-them',\n",
       " 'part',\n",
       " 'everyon',\n",
       " 'lov',\n",
       " 'taff',\n",
       " 'good',\n",
       " '.',\n",
       " 'soft',\n",
       " 'chew',\n",
       " '.',\n",
       " 'flav',\n",
       " 'amaz',\n",
       " '.',\n",
       " 'would',\n",
       " 'definit',\n",
       " 'recommend',\n",
       " 'buy',\n",
       " '.',\n",
       " 'satisf',\n",
       " 'right',\n",
       " \"'m\",\n",
       " 'mostl',\n",
       " 'sprout',\n",
       " 'cat',\n",
       " 'eat',\n",
       " 'grass',\n",
       " '.',\n",
       " 'lov',\n",
       " '.',\n",
       " 'rot',\n",
       " 'around',\n",
       " 'wheatgrass',\n",
       " 'rye',\n",
       " 'health',\n",
       " 'dog',\n",
       " 'food',\n",
       " '.',\n",
       " 'good',\n",
       " 'digest',\n",
       " '.',\n",
       " 'also',\n",
       " 'good',\n",
       " 'smal',\n",
       " 'pupp',\n",
       " '.',\n",
       " 'dog',\n",
       " 'eat',\n",
       " 'requir',\n",
       " 'amount',\n",
       " 'ever',\n",
       " 'fee',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"'s\",\n",
       " 'cactu',\n",
       " 'tequil',\n",
       " 'un',\n",
       " 'combin',\n",
       " 'ingred',\n",
       " 'flavo',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " 'mak',\n",
       " 'on',\n",
       " 'kind',\n",
       " 'pick',\n",
       " 'bottl',\n",
       " 'trip',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'hom',\n",
       " 'us',\n",
       " 'tot',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'real',\n",
       " 'simpl',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'find',\n",
       " 'anywh',\n",
       " 'cit',\n",
       " 'bummed.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'mag',\n",
       " 'internet',\n",
       " 'cas',\n",
       " 'sauc',\n",
       " 'ecst',\n",
       " 'it.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " '..',\n",
       " 'mean',\n",
       " 'reall',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'sauc',\n",
       " 'tastelessl',\n",
       " 'burn',\n",
       " 'throat',\n",
       " 'grab',\n",
       " 'bottl',\n",
       " 'tequil',\n",
       " 'pic',\n",
       " 'gourmet',\n",
       " 'de',\n",
       " 'inc',\n",
       " '.',\n",
       " 'real',\n",
       " 'tast',\n",
       " 'nev',\n",
       " 'want',\n",
       " 'us',\n",
       " 'sauce.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'incr',\n",
       " 'serv',\n",
       " 'on',\n",
       " 'boy',\n",
       " 'nee',\n",
       " 'los',\n",
       " 'weight',\n",
       " \"n't\",\n",
       " '.',\n",
       " 'put',\n",
       " 'food',\n",
       " 'flo',\n",
       " 'chubb',\n",
       " 'guy',\n",
       " 'protein-rich',\n",
       " 'by-product',\n",
       " 'food',\n",
       " 'high',\n",
       " 'skinn',\n",
       " 'boy',\n",
       " 'jump',\n",
       " '.',\n",
       " 'high',\n",
       " 'food',\n",
       " 'sit',\n",
       " 'go',\n",
       " 'stal',\n",
       " '.',\n",
       " 'reall',\n",
       " 'go',\n",
       " 'food',\n",
       " '.',\n",
       " 'chubb',\n",
       " 'boy',\n",
       " 'los',\n",
       " 'ount',\n",
       " 'week',\n",
       " '.',\n",
       " 'cat',\n",
       " 'happil',\n",
       " 'eat',\n",
       " 'felid',\n",
       " 'platin',\n",
       " 'two',\n",
       " 'year',\n",
       " '.',\n",
       " 'got',\n",
       " 'new',\n",
       " 'bag',\n",
       " 'shap',\n",
       " 'food',\n",
       " 'diff',\n",
       " '.',\n",
       " 'tri',\n",
       " 'new',\n",
       " 'food',\n",
       " 'first',\n",
       " 'put',\n",
       " 'bowl',\n",
       " 'bowl',\n",
       " 'sit',\n",
       " 'ful',\n",
       " 'kitt',\n",
       " 'touch',\n",
       " 'food',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'not',\n",
       " 'simil',\n",
       " 'review',\n",
       " 'rel',\n",
       " 'formul',\n",
       " 'chang',\n",
       " 'past',\n",
       " '.',\n",
       " 'unfortun',\n",
       " 'nee',\n",
       " 'find',\n",
       " 'new',\n",
       " 'food',\n",
       " 'cat',\n",
       " 'eat',\n",
       " '.',\n",
       " 'good',\n",
       " 'flav',\n",
       " 'cam',\n",
       " 'sec',\n",
       " 'pack',\n",
       " '...',\n",
       " 'fresh',\n",
       " 'delic',\n",
       " 'lov',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " 'twizzl',\n",
       " 'guilt',\n",
       " 'pleas',\n",
       " '-',\n",
       " 'yumm',\n",
       " '.',\n",
       " 'six',\n",
       " 'pound',\n",
       " 'around',\n",
       " 'son',\n",
       " '.',\n",
       " 'daught',\n",
       " 'lov',\n",
       " 'twizzl',\n",
       " 'ship',\n",
       " 'six',\n",
       " 'pound',\n",
       " 'reall',\n",
       " 'hit',\n",
       " 'spot',\n",
       " '.',\n",
       " \"'s\",\n",
       " 'exactl',\n",
       " 'would',\n",
       " 'expect',\n",
       " '...',\n",
       " 'six',\n",
       " 'pack',\n",
       " 'strawberri',\n",
       " 'twizzl',\n",
       " '.',\n",
       " 'lov',\n",
       " 'eat',\n",
       " 'good',\n",
       " 'watch',\n",
       " 'tv',\n",
       " 'look',\n",
       " 'mov',\n",
       " 'sweet',\n",
       " '.',\n",
       " 'lik',\n",
       " 'transf',\n",
       " 'zip',\n",
       " 'lock',\n",
       " 'bagg',\n",
       " 'stay',\n",
       " 'fresh',\n",
       " 'tak',\n",
       " 'tim',\n",
       " 'eat',\n",
       " '.',\n",
       " 'satisf',\n",
       " 'twizzl',\n",
       " 'purcha',\n",
       " '.',\n",
       " 'shar',\n",
       " 'oth',\n",
       " 'enjoy',\n",
       " '.',\n",
       " 'definit',\n",
       " 'ord',\n",
       " '.',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " 'child',\n",
       " 'favorit',\n",
       " 'cand',\n",
       " 'mad',\n",
       " 'lancast',\n",
       " 'pennsylvan',\n",
       " 'cand',\n",
       " 'inc.',\n",
       " 'on',\n",
       " 'oldest',\n",
       " 'confectioner',\n",
       " 'firm',\n",
       " 'unit',\n",
       " 'stat',\n",
       " 'subsidiar',\n",
       " 'hershey',\n",
       " 'compan',\n",
       " 'compan',\n",
       " 'est',\n",
       " '1845',\n",
       " 'young',\n",
       " 'smyl',\n",
       " 'also',\n",
       " 'mak',\n",
       " 'appl',\n",
       " 'lic',\n",
       " 'twist',\n",
       " 'green',\n",
       " 'col',\n",
       " 'blu',\n",
       " 'raspberr',\n",
       " 'lic',\n",
       " 'twist',\n",
       " 'lik',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'keep',\n",
       " 'dri',\n",
       " 'cool',\n",
       " 'plac',\n",
       " 'recommend',\n",
       " 'put',\n",
       " 'fridg',\n",
       " '.',\n",
       " 'accord',\n",
       " 'guin',\n",
       " 'book',\n",
       " 'record',\n",
       " 'longest',\n",
       " 'lic',\n",
       " 'twist',\n",
       " 'ev',\n",
       " 'mad',\n",
       " 'meas',\n",
       " '1.200',\n",
       " 'feet',\n",
       " '370',\n",
       " 'weight',\n",
       " '100',\n",
       " 'pound',\n",
       " '45',\n",
       " 'kg',\n",
       " 'mad',\n",
       " 'cand',\n",
       " 'int',\n",
       " '.',\n",
       " 'record-break',\n",
       " 'twist',\n",
       " 'becam',\n",
       " 'guin',\n",
       " 'world',\n",
       " 'record',\n",
       " 'jul',\n",
       " '19',\n",
       " '1998',\n",
       " '.',\n",
       " 'produc',\n",
       " 'kosh',\n",
       " 'thank',\n",
       " 'cand',\n",
       " 'del',\n",
       " 'fast',\n",
       " 'purcha',\n",
       " 'reason',\n",
       " 'pric',\n",
       " '.',\n",
       " 'hom',\n",
       " 'bound',\n",
       " 'un',\n",
       " 'get',\n",
       " 'stor',\n",
       " 'perfect',\n",
       " '.',\n",
       " 'husband',\n",
       " 'twizzl',\n",
       " 'addict',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'bought',\n",
       " 'man',\n",
       " 'tim',\n",
       " 'amazon',\n",
       " \"'re\",\n",
       " 'govern',\n",
       " 'employ',\n",
       " 'liv',\n",
       " 'overse',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'get',\n",
       " 'countr',\n",
       " 'assign',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'alway',\n",
       " 'fresh',\n",
       " 'tast',\n",
       " 'pack',\n",
       " 'wel',\n",
       " 'ar',\n",
       " 'tim',\n",
       " 'man',\n",
       " '.',\n",
       " 'bought',\n",
       " 'husband',\n",
       " 'cur',\n",
       " 'overse',\n",
       " '.',\n",
       " 'lov',\n",
       " 'app',\n",
       " 'staff',\n",
       " 'lik',\n",
       " 'also.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'gen',\n",
       " 'amount',\n",
       " 'twizzl',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'wel',\n",
       " 'wor',\n",
       " 'pric',\n",
       " '.',\n",
       " '<',\n",
       " 'href=',\n",
       " \"''\",\n",
       " 'http',\n",
       " '//www.amazon.com/gp/product/b001gvisjm',\n",
       " \"''\",\n",
       " '>',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'pack',\n",
       " '6',\n",
       " '<',\n",
       " '/a',\n",
       " '>',\n",
       " 'rememb',\n",
       " 'buy',\n",
       " 'cand',\n",
       " 'kid',\n",
       " 'qualit',\n",
       " \"n't\",\n",
       " 'drop',\n",
       " 'year',\n",
       " '.',\n",
       " 'stil',\n",
       " 'superb',\n",
       " 'produc',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappoint',\n",
       " '.',\n",
       " 'lov',\n",
       " 'cand',\n",
       " '.',\n",
       " 'weight',\n",
       " 'watch',\n",
       " 'cut',\n",
       " 'back',\n",
       " 'stil',\n",
       " 'crav',\n",
       " '.',\n",
       " 'liv',\n",
       " 'us',\n",
       " '7',\n",
       " 'yr',\n",
       " 'miss',\n",
       " 'twizzl',\n",
       " 'go',\n",
       " 'back',\n",
       " 'visit',\n",
       " 'someon',\n",
       " 'visit',\n",
       " 'alway',\n",
       " 'stock',\n",
       " '.',\n",
       " 'say',\n",
       " 'yum',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'sel',\n",
       " 'mexico',\n",
       " 'fai',\n",
       " 'buy',\n",
       " 'oft',\n",
       " \"'m\",\n",
       " 'abl',\n",
       " 'buy',\n",
       " 'right',\n",
       " '.',\n",
       " 'produc',\n",
       " 'receiv',\n",
       " 'advertised.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'href=',\n",
       " \"''\",\n",
       " 'http',\n",
       " '//www.amazon.com/gp/product/b001gvisjm',\n",
       " \"''\",\n",
       " '>',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'pack',\n",
       " '6',\n",
       " '<',\n",
       " '/a',\n",
       " '>',\n",
       " 'cand',\n",
       " 'red',\n",
       " 'flav',\n",
       " '.',\n",
       " 'plan',\n",
       " 'chew',\n",
       " '.',\n",
       " 'would',\n",
       " 'nev',\n",
       " 'buy',\n",
       " 'glad',\n",
       " 'amazon',\n",
       " 'carr',\n",
       " 'batter',\n",
       " '.',\n",
       " 'hard',\n",
       " 'tim',\n",
       " 'find',\n",
       " 'elsewh',\n",
       " 'un',\n",
       " 'siz',\n",
       " '.',\n",
       " 'nee',\n",
       " 'gar',\n",
       " 'door',\n",
       " 'opener.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'gre',\n",
       " 'deal',\n",
       " 'pric',\n",
       " '.',\n",
       " 'got',\n",
       " 'mum',\n",
       " 'diabet',\n",
       " 'nee',\n",
       " 'watch',\n",
       " 'sug',\n",
       " 'intak',\n",
       " 'fath',\n",
       " 'simpl',\n",
       " 'choo',\n",
       " 'limit',\n",
       " 'unnecessar',\n",
       " 'sug',\n",
       " 'intak',\n",
       " '-',\n",
       " \"'s\",\n",
       " 'on',\n",
       " 'sweet',\n",
       " 'too',\n",
       " '-',\n",
       " 'lov',\n",
       " 'toff',\n",
       " 'would',\n",
       " 'nev',\n",
       " 'guess',\n",
       " \"'re\",\n",
       " 'sugar-fre',\n",
       " \"'s\",\n",
       " 'gre',\n",
       " 'eat',\n",
       " 'prett',\n",
       " 'much',\n",
       " 'guilt',\n",
       " 'fre',\n",
       " 'impress',\n",
       " \"'ve\",\n",
       " 'ord',\n",
       " 'w',\n",
       " 'dark',\n",
       " 'chocol',\n",
       " 'tak',\n",
       " 'off',\n",
       " \"'ll\",\n",
       " 'eat',\n",
       " 'instead',\n",
       " 'snack',\n",
       " 'sugar',\n",
       " 'sweets.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'excel',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"'s\",\n",
       " 'cactu',\n",
       " 'tequil',\n",
       " 'un',\n",
       " 'combin',\n",
       " 'ingred',\n",
       " 'flavo',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " 'mak',\n",
       " 'on',\n",
       " 'kind',\n",
       " 'pick',\n",
       " 'bottl',\n",
       " 'trip',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'hom',\n",
       " 'us',\n",
       " 'tot',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'real',\n",
       " 'simpl',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'find',\n",
       " 'anywh',\n",
       " 'cit',\n",
       " 'bummed.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'mag',\n",
       " 'internet',\n",
       " 'cas',\n",
       " 'sauc',\n",
       " 'ecst',\n",
       " 'it.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " '..',\n",
       " 'mean',\n",
       " 'reall',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'sauc',\n",
       " 'tastelessl',\n",
       " 'burn',\n",
       " 'throat',\n",
       " 'grab',\n",
       " 'bottl',\n",
       " 'tequil',\n",
       " 'pic',\n",
       " 'gourmet',\n",
       " 'de',\n",
       " 'inc',\n",
       " '.',\n",
       " 'real',\n",
       " 'tast',\n",
       " 'nev',\n",
       " 'want',\n",
       " 'us',\n",
       " 'sauce.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'incr',\n",
       " 'serv',\n",
       " 'nev',\n",
       " 'hug',\n",
       " 'coff',\n",
       " 'fan',\n",
       " '.',\n",
       " 'howev',\n",
       " 'moth',\n",
       " 'purcha',\n",
       " 'littl',\n",
       " 'machin',\n",
       " 'talk',\n",
       " 'tri',\n",
       " 'lat',\n",
       " 'macciato',\n",
       " '.',\n",
       " 'coff',\n",
       " 'shop',\n",
       " 'bet',\n",
       " 'on',\n",
       " 'lik',\n",
       " 'produc',\n",
       " 'us',\n",
       " 'non-coffe',\n",
       " 'drink',\n",
       " '.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'littl',\n",
       " 'dolch',\n",
       " 'guesto',\n",
       " 'machin',\n",
       " 'sup',\n",
       " 'eas',\n",
       " 'us',\n",
       " 'prep',\n",
       " 'reall',\n",
       " 'good',\n",
       " 'coffee/latte/cappuccino/etc',\n",
       " 'less',\n",
       " 'minut',\n",
       " 'wat',\n",
       " 'heat',\n",
       " '.',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'dolc',\n",
       " 'gusto',\n",
       " 'anyon',\n",
       " '.',\n",
       " 'good',\n",
       " 'pric',\n",
       " \"i'am\",\n",
       " 'get',\n",
       " 'on',\n",
       " 'off',\n",
       " 'gre',\n",
       " 'pric',\n",
       " 'gre',\n",
       " 'tast',\n",
       " 'thank',\n",
       " 'amazon',\n",
       " 'sel',\n",
       " 'product.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'star',\n",
       " 'mccann',\n",
       " \"'s\",\n",
       " 'inst',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "filtered_sentence = list(map(lambda x : lancaster.stem(x),filtered_sentence))\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiB_pZw61Sb6"
   },
   "source": [
    "## 3.5.PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jtuCzOdRG4F4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bapan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bought', 'VBN'),\n",
       " ('sev', 'NNS'),\n",
       " ('vit', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('dog', 'VB'),\n",
       " ('food', 'NN'),\n",
       " ('produc', 'NN'),\n",
       " ('found', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " ('qualit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('produc', 'JJ'),\n",
       " ('look', 'NN'),\n",
       " ('lik', 'JJ'),\n",
       " ('stew', 'NN'),\n",
       " ('process', 'NN'),\n",
       " ('meat', 'NN'),\n",
       " ('smel', 'NN'),\n",
       " ('bet', 'NN'),\n",
       " ('.', '.'),\n",
       " ('labrad', 'CC'),\n",
       " ('finick', 'JJ'),\n",
       " ('apprec', 'NN'),\n",
       " ('produc', 'NN'),\n",
       " ('bet', 'NN'),\n",
       " ('.', '.'),\n",
       " ('produc', 'NN'),\n",
       " ('ar', 'NN'),\n",
       " ('label', 'NN'),\n",
       " ('jumbo', 'NN'),\n",
       " ('salt', 'NN'),\n",
       " ('peanut', 'NN'),\n",
       " ('...', ':'),\n",
       " ('peanut', 'NN'),\n",
       " ('act', 'NN'),\n",
       " ('smal', 'JJ'),\n",
       " ('siz', 'NN'),\n",
       " ('unsalt', 'NN'),\n",
       " ('.', '.'),\n",
       " ('sur', 'JJ'),\n",
       " ('er', 'JJ'),\n",
       " ('vend', 'NN'),\n",
       " ('intend', 'VBP'),\n",
       " ('repr', 'NN'),\n",
       " ('produc', 'NN'),\n",
       " ('``', '``'),\n",
       " ('jumbo', 'JJ'),\n",
       " (\"''\", \"''\"),\n",
       " ('.', '.'),\n",
       " ('confect', 'VB'),\n",
       " ('around', 'IN'),\n",
       " ('centur', 'NN'),\n",
       " ('.', '.'),\n",
       " ('light', 'JJ'),\n",
       " ('pillow', 'JJ'),\n",
       " ('citru', 'NN'),\n",
       " ('gelatin', 'NN'),\n",
       " ('nut', 'SYM'),\n",
       " ('-', ':'),\n",
       " ('cas', 'NN'),\n",
       " ('filbert', 'NN'),\n",
       " ('.', '.'),\n",
       " ('cut', 'VB'),\n",
       " ('tin', 'JJ'),\n",
       " ('squ', 'JJ'),\n",
       " ('lib', 'NN'),\n",
       " ('coat', 'NN'),\n",
       " ('powd', 'NN'),\n",
       " ('sug', 'NN'),\n",
       " ('.', '.'),\n",
       " ('tin', 'NN'),\n",
       " ('mou', 'NN'),\n",
       " ('heav', 'NN'),\n",
       " ('.', '.'),\n",
       " ('chew', 'NN'),\n",
       " ('flav', 'NN'),\n",
       " ('.', '.'),\n",
       " ('highl', 'JJ'),\n",
       " ('recommend', 'NN'),\n",
       " ('yumm', 'NN'),\n",
       " ('tre', 'NN'),\n",
       " ('.', '.'),\n",
       " ('famili', 'JJ'),\n",
       " ('stor', 'NN'),\n",
       " ('c.', 'NN'),\n",
       " ('.', '.'),\n",
       " ('lew', 'NN'),\n",
       " (\"'\", \"''\"),\n",
       " ('``', '``'),\n",
       " ('lion', 'NN'),\n",
       " ('witch', 'NN'),\n",
       " ('wardrob', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('-', ':'),\n",
       " ('tre', 'NN'),\n",
       " ('seduc', 'NN'),\n",
       " ('edmund', 'NN'),\n",
       " ('sel', 'VBD'),\n",
       " ('broth', 'DT'),\n",
       " ('sist', 'JJ'),\n",
       " ('witch', 'NN'),\n",
       " ('.', '.'),\n",
       " ('look', 'NN'),\n",
       " ('secret', 'JJ'),\n",
       " ('ingred', 'VBD'),\n",
       " ('robitussin', 'NN'),\n",
       " ('believ', 'NN'),\n",
       " ('found', 'VBD'),\n",
       " ('.', '.'),\n",
       " ('got', 'VBD'),\n",
       " ('addit', 'JJ'),\n",
       " ('root', 'NN'),\n",
       " ('beer', 'NN'),\n",
       " ('extract', 'NN'),\n",
       " ('ord', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('mad', 'NN'),\n",
       " ('cherr', 'NN'),\n",
       " ('sod', 'NN'),\n",
       " ('.', '.'),\n",
       " ('flav', 'JJ'),\n",
       " ('medicin', 'NN'),\n",
       " ('.', '.'),\n",
       " ('gre', 'JJ'),\n",
       " ('taff', 'NN'),\n",
       " ('gre', 'NN'),\n",
       " ('pric', 'NN'),\n",
       " ('.', '.'),\n",
       " ('wid', 'JJ'),\n",
       " ('assort', 'NN'),\n",
       " ('yumm', 'NN'),\n",
       " ('taff', 'NN'),\n",
       " ('.', '.'),\n",
       " ('deliver', 'VB'),\n",
       " ('quick', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('taff', 'NN'),\n",
       " ('lov', 'JJ'),\n",
       " ('deal', 'NN'),\n",
       " ('.', '.'),\n",
       " ('got', 'VBD'),\n",
       " ('wild', 'JJ'),\n",
       " ('hair', 'NN'),\n",
       " ('taff', 'NN'),\n",
       " ('ord', 'NN'),\n",
       " ('fiv', 'NN'),\n",
       " ('pound', 'NN'),\n",
       " ('bag', 'NN'),\n",
       " ('.', '.'),\n",
       " ('taff', 'NN'),\n",
       " ('enjoy', 'NN'),\n",
       " ('man', 'NN'),\n",
       " ('flav', 'NN'),\n",
       " ('watermelon', 'NN'),\n",
       " ('root', 'NN'),\n",
       " ('beer', 'NN'),\n",
       " ('melon', 'NN'),\n",
       " ('peppermint', 'NN'),\n",
       " ('grap', 'NN'),\n",
       " ('etc', 'NN'),\n",
       " ('.', '.'),\n",
       " ('complaint', 'VB'),\n",
       " ('bit', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('red/black', 'NN'),\n",
       " ('licorice-flavor', 'NN'),\n",
       " ('piec', 'NN'),\n",
       " ('particul', 'NN'),\n",
       " ('favorit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('kid', 'NN'),\n",
       " ('husband', 'NN'),\n",
       " ('last', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('week', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('recommend', 'VB'),\n",
       " ('brand', 'NN'),\n",
       " ('taff', 'NN'),\n",
       " ('--', ':'),\n",
       " ('delight', 'JJ'),\n",
       " ('tre', 'NN'),\n",
       " ('.', '.'),\n",
       " ('saltw', 'JJ'),\n",
       " ('taff', 'NN'),\n",
       " ('gre', 'NN'),\n",
       " ('flav', 'NN'),\n",
       " ('soft', 'JJ'),\n",
       " ('chew', 'NN'),\n",
       " ('.', '.'),\n",
       " ('cand', 'NN'),\n",
       " ('individu', 'NN'),\n",
       " ('wrap', 'NN'),\n",
       " ('wel', 'NN'),\n",
       " ('.', '.'),\n",
       " ('non', 'JJ'),\n",
       " ('cand', 'NN'),\n",
       " ('stuck', 'VBD'),\n",
       " ('toge', 'JJ'),\n",
       " ('hap', 'NN'),\n",
       " ('exp', 'NN'),\n",
       " ('vert', 'JJ'),\n",
       " ('fral', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('.', '.'),\n",
       " ('would', 'MD'),\n",
       " ('highl', 'VB'),\n",
       " ('recommend', 'VB'),\n",
       " ('cand', 'NN'),\n",
       " ('serv', 'NN'),\n",
       " ('beach-them', 'JJ'),\n",
       " ('part', 'NN'),\n",
       " ('everyon', 'NN'),\n",
       " ('lov', 'JJ'),\n",
       " ('taff', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('soft', 'JJ'),\n",
       " ('chew', 'NN'),\n",
       " ('.', '.'),\n",
       " ('flav', 'JJ'),\n",
       " ('amaz', 'NN'),\n",
       " ('.', '.'),\n",
       " ('would', 'MD'),\n",
       " ('definit', 'VB'),\n",
       " ('recommend', 'VB'),\n",
       " ('buy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('satisf', 'NN'),\n",
       " ('right', 'JJ'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('mostl', 'JJ'),\n",
       " ('sprout', 'NN'),\n",
       " ('cat', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('grass', 'NN'),\n",
       " ('.', '.'),\n",
       " ('lov', 'NN'),\n",
       " ('.', '.'),\n",
       " ('rot', 'NN'),\n",
       " ('around', 'IN'),\n",
       " ('wheatgrass', 'NN'),\n",
       " ('rye', 'NN'),\n",
       " ('health', 'NN'),\n",
       " ('dog', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('.', '.'),\n",
       " ('good', 'JJ'),\n",
       " ('digest', 'NN'),\n",
       " ('.', '.'),\n",
       " ('also', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('smal', 'JJ'),\n",
       " ('pupp', 'NN'),\n",
       " ('.', '.'),\n",
       " ('dog', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('requir', 'NN'),\n",
       " ('amount', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('fee', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"n't\", 'RB'),\n",
       " ('know', 'VB'),\n",
       " (\"'s\", 'POS'),\n",
       " ('cactu', 'JJ'),\n",
       " ('tequil', 'NN'),\n",
       " ('un', 'JJ'),\n",
       " ('combin', 'NN'),\n",
       " ('ingred', 'VBD'),\n",
       " ('flavo', 'JJ'),\n",
       " ('hot', 'JJ'),\n",
       " ('sauc', 'NN'),\n",
       " ('mak', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('kind', 'NN'),\n",
       " ('pick', 'NN'),\n",
       " ('bottl', 'NN'),\n",
       " ('trip', 'NN'),\n",
       " ('brought', 'VBD'),\n",
       " ('back', 'RP'),\n",
       " ('hom', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('tot', 'VBP'),\n",
       " ('blown', 'VBN'),\n",
       " ('away', 'RB'),\n",
       " ('real', 'JJ'),\n",
       " ('simpl', 'NNS'),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('find', 'VB'),\n",
       " ('anywh', 'JJ'),\n",
       " ('cit', 'NN'),\n",
       " ('bummed.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('mag', 'NN'),\n",
       " ('internet', 'NN'),\n",
       " ('cas', 'NN'),\n",
       " ('sauc', 'NN'),\n",
       " ('ecst', 'NN'),\n",
       " ('it.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('lov', 'NN'),\n",
       " ('hot', 'JJ'),\n",
       " ('sauc', 'NN'),\n",
       " ('..', 'JJ'),\n",
       " ('mean', 'NN'),\n",
       " ('reall', 'NN'),\n",
       " ('lov', 'NN'),\n",
       " ('hot', 'JJ'),\n",
       " ('sauc', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('want', 'VB'),\n",
       " ('sauc', 'JJ'),\n",
       " ('tastelessl', 'NN'),\n",
       " ('burn', 'NN'),\n",
       " ('throat', 'NN'),\n",
       " ('grab', 'NN'),\n",
       " ('bottl', 'NN'),\n",
       " ('tequil', 'NN'),\n",
       " ('pic', 'NN'),\n",
       " ('gourmet', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('inc', 'NN'),\n",
       " ('.', '.'),\n",
       " ('real', 'JJ'),\n",
       " ('tast', 'JJ'),\n",
       " ('nev', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('sauce.', 'VB'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('thank', 'VBD'),\n",
       " ('person', 'NN'),\n",
       " ('incr', 'JJ'),\n",
       " ('serv', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('boy', 'NN'),\n",
       " ('nee', 'JJ'),\n",
       " ('los', 'NN'),\n",
       " ('weight', 'NN'),\n",
       " (\"n't\", 'RB'),\n",
       " ('.', '.'),\n",
       " ('put', 'VB'),\n",
       " ('food', 'NN'),\n",
       " ('flo', 'NN'),\n",
       " ('chubb', 'NN'),\n",
       " ('guy', 'JJ'),\n",
       " ('protein-rich', 'JJ'),\n",
       " ('by-product', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('high', 'JJ'),\n",
       " ('skinn', 'NN'),\n",
       " ('boy', 'NN'),\n",
       " ('jump', 'NN'),\n",
       " ('.', '.'),\n",
       " ('high', 'JJ'),\n",
       " ('food', 'NN'),\n",
       " ('sit', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('stal', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('reall', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('food', 'NN'),\n",
       " ('.', '.'),\n",
       " ('chubb', 'NN'),\n",
       " ('boy', 'NN'),\n",
       " ('los', 'NN'),\n",
       " ('ount', 'NN'),\n",
       " ('week', 'NN'),\n",
       " ('.', '.'),\n",
       " ('cat', 'NN'),\n",
       " ('happil', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('felid', 'JJ'),\n",
       " ('platin', 'NN'),\n",
       " ('two', 'CD'),\n",
       " ('year', 'NN'),\n",
       " ('.', '.'),\n",
       " ('got', 'VBD'),\n",
       " ('new', 'JJ'),\n",
       " ('bag', 'NN'),\n",
       " ('shap', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('diff', 'NN'),\n",
       " ('.', '.'),\n",
       " ('tri', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('food', 'NN'),\n",
       " ('first', 'RB'),\n",
       " ('put', 'VBD'),\n",
       " ('bowl', 'RP'),\n",
       " ('bowl', 'NN'),\n",
       " ('sit', 'NN'),\n",
       " ('ful', 'JJ'),\n",
       " ('kitt', 'NN'),\n",
       " ('touch', 'JJ'),\n",
       " ('food', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('simil', 'JJ'),\n",
       " ('review', 'NN'),\n",
       " ('rel', 'NN'),\n",
       " ('formul', 'NN'),\n",
       " ('chang', 'NN'),\n",
       " ('past', 'NN'),\n",
       " ('.', '.'),\n",
       " ('unfortun', 'JJ'),\n",
       " ('nee', 'JJ'),\n",
       " ('find', 'VBP'),\n",
       " ('new', 'JJ'),\n",
       " ('food', 'NN'),\n",
       " ('cat', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('.', '.'),\n",
       " ('good', 'JJ'),\n",
       " ('flav', 'NN'),\n",
       " ('cam', 'NN'),\n",
       " ('sec', 'NN'),\n",
       " ('pack', 'NN'),\n",
       " ('...', ':'),\n",
       " ('fresh', 'JJ'),\n",
       " ('delic', 'JJ'),\n",
       " ('lov', 'NN'),\n",
       " ('twizzl', 'NN'),\n",
       " ('strawberri', 'NN'),\n",
       " ('twizzl', 'NN'),\n",
       " ('guilt', 'NN'),\n",
       " ('pleas', 'SYM'),\n",
       " ('-', ':'),\n",
       " ('yumm', 'NN'),\n",
       " ('.', '.'),\n",
       " ('six', 'CD'),\n",
       " ('pound', 'NN'),\n",
       " ('around', 'IN'),\n",
       " ('son', 'NN'),\n",
       " ('.', '.'),\n",
       " ('daught', 'JJ'),\n",
       " ('lov', 'NN'),\n",
       " ('twizzl', 'NN'),\n",
       " ('ship', 'NN'),\n",
       " ('six', 'CD'),\n",
       " ('pound', 'NN'),\n",
       " ('reall', 'NN'),\n",
       " ('hit', 'VBD'),\n",
       " ('spot', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'s\", 'POS'),\n",
       " ('exactl', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('expect', 'VB'),\n",
       " ('...', ':'),\n",
       " ('six', 'CD'),\n",
       " ('pack', 'NN'),\n",
       " ('strawberri', 'NN'),\n",
       " ('twizzl', 'NN'),\n",
       " ('.', '.'),\n",
       " ('lov', 'JJ'),\n",
       " ('eat', 'NN'),\n",
       " ('good', 'JJ'),\n",
       " ('watch', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('look', 'NN'),\n",
       " ('mov', 'JJ'),\n",
       " ('sweet', 'NN'),\n",
       " ('.', '.'),\n",
       " ('lik', 'JJ'),\n",
       " ('transf', 'NN'),\n",
       " ('zip', 'NN'),\n",
       " ('lock', 'NN'),\n",
       " ('bagg', 'NN'),\n",
       " ('stay', 'NN'),\n",
       " ('fresh', 'JJ'),\n",
       " ('tak', 'NN'),\n",
       " ('tim', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('.', '.'),\n",
       " ('satisf', 'JJ'),\n",
       " ('twizzl', 'NN'),\n",
       " ('purcha', 'NN'),\n",
       " ('.', '.'),\n",
       " ('shar', 'VB'),\n",
       " ('oth', 'DT'),\n",
       " ('enjoy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('definit', 'NN'),\n",
       " ('ord', 'NN'),\n",
       " ('.', '.'),\n",
       " ('twizzl', 'VB'),\n",
       " ('strawberri', 'JJ'),\n",
       " ('child', 'NN'),\n",
       " ('favorit', 'NN'),\n",
       " ('cand', 'NN'),\n",
       " ('mad', 'NN'),\n",
       " ('lancast', 'NN'),\n",
       " ('pennsylvan', 'NN'),\n",
       " ('cand', 'VBP'),\n",
       " ('inc.', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('oldest', 'JJS'),\n",
       " ('confectioner', 'NN'),\n",
       " ('firm', 'NN'),\n",
       " ('unit', 'NN'),\n",
       " ('stat', 'VBD'),\n",
       " ('subsidiar', 'JJ'),\n",
       " ('hershey', 'NN'),\n",
       " ('compan', 'VBP'),\n",
       " ('compan', 'NN'),\n",
       " ('est', 'NN'),\n",
       " ('1845', 'CD'),\n",
       " ('young', 'JJ'),\n",
       " ('smyl', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('mak', 'VBZ'),\n",
       " ('appl', 'JJ'),\n",
       " ('lic', 'JJ'),\n",
       " ('twist', 'NN'),\n",
       " ('green', 'JJ'),\n",
       " ('col', 'NN'),\n",
       " ('blu', 'NN'),\n",
       " ('raspberr', 'VBZ'),\n",
       " ('lic', 'JJ'),\n",
       " ('twist', 'NN'),\n",
       " ('lik', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('keep', 'VB'),\n",
       " ('dri', 'NN'),\n",
       " ('cool', 'JJ'),\n",
       " ('plac', 'NN'),\n",
       " ('recommend', 'NN'),\n",
       " ('put', 'VBD'),\n",
       " ('fridg', 'RB'),\n",
       " ('.', '.'),\n",
       " ('accord', 'VB'),\n",
       " ('guin', 'JJ'),\n",
       " ('book', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('longest', 'JJS'),\n",
       " ('lic', 'JJ'),\n",
       " ('twist', 'NN'),\n",
       " ('ev', 'NN'),\n",
       " ('mad', 'JJ'),\n",
       " ('meas', 'NNS'),\n",
       " ('1.200', 'CD'),\n",
       " ('feet', 'NNS'),\n",
       " ('370', 'CD'),\n",
       " ('weight', 'VBD'),\n",
       " ('100', 'CD'),\n",
       " ('pound', 'NN'),\n",
       " ('45', 'CD'),\n",
       " ('kg', 'NN'),\n",
       " ('mad', 'JJ'),\n",
       " ('cand', 'NN'),\n",
       " ('int', 'NN'),\n",
       " ('.', '.'),\n",
       " ('record-break', 'JJ'),\n",
       " ('twist', 'NN'),\n",
       " ('becam', 'NN'),\n",
       " ('guin', 'JJ'),\n",
       " ('world', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('jul', 'NN'),\n",
       " ('19', 'CD'),\n",
       " ('1998', 'CD'),\n",
       " ('.', '.'),\n",
       " ('produc', 'VB'),\n",
       " ('kosh', 'JJ'),\n",
       " ('thank', 'NN'),\n",
       " ('cand', 'NN'),\n",
       " ('del', 'NN'),\n",
       " ('fast', 'JJ'),\n",
       " ('purcha', 'JJ'),\n",
       " ('reason', 'NN'),\n",
       " ('pric', 'NN'),\n",
       " ('.', '.'),\n",
       " ('hom', 'NN'),\n",
       " ('bound', 'NN'),\n",
       " ('un', 'JJ'),\n",
       " ('get', 'NN'),\n",
       " ('stor', 'NN'),\n",
       " ('perfect', 'NN'),\n",
       " ('.', '.'),\n",
       " ('husband', 'NN'),\n",
       " ('twizzl', 'NN'),\n",
       " ('addict', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('bought', 'VBN'),\n",
       " ('man', 'NN'),\n",
       " ('tim', 'NN'),\n",
       " ('amazon', 'NN'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('govern', 'JJ'),\n",
       " ('employ', 'JJ'),\n",
       " ('liv', 'NN'),\n",
       " ('overse', 'NN'),\n",
       " ('ca', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('get', 'VB'),\n",
       " ('countr', 'JJ'),\n",
       " ('assign', 'NN'),\n",
       " ('.', '.'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('alway', 'RB'),\n",
       " ('fresh', 'JJ'),\n",
       " ('tast', 'NN'),\n",
       " ('pack', 'NN'),\n",
       " ('wel', 'NN'),\n",
       " ('ar', 'NN'),\n",
       " ('tim', 'NN'),\n",
       " ('man', 'NN'),\n",
       " ('.', '.'),\n",
       " ('bought', 'VBD'),\n",
       " ('husband', 'NN'),\n",
       " ('cur', 'NN'),\n",
       " ('overse', 'NN'),\n",
       " ('.', '.'),\n",
       " ('lov', 'JJ'),\n",
       " ('app', 'JJ'),\n",
       " ('staff', 'NN'),\n",
       " ('lik', 'NN'),\n",
       " ('also.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('gen', 'NN'),\n",
       " ('amount', 'NN'),\n",
       " ('twizzl', 'VBD'),\n",
       " ('16-ounc', 'JJ'),\n",
       " ('bag', 'NN'),\n",
       " ('wel', 'NN'),\n",
       " ('wor', 'NN'),\n",
       " ('pric', 'NN'),\n",
       " ('.', '.'),\n",
       " ('<', 'CC'),\n",
       " ('href=', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('http', 'NN'),\n",
       " ('//www.amazon.com/gp/product/b001gvisjm', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('>', 'CC'),\n",
       " ('twizzl', 'JJ'),\n",
       " ('strawberri', 'JJ'),\n",
       " ('16-ounc', 'JJ'),\n",
       " ('bag', 'NN'),\n",
       " ('pack', 'NN'),\n",
       " ('6', 'CD'),\n",
       " ('<', 'JJ'),\n",
       " ('/a', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('rememb', 'NN'),\n",
       " ('buy', 'NN'),\n",
       " ('cand', 'VBP'),\n",
       " ('kid', 'NN'),\n",
       " ('qualit', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('drop', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('.', '.'),\n",
       " ('stil', 'NN'),\n",
       " ('superb', 'NN'),\n",
       " ('produc', 'NN'),\n",
       " ('wo', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('disappoint', 'VB'),\n",
       " ('.', '.'),\n",
       " ('lov', 'JJ'),\n",
       " ('cand', 'NN'),\n",
       " ('.', '.'),\n",
       " ('weight', 'NN'),\n",
       " ('watch', 'NN'),\n",
       " ('cut', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('stil', 'JJ'),\n",
       " ('crav', 'NN'),\n",
       " ('.', '.'),\n",
       " ('liv', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('7', 'CD'),\n",
       " ('yr', 'JJ'),\n",
       " ('miss', 'NN'),\n",
       " ('twizzl', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('back', 'RB'),\n",
       " ('visit', 'RB'),\n",
       " ('someon', 'JJ'),\n",
       " ('visit', 'NN'),\n",
       " ('alway', 'NN'),\n",
       " ('stock', 'NN'),\n",
       " ('.', '.'),\n",
       " ('say', 'VB'),\n",
       " ('yum', 'JJ'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('sel', 'NN'),\n",
       " ('mexico', 'NN'),\n",
       " ('fai', 'NN'),\n",
       " ('buy', 'VB'),\n",
       " ('oft', 'JJ'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('abl', 'JJ'),\n",
       " ('buy', 'NN'),\n",
       " ('right', 'RB'),\n",
       " ('.', '.'),\n",
       " ('produc', 'VB'),\n",
       " ('receiv', 'JJ'),\n",
       " ('advertised.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('href=', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('http', 'NN'),\n",
       " ('//www.amazon.com/gp/product/b001gvisjm', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('>', 'CC'),\n",
       " ('twizzl', 'JJ'),\n",
       " ('strawberri', 'JJ'),\n",
       " ('16-ounc', 'JJ'),\n",
       " ('bag', 'NN'),\n",
       " ('pack', 'NN'),\n",
       " ('6', 'CD'),\n",
       " ('<', 'JJ'),\n",
       " ('/a', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('cand', 'NN'),\n",
       " ('red', 'VBD'),\n",
       " ('flav', 'NN'),\n",
       " ('.', '.'),\n",
       " ('plan', 'NN'),\n",
       " ('chew', 'NN'),\n",
       " ('.', '.'),\n",
       " ('would', 'MD'),\n",
       " ('nev', 'VB'),\n",
       " ('buy', 'VB'),\n",
       " ('glad', 'JJ'),\n",
       " ('amazon', 'NN'),\n",
       " ('carr', 'NN'),\n",
       " ('batter', 'NN'),\n",
       " ('.', '.'),\n",
       " ('hard', 'JJ'),\n",
       " ('tim', 'NN'),\n",
       " ('find', 'VB'),\n",
       " ('elsewh', 'JJ'),\n",
       " ('un', 'JJ'),\n",
       " ('siz', 'NN'),\n",
       " ('.', '.'),\n",
       " ('nee', 'JJ'),\n",
       " ('gar', 'NN'),\n",
       " ('door', 'NN'),\n",
       " ('opener.', 'IN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('gre', 'NN'),\n",
       " ('deal', 'NN'),\n",
       " ('pric', 'NN'),\n",
       " ('.', '.'),\n",
       " ('got', 'VBD'),\n",
       " ('mum', 'JJ'),\n",
       " ('diabet', 'JJ'),\n",
       " ('nee', 'NN'),\n",
       " ('watch', 'NN'),\n",
       " ('sug', 'NN'),\n",
       " ('intak', 'JJ'),\n",
       " ('fath', 'NN'),\n",
       " ('simpl', 'NN'),\n",
       " ('choo', 'NN'),\n",
       " ('limit', 'NN'),\n",
       " ('unnecessar', 'JJ'),\n",
       " ('sug', 'NN'),\n",
       " ('intak', 'SYM'),\n",
       " ('-', ':'),\n",
       " (\"'s\", 'POS'),\n",
       " ('on', 'IN'),\n",
       " ('sweet', 'NN'),\n",
       " ('too', 'RB'),\n",
       " ('-', ':'),\n",
       " ('lov', 'NN'),\n",
       " ('toff', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('nev', 'VB'),\n",
       " ('guess', 'JJ'),\n",
       " (\"'re\", 'VBP'),\n",
       " ('sugar-fre', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('gre', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('prett', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('guilt', 'NN'),\n",
       " ('fre', 'NN'),\n",
       " ('impress', 'NN'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('ord', 'VBN'),\n",
       " ('w', 'NN'),\n",
       " ('dark', 'NN'),\n",
       " ('chocol', 'NN'),\n",
       " ('tak', 'VBD'),\n",
       " ('off', 'RP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('eat', 'VB'),\n",
       " ('instead', 'RB'),\n",
       " ('snack', 'NN'),\n",
       " ('sugar', 'NN'),\n",
       " ('sweets.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('excel', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('know', 'VB'),\n",
       " (\"'s\", 'POS'),\n",
       " ('cactu', 'JJ'),\n",
       " ('tequil', 'NN'),\n",
       " ('un', 'JJ'),\n",
       " ('combin', 'NN'),\n",
       " ('ingred', 'VBD'),\n",
       " ('flavo', 'JJ'),\n",
       " ('hot', 'JJ'),\n",
       " ('sauc', 'NN'),\n",
       " ('mak', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('kind', 'NN'),\n",
       " ('pick', 'NN'),\n",
       " ('bottl', 'NN'),\n",
       " ('trip', 'NN'),\n",
       " ('brought', 'VBD'),\n",
       " ('back', 'RP'),\n",
       " ('hom', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('tot', 'VBP'),\n",
       " ('blown', 'VBN'),\n",
       " ('away', 'RB'),\n",
       " ('real', 'JJ'),\n",
       " ('simpl', 'NNS'),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('find', 'VB'),\n",
       " ('anywh', 'JJ'),\n",
       " ('cit', 'NN'),\n",
       " ('bummed.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('mag', 'NN'),\n",
       " ('internet', 'NN'),\n",
       " ('cas', 'NN'),\n",
       " ('sauc', 'NN'),\n",
       " ('ecst', 'NN'),\n",
       " ('it.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('lov', 'NN'),\n",
       " ('hot', 'JJ'),\n",
       " ('sauc', 'NN'),\n",
       " ('..', 'JJ'),\n",
       " ('mean', 'NN'),\n",
       " ('reall', 'NN'),\n",
       " ('lov', 'NN'),\n",
       " ('hot', 'JJ'),\n",
       " ('sauc', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('want', 'VB'),\n",
       " ('sauc', 'JJ'),\n",
       " ('tastelessl', 'NN'),\n",
       " ('burn', 'NN'),\n",
       " ('throat', 'NN'),\n",
       " ('grab', 'NN'),\n",
       " ('bottl', 'NN'),\n",
       " ('tequil', 'NN'),\n",
       " ('pic', 'NN'),\n",
       " ('gourmet', 'NN'),\n",
       " ('de', 'IN'),\n",
       " ('inc', 'NN'),\n",
       " ('.', '.'),\n",
       " ('real', 'JJ'),\n",
       " ('tast', 'JJ'),\n",
       " ('nev', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('sauce.', 'VB'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('thank', 'VBD'),\n",
       " ('person', 'NN'),\n",
       " ('incr', 'JJ'),\n",
       " ('serv', 'NN'),\n",
       " ('nev', 'NN'),\n",
       " ('hug', 'VBD'),\n",
       " ('coff', 'NN'),\n",
       " ('fan', 'NN'),\n",
       " ('.', '.'),\n",
       " ('howev', 'VB'),\n",
       " ('moth', 'JJ'),\n",
       " ('purcha', 'NN'),\n",
       " ('littl', 'NN'),\n",
       " ('machin', 'JJ'),\n",
       " ('talk', 'NN'),\n",
       " ('tri', 'NN'),\n",
       " ('lat', 'JJ'),\n",
       " ('macciato', 'NN'),\n",
       " ('.', '.'),\n",
       " ('coff', 'NN'),\n",
       " ('shop', 'NN'),\n",
       " ('bet', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('lik', 'NN'),\n",
       " ('produc', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('non-coffe', 'JJ'),\n",
       " ('drink', 'NN'),\n",
       " ('.', '.'),\n",
       " ('<', 'CC'),\n",
       " ('br', 'JJ'),\n",
       " ('>', 'NNP'),\n",
       " ('littl', 'NN'),\n",
       " ('dolch', 'NN'),\n",
       " ('guesto', 'NN'),\n",
       " ('machin', 'NN'),\n",
       " ('sup', 'NN'),\n",
       " ('eas', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('prep', 'VB'),\n",
       " ('reall', 'VB'),\n",
       " ('good', 'JJ'),\n",
       " ('coffee/latte/cappuccino/etc', 'NN'),\n",
       " ('less', 'RBR'),\n",
       " ('minut', 'JJ'),\n",
       " ('wat', 'NN'),\n",
       " ('heat', 'NN'),\n",
       " ('.', '.'),\n",
       " ('would', 'MD'),\n",
       " ('recommend', 'VB'),\n",
       " ('dolc', 'NN'),\n",
       " ('gusto', 'NN'),\n",
       " ('anyon', 'NN'),\n",
       " ('.', '.'),\n",
       " ('good', 'JJ'),\n",
       " ('pric', 'NN'),\n",
       " (\"i'am\", 'NN'),\n",
       " ('get', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('off', 'RP'),\n",
       " ('gre', 'NN'),\n",
       " ('pric', 'JJ'),\n",
       " ('gre', 'NN'),\n",
       " ('tast', 'NN'),\n",
       " ('thank', 'NN'),\n",
       " ('amazon', 'JJ'),\n",
       " ('sel', 'NN'),\n",
       " ('product.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('>', 'NNP'),\n",
       " ('star', 'NN'),\n",
       " ('mccann', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('inst', 'JJ'),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nltk.pos_tag(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNekLhZNQScM"
   },
   "source": [
    "# Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gks5nGgTHcbO"
   },
   "outputs": [],
   "source": [
    "filter1 =nltk.pos_tag(filtered_sentence)\n",
    "df_filter =pd.DataFrame(filter1,columns=['pos_tag', 'tag_type'])\n",
    "#df_filter.to_csv('filter.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>tag_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sev</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pos_tag tag_type\n",
       "0  bought      VBN\n",
       "1     sev      NNS\n",
       "2     vit       NN\n",
       "3     can       MD\n",
       "4     dog       VB"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ixroF9NGFvi"
   },
   "source": [
    "# 4.**Techniques for Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "67431e1466aefbba119b54205893dd0dcdff9f3b",
    "id": "-ZTp3zY-4Ztw"
   },
   "source": [
    "4. **Techniques for Encoding**\n",
    "\n",
    "      **BAG OF WORDS**\n",
    "      \n",
    "      In BoW we construct a dictionary that contains set of all unique words from our text review dataset.The frequency of the word is counted here. if there are **d** unique words in our dictionary then for every sentence or review the vector will be of length **d** and count of word from review is stored at its particular location in vector. The vector will be highly sparse in such case.\n",
    "      \n",
    "      Ex. pasta is tasty and pasta is good\n",
    "      \n",
    "     **[0]....[1]............[1]...........[2]..........[2]............[1]..........**             <== Its vector representation ( remaining all dots will be represented as zeroes)\n",
    "     \n",
    "     **[a]..[and].....[good].......[is].......[pasta]....[tasty].......**            <==This is dictionary\n",
    "      .\n",
    "      \n",
    "    Using scikit-learn's CountVectorizer we can get the BoW and check out all the parameters it consists of, one of them is max_features =5000 it tells about to consider only top 5000 most frequently repeated words to place in a dictionary. so our dictionary length or vector length will be only 5000\n",
    "    \n",
    "\n",
    "\n",
    "   **BINARY BAG OF WORDS**\n",
    "    \n",
    "   In binary BoW, we dont count the frequency of word, we just place **1** if the word appears in the review or else **0**. In CountVectorizer there is a parameter **binary = true** this makes our BoW to binary BoW.\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought',\n",
       " 'sev',\n",
       " 'vit',\n",
       " 'can',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'produc',\n",
       " 'found',\n",
       " 'good',\n",
       " 'qualit',\n",
       " '.',\n",
       " 'produc',\n",
       " 'look',\n",
       " 'lik',\n",
       " 'stew',\n",
       " 'process',\n",
       " 'meat',\n",
       " 'smel',\n",
       " 'bet',\n",
       " '.',\n",
       " 'labrad',\n",
       " 'finick',\n",
       " 'apprec',\n",
       " 'produc',\n",
       " 'bet',\n",
       " '.',\n",
       " 'produc',\n",
       " 'ar',\n",
       " 'label',\n",
       " 'jumbo',\n",
       " 'salt',\n",
       " 'peanut',\n",
       " '...',\n",
       " 'peanut',\n",
       " 'act',\n",
       " 'smal',\n",
       " 'siz',\n",
       " 'unsalt',\n",
       " '.',\n",
       " 'sur',\n",
       " 'er',\n",
       " 'vend',\n",
       " 'intend',\n",
       " 'repr',\n",
       " 'produc',\n",
       " '``',\n",
       " 'jumbo',\n",
       " \"''\",\n",
       " '.',\n",
       " 'confect',\n",
       " 'around',\n",
       " 'centur',\n",
       " '.',\n",
       " 'light',\n",
       " 'pillow',\n",
       " 'citru',\n",
       " 'gelatin',\n",
       " 'nut',\n",
       " '-',\n",
       " 'cas',\n",
       " 'filbert',\n",
       " '.',\n",
       " 'cut',\n",
       " 'tin',\n",
       " 'squ',\n",
       " 'lib',\n",
       " 'coat',\n",
       " 'powd',\n",
       " 'sug',\n",
       " '.',\n",
       " 'tin',\n",
       " 'mou',\n",
       " 'heav',\n",
       " '.',\n",
       " 'chew',\n",
       " 'flav',\n",
       " '.',\n",
       " 'highl',\n",
       " 'recommend',\n",
       " 'yumm',\n",
       " 'tre',\n",
       " '.',\n",
       " 'famili',\n",
       " 'stor',\n",
       " 'c.',\n",
       " '.',\n",
       " 'lew',\n",
       " \"'\",\n",
       " '``',\n",
       " 'lion',\n",
       " 'witch',\n",
       " 'wardrob',\n",
       " \"''\",\n",
       " '-',\n",
       " 'tre',\n",
       " 'seduc',\n",
       " 'edmund',\n",
       " 'sel',\n",
       " 'broth',\n",
       " 'sist',\n",
       " 'witch',\n",
       " '.',\n",
       " 'look',\n",
       " 'secret',\n",
       " 'ingred',\n",
       " 'robitussin',\n",
       " 'believ',\n",
       " 'found',\n",
       " '.',\n",
       " 'got',\n",
       " 'addit',\n",
       " 'root',\n",
       " 'beer',\n",
       " 'extract',\n",
       " 'ord',\n",
       " 'good',\n",
       " 'mad',\n",
       " 'cherr',\n",
       " 'sod',\n",
       " '.',\n",
       " 'flav',\n",
       " 'medicin',\n",
       " '.',\n",
       " 'gre',\n",
       " 'taff',\n",
       " 'gre',\n",
       " 'pric',\n",
       " '.',\n",
       " 'wid',\n",
       " 'assort',\n",
       " 'yumm',\n",
       " 'taff',\n",
       " '.',\n",
       " 'deliver',\n",
       " 'quick',\n",
       " '.',\n",
       " 'taff',\n",
       " 'lov',\n",
       " 'deal',\n",
       " '.',\n",
       " 'got',\n",
       " 'wild',\n",
       " 'hair',\n",
       " 'taff',\n",
       " 'ord',\n",
       " 'fiv',\n",
       " 'pound',\n",
       " 'bag',\n",
       " '.',\n",
       " 'taff',\n",
       " 'enjoy',\n",
       " 'man',\n",
       " 'flav',\n",
       " 'watermelon',\n",
       " 'root',\n",
       " 'beer',\n",
       " 'melon',\n",
       " 'peppermint',\n",
       " 'grap',\n",
       " 'etc',\n",
       " '.',\n",
       " 'complaint',\n",
       " 'bit',\n",
       " 'much',\n",
       " 'red/black',\n",
       " 'licorice-flavor',\n",
       " 'piec',\n",
       " 'particul',\n",
       " 'favorit',\n",
       " '.',\n",
       " 'kid',\n",
       " 'husband',\n",
       " 'last',\n",
       " 'two',\n",
       " 'week',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'brand',\n",
       " 'taff',\n",
       " '--',\n",
       " 'delight',\n",
       " 'tre',\n",
       " '.',\n",
       " 'saltw',\n",
       " 'taff',\n",
       " 'gre',\n",
       " 'flav',\n",
       " 'soft',\n",
       " 'chew',\n",
       " '.',\n",
       " 'cand',\n",
       " 'individu',\n",
       " 'wrap',\n",
       " 'wel',\n",
       " '.',\n",
       " 'non',\n",
       " 'cand',\n",
       " 'stuck',\n",
       " 'toge',\n",
       " 'hap',\n",
       " 'exp',\n",
       " 'vert',\n",
       " 'fral',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'would',\n",
       " 'highl',\n",
       " 'recommend',\n",
       " 'cand',\n",
       " 'serv',\n",
       " 'beach-them',\n",
       " 'part',\n",
       " 'everyon',\n",
       " 'lov',\n",
       " 'taff',\n",
       " 'good',\n",
       " '.',\n",
       " 'soft',\n",
       " 'chew',\n",
       " '.',\n",
       " 'flav',\n",
       " 'amaz',\n",
       " '.',\n",
       " 'would',\n",
       " 'definit',\n",
       " 'recommend',\n",
       " 'buy',\n",
       " '.',\n",
       " 'satisf',\n",
       " 'right',\n",
       " \"'m\",\n",
       " 'mostl',\n",
       " 'sprout',\n",
       " 'cat',\n",
       " 'eat',\n",
       " 'grass',\n",
       " '.',\n",
       " 'lov',\n",
       " '.',\n",
       " 'rot',\n",
       " 'around',\n",
       " 'wheatgrass',\n",
       " 'rye',\n",
       " 'health',\n",
       " 'dog',\n",
       " 'food',\n",
       " '.',\n",
       " 'good',\n",
       " 'digest',\n",
       " '.',\n",
       " 'also',\n",
       " 'good',\n",
       " 'smal',\n",
       " 'pupp',\n",
       " '.',\n",
       " 'dog',\n",
       " 'eat',\n",
       " 'requir',\n",
       " 'amount',\n",
       " 'ever',\n",
       " 'fee',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"'s\",\n",
       " 'cactu',\n",
       " 'tequil',\n",
       " 'un',\n",
       " 'combin',\n",
       " 'ingred',\n",
       " 'flavo',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " 'mak',\n",
       " 'on',\n",
       " 'kind',\n",
       " 'pick',\n",
       " 'bottl',\n",
       " 'trip',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'hom',\n",
       " 'us',\n",
       " 'tot',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'real',\n",
       " 'simpl',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'find',\n",
       " 'anywh',\n",
       " 'cit',\n",
       " 'bummed.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'mag',\n",
       " 'internet',\n",
       " 'cas',\n",
       " 'sauc',\n",
       " 'ecst',\n",
       " 'it.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " '..',\n",
       " 'mean',\n",
       " 'reall',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'sauc',\n",
       " 'tastelessl',\n",
       " 'burn',\n",
       " 'throat',\n",
       " 'grab',\n",
       " 'bottl',\n",
       " 'tequil',\n",
       " 'pic',\n",
       " 'gourmet',\n",
       " 'de',\n",
       " 'inc',\n",
       " '.',\n",
       " 'real',\n",
       " 'tast',\n",
       " 'nev',\n",
       " 'want',\n",
       " 'us',\n",
       " 'sauce.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'incr',\n",
       " 'serv',\n",
       " 'on',\n",
       " 'boy',\n",
       " 'nee',\n",
       " 'los',\n",
       " 'weight',\n",
       " \"n't\",\n",
       " '.',\n",
       " 'put',\n",
       " 'food',\n",
       " 'flo',\n",
       " 'chubb',\n",
       " 'guy',\n",
       " 'protein-rich',\n",
       " 'by-product',\n",
       " 'food',\n",
       " 'high',\n",
       " 'skinn',\n",
       " 'boy',\n",
       " 'jump',\n",
       " '.',\n",
       " 'high',\n",
       " 'food',\n",
       " 'sit',\n",
       " 'go',\n",
       " 'stal',\n",
       " '.',\n",
       " 'reall',\n",
       " 'go',\n",
       " 'food',\n",
       " '.',\n",
       " 'chubb',\n",
       " 'boy',\n",
       " 'los',\n",
       " 'ount',\n",
       " 'week',\n",
       " '.',\n",
       " 'cat',\n",
       " 'happil',\n",
       " 'eat',\n",
       " 'felid',\n",
       " 'platin',\n",
       " 'two',\n",
       " 'year',\n",
       " '.',\n",
       " 'got',\n",
       " 'new',\n",
       " 'bag',\n",
       " 'shap',\n",
       " 'food',\n",
       " 'diff',\n",
       " '.',\n",
       " 'tri',\n",
       " 'new',\n",
       " 'food',\n",
       " 'first',\n",
       " 'put',\n",
       " 'bowl',\n",
       " 'bowl',\n",
       " 'sit',\n",
       " 'ful',\n",
       " 'kitt',\n",
       " 'touch',\n",
       " 'food',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'not',\n",
       " 'simil',\n",
       " 'review',\n",
       " 'rel',\n",
       " 'formul',\n",
       " 'chang',\n",
       " 'past',\n",
       " '.',\n",
       " 'unfortun',\n",
       " 'nee',\n",
       " 'find',\n",
       " 'new',\n",
       " 'food',\n",
       " 'cat',\n",
       " 'eat',\n",
       " '.',\n",
       " 'good',\n",
       " 'flav',\n",
       " 'cam',\n",
       " 'sec',\n",
       " 'pack',\n",
       " '...',\n",
       " 'fresh',\n",
       " 'delic',\n",
       " 'lov',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " 'twizzl',\n",
       " 'guilt',\n",
       " 'pleas',\n",
       " '-',\n",
       " 'yumm',\n",
       " '.',\n",
       " 'six',\n",
       " 'pound',\n",
       " 'around',\n",
       " 'son',\n",
       " '.',\n",
       " 'daught',\n",
       " 'lov',\n",
       " 'twizzl',\n",
       " 'ship',\n",
       " 'six',\n",
       " 'pound',\n",
       " 'reall',\n",
       " 'hit',\n",
       " 'spot',\n",
       " '.',\n",
       " \"'s\",\n",
       " 'exactl',\n",
       " 'would',\n",
       " 'expect',\n",
       " '...',\n",
       " 'six',\n",
       " 'pack',\n",
       " 'strawberri',\n",
       " 'twizzl',\n",
       " '.',\n",
       " 'lov',\n",
       " 'eat',\n",
       " 'good',\n",
       " 'watch',\n",
       " 'tv',\n",
       " 'look',\n",
       " 'mov',\n",
       " 'sweet',\n",
       " '.',\n",
       " 'lik',\n",
       " 'transf',\n",
       " 'zip',\n",
       " 'lock',\n",
       " 'bagg',\n",
       " 'stay',\n",
       " 'fresh',\n",
       " 'tak',\n",
       " 'tim',\n",
       " 'eat',\n",
       " '.',\n",
       " 'satisf',\n",
       " 'twizzl',\n",
       " 'purcha',\n",
       " '.',\n",
       " 'shar',\n",
       " 'oth',\n",
       " 'enjoy',\n",
       " '.',\n",
       " 'definit',\n",
       " 'ord',\n",
       " '.',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " 'child',\n",
       " 'favorit',\n",
       " 'cand',\n",
       " 'mad',\n",
       " 'lancast',\n",
       " 'pennsylvan',\n",
       " 'cand',\n",
       " 'inc.',\n",
       " 'on',\n",
       " 'oldest',\n",
       " 'confectioner',\n",
       " 'firm',\n",
       " 'unit',\n",
       " 'stat',\n",
       " 'subsidiar',\n",
       " 'hershey',\n",
       " 'compan',\n",
       " 'compan',\n",
       " 'est',\n",
       " '1845',\n",
       " 'young',\n",
       " 'smyl',\n",
       " 'also',\n",
       " 'mak',\n",
       " 'appl',\n",
       " 'lic',\n",
       " 'twist',\n",
       " 'green',\n",
       " 'col',\n",
       " 'blu',\n",
       " 'raspberr',\n",
       " 'lic',\n",
       " 'twist',\n",
       " 'lik',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'keep',\n",
       " 'dri',\n",
       " 'cool',\n",
       " 'plac',\n",
       " 'recommend',\n",
       " 'put',\n",
       " 'fridg',\n",
       " '.',\n",
       " 'accord',\n",
       " 'guin',\n",
       " 'book',\n",
       " 'record',\n",
       " 'longest',\n",
       " 'lic',\n",
       " 'twist',\n",
       " 'ev',\n",
       " 'mad',\n",
       " 'meas',\n",
       " '1.200',\n",
       " 'feet',\n",
       " '370',\n",
       " 'weight',\n",
       " '100',\n",
       " 'pound',\n",
       " '45',\n",
       " 'kg',\n",
       " 'mad',\n",
       " 'cand',\n",
       " 'int',\n",
       " '.',\n",
       " 'record-break',\n",
       " 'twist',\n",
       " 'becam',\n",
       " 'guin',\n",
       " 'world',\n",
       " 'record',\n",
       " 'jul',\n",
       " '19',\n",
       " '1998',\n",
       " '.',\n",
       " 'produc',\n",
       " 'kosh',\n",
       " 'thank',\n",
       " 'cand',\n",
       " 'del',\n",
       " 'fast',\n",
       " 'purcha',\n",
       " 'reason',\n",
       " 'pric',\n",
       " '.',\n",
       " 'hom',\n",
       " 'bound',\n",
       " 'un',\n",
       " 'get',\n",
       " 'stor',\n",
       " 'perfect',\n",
       " '.',\n",
       " 'husband',\n",
       " 'twizzl',\n",
       " 'addict',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'bought',\n",
       " 'man',\n",
       " 'tim',\n",
       " 'amazon',\n",
       " \"'re\",\n",
       " 'govern',\n",
       " 'employ',\n",
       " 'liv',\n",
       " 'overse',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'get',\n",
       " 'countr',\n",
       " 'assign',\n",
       " '.',\n",
       " \"'ve\",\n",
       " 'alway',\n",
       " 'fresh',\n",
       " 'tast',\n",
       " 'pack',\n",
       " 'wel',\n",
       " 'ar',\n",
       " 'tim',\n",
       " 'man',\n",
       " '.',\n",
       " 'bought',\n",
       " 'husband',\n",
       " 'cur',\n",
       " 'overse',\n",
       " '.',\n",
       " 'lov',\n",
       " 'app',\n",
       " 'staff',\n",
       " 'lik',\n",
       " 'also.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'gen',\n",
       " 'amount',\n",
       " 'twizzl',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'wel',\n",
       " 'wor',\n",
       " 'pric',\n",
       " '.',\n",
       " '<',\n",
       " 'href=',\n",
       " \"''\",\n",
       " 'http',\n",
       " '//www.amazon.com/gp/product/b001gvisjm',\n",
       " \"''\",\n",
       " '>',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'pack',\n",
       " '6',\n",
       " '<',\n",
       " '/a',\n",
       " '>',\n",
       " 'rememb',\n",
       " 'buy',\n",
       " 'cand',\n",
       " 'kid',\n",
       " 'qualit',\n",
       " \"n't\",\n",
       " 'drop',\n",
       " 'year',\n",
       " '.',\n",
       " 'stil',\n",
       " 'superb',\n",
       " 'produc',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappoint',\n",
       " '.',\n",
       " 'lov',\n",
       " 'cand',\n",
       " '.',\n",
       " 'weight',\n",
       " 'watch',\n",
       " 'cut',\n",
       " 'back',\n",
       " 'stil',\n",
       " 'crav',\n",
       " '.',\n",
       " 'liv',\n",
       " 'us',\n",
       " '7',\n",
       " 'yr',\n",
       " 'miss',\n",
       " 'twizzl',\n",
       " 'go',\n",
       " 'back',\n",
       " 'visit',\n",
       " 'someon',\n",
       " 'visit',\n",
       " 'alway',\n",
       " 'stock',\n",
       " '.',\n",
       " 'say',\n",
       " 'yum',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'sel',\n",
       " 'mexico',\n",
       " 'fai',\n",
       " 'buy',\n",
       " 'oft',\n",
       " \"'m\",\n",
       " 'abl',\n",
       " 'buy',\n",
       " 'right',\n",
       " '.',\n",
       " 'produc',\n",
       " 'receiv',\n",
       " 'advertised.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'href=',\n",
       " \"''\",\n",
       " 'http',\n",
       " '//www.amazon.com/gp/product/b001gvisjm',\n",
       " \"''\",\n",
       " '>',\n",
       " 'twizzl',\n",
       " 'strawberri',\n",
       " '16-ounc',\n",
       " 'bag',\n",
       " 'pack',\n",
       " '6',\n",
       " '<',\n",
       " '/a',\n",
       " '>',\n",
       " 'cand',\n",
       " 'red',\n",
       " 'flav',\n",
       " '.',\n",
       " 'plan',\n",
       " 'chew',\n",
       " '.',\n",
       " 'would',\n",
       " 'nev',\n",
       " 'buy',\n",
       " 'glad',\n",
       " 'amazon',\n",
       " 'carr',\n",
       " 'batter',\n",
       " '.',\n",
       " 'hard',\n",
       " 'tim',\n",
       " 'find',\n",
       " 'elsewh',\n",
       " 'un',\n",
       " 'siz',\n",
       " '.',\n",
       " 'nee',\n",
       " 'gar',\n",
       " 'door',\n",
       " 'opener.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'gre',\n",
       " 'deal',\n",
       " 'pric',\n",
       " '.',\n",
       " 'got',\n",
       " 'mum',\n",
       " 'diabet',\n",
       " 'nee',\n",
       " 'watch',\n",
       " 'sug',\n",
       " 'intak',\n",
       " 'fath',\n",
       " 'simpl',\n",
       " 'choo',\n",
       " 'limit',\n",
       " 'unnecessar',\n",
       " 'sug',\n",
       " 'intak',\n",
       " '-',\n",
       " \"'s\",\n",
       " 'on',\n",
       " 'sweet',\n",
       " 'too',\n",
       " '-',\n",
       " 'lov',\n",
       " 'toff',\n",
       " 'would',\n",
       " 'nev',\n",
       " 'guess',\n",
       " \"'re\",\n",
       " 'sugar-fre',\n",
       " \"'s\",\n",
       " 'gre',\n",
       " 'eat',\n",
       " 'prett',\n",
       " 'much',\n",
       " 'guilt',\n",
       " 'fre',\n",
       " 'impress',\n",
       " \"'ve\",\n",
       " 'ord',\n",
       " 'w',\n",
       " 'dark',\n",
       " 'chocol',\n",
       " 'tak',\n",
       " 'off',\n",
       " \"'ll\",\n",
       " 'eat',\n",
       " 'instead',\n",
       " 'snack',\n",
       " 'sugar',\n",
       " 'sweets.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'excel',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"'s\",\n",
       " 'cactu',\n",
       " 'tequil',\n",
       " 'un',\n",
       " 'combin',\n",
       " 'ingred',\n",
       " 'flavo',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " 'mak',\n",
       " 'on',\n",
       " 'kind',\n",
       " 'pick',\n",
       " 'bottl',\n",
       " 'trip',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'hom',\n",
       " 'us',\n",
       " 'tot',\n",
       " 'blown',\n",
       " 'away',\n",
       " 'real',\n",
       " 'simpl',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'find',\n",
       " 'anywh',\n",
       " 'cit',\n",
       " 'bummed.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'mag',\n",
       " 'internet',\n",
       " 'cas',\n",
       " 'sauc',\n",
       " 'ecst',\n",
       " 'it.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " '..',\n",
       " 'mean',\n",
       " 'reall',\n",
       " 'lov',\n",
       " 'hot',\n",
       " 'sauc',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'sauc',\n",
       " 'tastelessl',\n",
       " 'burn',\n",
       " 'throat',\n",
       " 'grab',\n",
       " 'bottl',\n",
       " 'tequil',\n",
       " 'pic',\n",
       " 'gourmet',\n",
       " 'de',\n",
       " 'inc',\n",
       " '.',\n",
       " 'real',\n",
       " 'tast',\n",
       " 'nev',\n",
       " 'want',\n",
       " 'us',\n",
       " 'sauce.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'thank',\n",
       " 'person',\n",
       " 'incr',\n",
       " 'serv',\n",
       " 'nev',\n",
       " 'hug',\n",
       " 'coff',\n",
       " 'fan',\n",
       " '.',\n",
       " 'howev',\n",
       " 'moth',\n",
       " 'purcha',\n",
       " 'littl',\n",
       " 'machin',\n",
       " 'talk',\n",
       " 'tri',\n",
       " 'lat',\n",
       " 'macciato',\n",
       " '.',\n",
       " 'coff',\n",
       " 'shop',\n",
       " 'bet',\n",
       " 'on',\n",
       " 'lik',\n",
       " 'produc',\n",
       " 'us',\n",
       " 'non-coffe',\n",
       " 'drink',\n",
       " '.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'littl',\n",
       " 'dolch',\n",
       " 'guesto',\n",
       " 'machin',\n",
       " 'sup',\n",
       " 'eas',\n",
       " 'us',\n",
       " 'prep',\n",
       " 'reall',\n",
       " 'good',\n",
       " 'coffee/latte/cappuccino/etc',\n",
       " 'less',\n",
       " 'minut',\n",
       " 'wat',\n",
       " 'heat',\n",
       " '.',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'dolc',\n",
       " 'gusto',\n",
       " 'anyon',\n",
       " '.',\n",
       " 'good',\n",
       " 'pric',\n",
       " \"i'am\",\n",
       " 'get',\n",
       " 'on',\n",
       " 'off',\n",
       " 'gre',\n",
       " 'pric',\n",
       " 'gre',\n",
       " 'tast',\n",
       " 'thank',\n",
       " 'amazon',\n",
       " 'sel',\n",
       " 'product.',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '>',\n",
       " 'star',\n",
       " 'mccann',\n",
       " \"'s\",\n",
       " 'inst',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "lO5XWjsSHeoY"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer  = CountVectorizer()\n",
    "vectorizer.fit(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84583, 5504)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = vectorizer.transform(filtered_sentence)\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_vectorizer  =CountVectorizer(binary=True)\n",
    "binary_vectorizer.fit(filtered_sentence)\n",
    "len(binary_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_vector = binary_vectorizer.transform(filtered_sentence)\n",
    "binary_vector.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da9a72410e69708650ccf3263fea6d9b1222147f",
    "id": "Sd74HLAv4Zt1"
   },
   "source": [
    " **Drawbacks of BoW/ Binary BoW**\n",
    " \n",
    " Our main objective in doing these text to vector encodings is that similar meaning text vectors should be close to each other, but in some cases this may not possible for Bow\n",
    " \n",
    "For example, if we consider two reviews **This pasta is very tasty** and **This pasta is not tasty** after stopwords removal both sentences will be converted to **pasta tasty** so both giving exact same meaning.\n",
    "\n",
    "The main problem is here we are not considering the front and back words related to every word, here comes Bigram and Ngram techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LECjIsn5UK7h"
   },
   "source": [
    "## 4.1.N-gram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8c25fa64918f9b5129ca8d424684354c29f041d",
    "id": "3fUU4t5M4Zt2"
   },
   "source": [
    "### 4.1.1.**BI-GRAM BOW**\n",
    "\n",
    "Considering pair of words for creating dictionary is Bi-Gram , Tri-Gram means three consecutive words so as NGram.\n",
    "\n",
    "CountVectorizer has a parameter **ngram_range** if assigned to (1,2) it considers Bi-Gram BoW\n",
    "\n",
    "But this massively increases our dictionary size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "zYNyQalgHgx4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram\n",
    "\n",
    "CountVec = CountVectorizer(ngram_range=(0,1)) # forward bigram\n",
    "bi = CountVec.fit(filtered_sentence)\n",
    "len(bi.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84583, 5504)\n"
     ]
    }
   ],
   "source": [
    "bigram_vector = CountVec.transform(filtered_sentence)\n",
    "print(bigram_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d29a0749cc26757d3f311cadee7dfdd97aa7c76",
    "id": "lHcH77Nu4ZuA"
   },
   "source": [
    "## 4.2.**TF-IDF**\n",
    "\n",
    "**Term Frequency -  Inverse Document Frequency** it makes sure that less importance is given to most frequent words and also considers less frequent words.\n",
    "\n",
    "**Term Frequency** is number of times a **particular word(W)** occurs in a review divided by totall number of words **(Wr)** in review. The term frequency value ranges from 0 to 1.\n",
    "\n",
    "**Inverse Document Frequency** is calculated as **log(Total Number of Docs(N) / Number of Docs which contains particular word(n))**. Here Docs referred as Reviews.\n",
    "\n",
    "\n",
    "**TF-IDF** is **TF * IDF** that is **(W/Wr)*LOG(N/n)**\n",
    "\n",
    "\n",
    " Using scikit-learn's tfidfVectorizer we can get the TF-IDF.\n",
    "\n",
    "So even here we get a TF-IDF value for every word and in some cases it may consider different meaning reviews as similar after stopwords removal. so to over come we can use BI-Gram or NGram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "bF2KDPygHiPW"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5337"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vec_smooth = TfidfVectorizer(use_idf=True,  \n",
    "                        smooth_idf=True,  \n",
    "                        ngram_range=(0,1),stop_words='english')\n",
    "tf_idf_vec_smooth.fit(filtered_sentence)\n",
    "len(tf_idf_vec_smooth.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84583, 5337)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector = tf_idf_vec_smooth.transform(filtered_sentence)\n",
    "tf_idf_vector.shape  # not printing vector as the size is large and will display out of memory error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd2IJswwQjxa"
   },
   "source": [
    "## 4.3.Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpIR5o5zveup"
   },
   "source": [
    "Gensim is a free to use python library. It provides APIs to solve various problems relating to natural language processing. It is fast, scalable and robust.\n",
    "\n",
    "In this practice exercise we will train our own Word2Vec model using gensim Word2Vec API. Objectives of this practice exercise are, \n",
    "\n",
    "\n",
    "1.   Train your word2vec word embedding model.\n",
    "2.   Visualize trained word embedding model using principal component analysis.\n",
    "\n",
    "\n",
    "First step will be to load the corpus, clean it and tokenize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYs5Xlmf6539"
   },
   "source": [
    "Libraries used in this notebook along with their version:\n",
    "\n",
    "google\t2.0.3\n",
    "\n",
    "matplotlib\t3.2.1\n",
    "\n",
    "numpy\t1.18.3\n",
    "\n",
    "pandas\t1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "y5x2UsJBHjfz"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7JLBNQSzibP"
   },
   "source": [
    "Next step is to import the Word2Vec model from gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ET56QszJHkz1"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqTRR4O7zymN"
   },
   "source": [
    "##### Create your own model using the data_list defined above and gensim Word2Vec API. (Hint: https://radimrehurek.com/gensim/models/word2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = report.head(5)  # taking 5 values to make computation faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for sentences in train:\n",
    "    train[i] = sentences.split(' ')\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = []\n",
    "for val in train:\n",
    "    document.append(val)\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "JW2iWKa6HmiK"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=document, vector_size=4, window=1, min_count=1, workers=4)\n",
    "model.save(\"word2vec_2.model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00525026,  0.08687656, -0.02292105,  0.2099418 ], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['Salted']  # vector for Salted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('very', 0.9754360318183899),\n",
       " ('This', 0.8565337657928467),\n",
       " ('out', 0.8558760285377502),\n",
       " ('got', 0.8383424878120422),\n",
       " ('dog', 0.7904241681098938),\n",
       " ('in', 0.7720502614974976),\n",
       " ('with', 0.7592442035675049),\n",
       " ('you', 0.7581216096878052),\n",
       " ('', 0.7547386288642883),\n",
       " ('Filberts.', 0.7532793879508972)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.wv.most_similar('Salted', topn=10) # most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18129264,  0.23563291,  0.1912711 ,  0.13729256], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Witch.', 0.9921318292617798),\n",
       " ('canned', 0.9699839353561401),\n",
       " ('you', 0.9456015825271606),\n",
       " ('tiny', 0.9127481579780579),\n",
       " ('-', 0.8640699982643127),\n",
       " ('got', 0.8637152910232544),\n",
       " ('more', 0.8624321222305298),\n",
       " ('labeled', 0.8432460427284241),\n",
       " ('with', 0.8026028871536255),\n",
       " ('liberally', 0.7958273887634277)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.wv.most_similar('food', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b599Joey0a1W"
   },
   "source": [
    "##### Use PCA algorithm from sklearn to convert high dimesnional word embeddings to two diemnsions and save them in the variable \"results\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2TT3A0n0u0D"
   },
   "source": [
    "##### Visualizing the word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkYL18YhPYLW"
   },
   "source": [
    "# 5.Emotion and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfWFnaytHwrN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPWeJKOa92/X/aynAIwYQ1F",
   "collapsed_sections": [],
   "name": "Session2_inclass_question-v1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
