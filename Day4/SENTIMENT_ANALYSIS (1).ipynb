{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sentiment-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('D:/NLP_DataSets/Sentiment_Analysis/TwitterSA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                        1.0            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location user_timezone  \n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN         Quito  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-9533ffea17a8>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['sentiment'] = Sentiment\n"
     ]
    }
   ],
   "source": [
    "Sentiment = []\n",
    "for e in df1['sentiment']:\n",
    "    \n",
    "    if e=='Positive' or e=='Neutral':\n",
    "         Sentiment.append('positive')\n",
    "    else:\n",
    "         Sentiment.append('negative')\n",
    "df1['sentiment'] = Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapan\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df1.sentiment)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet = train_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Masking, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = list()\n",
    "for comp in Tweet:\n",
    "    data_list.append(RegexpTokenizer('\\w+').tokenize(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13871"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " 'TJMShow',\n",
       " 'No',\n",
       " 'mention',\n",
       " 'of',\n",
       " 'Tamir',\n",
       " 'Rice',\n",
       " 'and',\n",
       " 'the',\n",
       " 'GOPDebate',\n",
       " 'was',\n",
       " 'held',\n",
       " 'in',\n",
       " 'Cleveland',\n",
       " 'Wow']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = []\n",
    "for line in data_list:\n",
    "    lines = list(map(lambda x: x.lower(), line))\n",
    "    low.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'gregabbott_tx',\n",
       " 'tedcruz',\n",
       " 'on',\n",
       " 'my',\n",
       " 'first',\n",
       " 'day',\n",
       " 'i',\n",
       " 'will',\n",
       " 'rescind',\n",
       " 'every',\n",
       " 'illegal',\n",
       " 'executive',\n",
       " 'action',\n",
       " 'taken',\n",
       " 'by',\n",
       " 'barack',\n",
       " 'obama',\n",
       " 'gopdebate',\n",
       " 'foxnews']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =  list(punctuation)  # + stopwords.words('english')  \n",
    "# stop_words.remove('no')\n",
    "# stop_words.remove('not')\n",
    "# stop_words.remove(\"wasn't\")\n",
    "# stop_words.remove(\"shouldn't\")\n",
    "# stop_words.remove(\"isn't\")\n",
    "# stop_words.remove(\"haven't\")\n",
    "# stop_words.remove(\"down\")\n",
    "# stop_words.remove(\"off\")\n",
    "# stop_words.remove(\"aren't\")\n",
    "# stop_words.remove(\"couldn't\")\n",
    "# stop_words.remove(\"doesn't\")\n",
    "# stop_words.remove(\"only\")\n",
    "# stop_words.remove(\"most\")\n",
    "# stop_words.remove(\"over\")\n",
    "# stop_words.remove(\"under\")\n",
    "# stop_words.remove(\"such\")\n",
    "# stop_words.remove(\"too\")\n",
    "# stop_words.remove(\"few\")\n",
    "# stop_words.remove(\"against\")\n",
    "# stop_words.remove(\"if\")\n",
    "\n",
    "def tokenize(words):\n",
    "    #words = word_tokenize(text)\n",
    "    #words = [w.lower() for w in words]\n",
    "    return [w for w in words if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentiment = []\n",
    "for file_id in low:\n",
    "    words = tokenize(file_id)\n",
    "    filtered_sentiment.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'tjmshow',\n",
       " 'no',\n",
       " 'mention',\n",
       " 'of',\n",
       " 'tamir',\n",
       " 'rice',\n",
       " 'and',\n",
       " 'the',\n",
       " 'gopdebate',\n",
       " 'was',\n",
       " 'held',\n",
       " 'in',\n",
       " 'cleveland',\n",
       " 'wow']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentiment[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13871\n",
      "13871\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_sentiment))\n",
    "print(len(low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bapan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = []\n",
    "for line in filtered_sentiment:\n",
    "    lines = list(map(lambda x: lmtzr.lemmatize(x), line))\n",
    "    lemmatized.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'tjmshow',\n",
       " 'no',\n",
       " 'mention',\n",
       " 'of',\n",
       " 'tamir',\n",
       " 'rice',\n",
       " 'and',\n",
       " 'the',\n",
       " 'gopdebate',\n",
       " 'wa',\n",
       " 'held',\n",
       " 'in',\n",
       " 'cleveland',\n",
       " 'wow']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13871"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = []\n",
    "for row in final_X:\n",
    "    seq = ''\n",
    "    for word in row:\n",
    "        seq = seq + ' ' + word\n",
    "    sent.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = pd.Series(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rt scottwalker didn t catch the full gopdebate last night here are some of scott s best line in 90 second walker16 http t co zsff\n"
     ]
    }
   ],
   "source": [
    "print(final_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabsize = 5000\n",
    "tokenizer = Tokenizer(num_words = vocabsize, split=' ')\n",
    "tokenizer.fit_on_texts(final_X.values)\n",
    "X = tokenizer.texts_to_sequences(final_X.values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(train_data['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1        positive\n",
       "2        positive\n",
       "3        positive\n",
       "4        positive\n",
       "           ...   \n",
       "13866    negative\n",
       "13867    positive\n",
       "13868    positive\n",
       "13869    negative\n",
       "13870    positive\n",
       "Name: sentiment, Length: 13871, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                       X, y, test_size=0.15, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11790, 31)\n",
      "(2081, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          3, 3963,   47,   63,    2,  326,  179, 1161, 1840,  189, 1185,\n",
       "         23, 1480, 1161,   90,   19,    8,    4,    9,    1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 200\n",
    "lstm_out = 196\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabsize, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "#model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout = 0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.4, recurrent_dropout = 0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 31, 200)           1000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 31, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               311248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 1,311,642\n",
      "Trainable params: 1,311,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "369/369 [==============================] - 31s 78ms/step - loss: 0.5761 - accuracy: 0.6908 - val_loss: 0.5150 - val_accuracy: 0.7492\n",
      "Epoch 2/10\n",
      "369/369 [==============================] - 27s 73ms/step - loss: 0.4782 - accuracy: 0.7709 - val_loss: 0.5139 - val_accuracy: 0.7371\n",
      "Epoch 3/10\n",
      "369/369 [==============================] - 28s 75ms/step - loss: 0.4226 - accuracy: 0.8036 - val_loss: 0.5123 - val_accuracy: 0.7395\n",
      "Epoch 4/10\n",
      "369/369 [==============================] - 27s 74ms/step - loss: 0.3763 - accuracy: 0.8295 - val_loss: 0.5454 - val_accuracy: 0.7463\n",
      "Epoch 5/10\n",
      "369/369 [==============================] - 27s 74ms/step - loss: 0.3381 - accuracy: 0.8502 - val_loss: 0.5759 - val_accuracy: 0.7386\n",
      "Epoch 6/10\n",
      "369/369 [==============================] - 27s 73ms/step - loss: 0.3038 - accuracy: 0.8613 - val_loss: 0.6226 - val_accuracy: 0.7299\n",
      "Epoch 7/10\n",
      "369/369 [==============================] - 27s 74ms/step - loss: 0.2813 - accuracy: 0.8757 - val_loss: 0.6807 - val_accuracy: 0.7237\n",
      "Epoch 8/10\n",
      "369/369 [==============================] - 27s 73ms/step - loss: 0.2569 - accuracy: 0.8851 - val_loss: 0.7557 - val_accuracy: 0.7256\n",
      "Epoch 9/10\n",
      "369/369 [==============================] - 26s 70ms/step - loss: 0.2414 - accuracy: 0.8939 - val_loss: 0.8363 - val_accuracy: 0.7309\n",
      "Epoch 10/10\n",
      "369/369 [==============================] - 26s 70ms/step - loss: 0.2266 - accuracy: 0.9008 - val_loss: 0.8795 - val_accuracy: 0.7290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2859b3dcbb0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0  109 1124   12 1780]]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 31) for input KerasTensor(type_spec=TensorSpec(shape=(None, 31), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (1, 28).\n",
      "1/1 - 0s\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "twts = ['Only fanatical crowd is easily controllable']\n",
    "       #['I use emotion for the many and reason for the few']]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twts = tokenizer.texts_to_sequences(twts)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twts = pad_sequences(twts, maxlen=28, dtype='int32', value=0)\n",
    "print(twts)\n",
    "sentiment = model.predict(twts,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10159443, 0.8984056 ], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0 953  29 170  44  89 363 499  34 109  59  51\n",
      "   47 496 420   2 563  13 791 540  20 363]]\n",
      "1/1 - 0s\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twts = ['''Modi talked about Swiss money but did nothing.\n",
    "       Internally also he only harassed people with what chidambaram called demonization, \n",
    "       making the poor and middle class suffer for nothing.''']\n",
    "       #['I use emotion for the many and reason for the few']]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twts = tokenizer.texts_to_sequences(twts)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twts = pad_sequences(twts, maxlen=28, dtype='int32', value=0)\n",
    "print(twts)\n",
    "sentiment = model.predict(twts,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9934582 , 0.00654184], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_senti = []\n",
    "\n",
    "for i in X_val:\n",
    "    #print(i)\n",
    "    Senti = model.predict(i.reshape(1,-1), batch_size = 1)[0]\n",
    "    if np.argmax(Senti) == 0:\n",
    "        pred_senti.append('negative')\n",
    "    else:\n",
    "        pred_senti.append('positive')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_senti[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "Building wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py): started\n",
      "  Building wheel for afinn (setup.py): finished with status 'done'\n",
      "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53455 sha256=d94e8fc27c78736475f9e0b3f58ada181443d30effcb9b6e2b167383180a5d63\n",
      "  Stored in directory: c:\\users\\bapan\\appdata\\local\\pip\\cache\\wheels\\f6\\6f\\c3\\b305c5107a17618f2938a067d5ffcbb556909d82398762089e\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_af, X_val_af = train_test_split(\n",
    "                                   final_X, test_size=0.15, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11790,), (2081,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_af.shape, X_val_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jgreendc realdonaldtrump in all fairness billclinton owns that phrase gopdebate'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_af[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' rt nancyleegrahn how did everyone feel about the climate change question last night exactly gopdebate'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_af[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = [af.score(tweet) for tweet in X_val_af]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = ['positive' if score > 0 else 'negative' for score in sentiment_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i][1] == 1:\n",
    "        actual.append('positive')\n",
    "    else:\n",
    "        actual.append('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['Actual Sentiment'] = actual\n",
    "test_df['LSTM_Sentiment'] = pred_senti\n",
    "test_df['Auto_Sentiment'] = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th>LSTM_Sentiment</th>\n",
       "      <th>Auto_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Actual Sentiment LSTM_Sentiment Auto_Sentiment\n",
       "0         negative       negative       negative\n",
       "1         negative       positive       positive\n",
       "2         positive       positive       positive\n",
       "3         negative       positive       negative\n",
       "4         positive       negative       negative\n",
       "5         positive       positive       negative\n",
       "6         negative       negative       positive\n",
       "7         negative       positive       negative\n",
       "8         positive       positive       negative\n",
       "9         negative       negative       positive"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df1 = pd.crosstab(test_df['Actual Sentiment'], test_df['LSTM_Sentiment'], rownames=['Actual'], colnames=['predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1010</td>\n",
       "      <td>284</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>308</td>\n",
       "      <td>479</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1318</td>\n",
       "      <td>763</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  negative  positive   All\n",
       "Actual                             \n",
       "negative       1010       284  1294\n",
       "positive        308       479   787\n",
       "All            1318       763  2081"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df2 = pd.crosstab(test_df['Actual Sentiment'], test_df['Auto_Sentiment'], rownames=['Actual'], colnames=['predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>876</td>\n",
       "      <td>418</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>418</td>\n",
       "      <td>369</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1294</td>\n",
       "      <td>787</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  negative  positive   All\n",
       "Actual                             \n",
       "negative        876       418  1294\n",
       "positive        418       369   787\n",
       "All            1294       787  2081"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
