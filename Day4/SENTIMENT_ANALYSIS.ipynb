{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sentiment-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('D:/NLP_DataSets/Sentiment_Analysis/TwitterSA/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold  ... relevant_yn_gold  \\\n",
       "0                        1.0            NaN  ...              NaN   \n",
       "\n",
       "  retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0             5             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location user_timezone  \n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN         Quito  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['text', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   Neutral"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment = []\n",
    "# for e in df1['sentiment']:\n",
    "    \n",
    "#     if e=='Positive':     # or e=='Neutral':\n",
    "#          Sentiment.append('positive')\n",
    "#     else:\n",
    "#          Sentiment.append('negative')\n",
    "# df1['sentiment'] = Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.sentiment != \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n",
       "1  RT @RobGeorge: That Carly Fiorina is trending ...  Positive"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10729, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapan\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df1.sentiment)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet = train_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF…\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout, Masking, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = list()\n",
    "for comp in Tweet:\n",
    "    data_list.append(RegexpTokenizer('\\w+').tokenize(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10729"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " 'DanScavino',\n",
       " 'GOPDebate',\n",
       " 'w',\n",
       " 'realDonaldTrump',\n",
       " 'delivered',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'ratings',\n",
       " 'in',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'presidential',\n",
       " 'debates',\n",
       " 'Trump2016',\n",
       " 'http',\n",
       " 't',\n",
       " 'co']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = []\n",
    "for line in data_list:\n",
    "    lines = list(map(lambda x: x.lower(), line))\n",
    "    low.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deer',\n",
       " 'in',\n",
       " 'the',\n",
       " 'headlights',\n",
       " 'rt',\n",
       " 'lizzwinstead',\n",
       " 'ben',\n",
       " 'carson',\n",
       " 'may',\n",
       " 'be',\n",
       " 'the',\n",
       " 'only',\n",
       " 'brain',\n",
       " 'surgeon',\n",
       " 'who',\n",
       " 'has',\n",
       " 'performed',\n",
       " 'a',\n",
       " 'lobotomy',\n",
       " 'on',\n",
       " 'himself',\n",
       " 'gopdebate']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words =  list(punctuation) + stopwords.words('english')  \n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove(\"wasn't\")\n",
    "stop_words.remove(\"shouldn't\")\n",
    "stop_words.remove(\"isn't\")\n",
    "stop_words.remove(\"haven't\")\n",
    "stop_words.remove(\"down\")\n",
    "stop_words.remove(\"off\")\n",
    "stop_words.remove(\"aren't\")\n",
    "stop_words.remove(\"couldn't\")\n",
    "stop_words.remove(\"doesn't\")\n",
    "stop_words.remove(\"only\")\n",
    "stop_words.remove(\"most\")\n",
    "stop_words.remove(\"over\")\n",
    "stop_words.remove(\"under\")\n",
    "stop_words.remove(\"such\")\n",
    "stop_words.remove(\"too\")\n",
    "stop_words.remove(\"few\")\n",
    "stop_words.remove(\"against\")\n",
    "stop_words.remove(\"if\")\n",
    "\n",
    "def tokenize(words):\n",
    "    #words = word_tokenize(text)\n",
    "    #words = [w.lower() for w in words]\n",
    "    return [w for w in words if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'more',\n",
       " 'other',\n",
       " 'some',\n",
       " 'nor',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " 'couldn',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " 'isn',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " 'wasn',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentiment = []\n",
    "for file_id in low:\n",
    "    words = tokenize(file_id)\n",
    "    filtered_sentiment.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'danscavino',\n",
       " 'gopdebate',\n",
       " 'w',\n",
       " 'realdonaldtrump',\n",
       " 'delivered',\n",
       " 'highest',\n",
       " 'ratings',\n",
       " 'history',\n",
       " 'presidential',\n",
       " 'debates',\n",
       " 'trump2016',\n",
       " 'http',\n",
       " 'co']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentiment[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10729\n",
      "10729\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_sentiment))\n",
    "print(len(low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bapan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = []\n",
    "for line in filtered_sentiment:\n",
    "    lines = list(map(lambda x: lmtzr.lemmatize(x), line))\n",
    "    lemmatized.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'danscavino',\n",
       " 'gopdebate',\n",
       " 'w',\n",
       " 'realdonaldtrump',\n",
       " 'delivered',\n",
       " 'highest',\n",
       " 'rating',\n",
       " 'history',\n",
       " 'presidential',\n",
       " 'debate',\n",
       " 'trump2016',\n",
       " 'http',\n",
       " 'co']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10729"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = []\n",
    "for row in final_X:\n",
    "    seq = ''\n",
    "    for word in row:\n",
    "        seq = seq + ' ' + word\n",
    "    sent.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X = pd.Series(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " rt robgeorge carly fiorina trending hour debate men completed gopdebate say\n"
     ]
    }
   ],
   "source": [
    "print(final_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabsize = 5000\n",
    "tokenizer = Tokenizer(num_words = vocabsize, split=' ')\n",
    "tokenizer.fit_on_texts(final_X.values)\n",
    "X = tokenizer.texts_to_sequences(final_X.values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(train_data['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Positive\n",
       "1        Positive\n",
       "2        Positive\n",
       "3        Positive\n",
       "4        Negative\n",
       "           ...   \n",
       "10724    Negative\n",
       "10725    Positive\n",
       "10726    Positive\n",
       "10727    Negative\n",
       "10728    Positive\n",
       "Name: sentiment, Length: 10729, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                       X, y, test_size=0.15, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9119, 24)\n",
      "(1610, 24)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    2,   58,  361,  238,  265,  915,    1, 1938,\n",
       "          4,    5])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 50\n",
    "#lstm_out = 296\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabsize, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "#model.add(LSTM(196, dropout=0.4, return_sequences=True))\n",
    "model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 50)            250000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 24, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               193648    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 444,042\n",
      "Trainable params: 444,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "285/285 [==============================] - 16s 49ms/step - loss: 0.4341 - accuracy: 0.8164 - val_loss: 0.3173 - val_accuracy: 0.8727\n",
      "Epoch 2/5\n",
      "285/285 [==============================] - 12s 43ms/step - loss: 0.3026 - accuracy: 0.8728 - val_loss: 0.3289 - val_accuracy: 0.8696\n",
      "Epoch 3/5\n",
      "285/285 [==============================] - 12s 42ms/step - loss: 0.2553 - accuracy: 0.8948 - val_loss: 0.3214 - val_accuracy: 0.8739\n",
      "Epoch 4/5\n",
      "285/285 [==============================] - 12s 43ms/step - loss: 0.2226 - accuracy: 0.9087 - val_loss: 0.3282 - val_accuracy: 0.8627\n",
      "Epoch 5/5\n",
      "285/285 [==============================] - 12s 42ms/step - loss: 0.1972 - accuracy: 0.9213 - val_loss: 0.3381 - val_accuracy: 0.8621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14881ee77f0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0 2593    9  157 4069 1636]]\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 24) for input KerasTensor(type_spec=TensorSpec(shape=(None, 24), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (1, 28).\n",
      "1/1 - 0s\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twts = ['''We are secular not because the word was added in our constitition.\n",
    "           Secularism is in our blood.''']\n",
    "       #['I use emotion for the many and reason for the few']]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twts = tokenizer.texts_to_sequences(twts)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twts = pad_sequences(twts, maxlen=28, dtype='int32', value=0)\n",
    "print(twts)\n",
    "sentiment = model.predict(twts,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9924434 , 0.00755663], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  796   84  264  417 2769   52   21  361  344  394  779  422  264]]\n",
      "1/1 - 0s\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twts = ['''Modi talked about Swiss money but did nothing.\n",
    "       Internally also he only harassed people with what chidambaram called demonization, \n",
    "       making the poor and middle class suffer for nothing.''']\n",
    "       #['I use emotion for the many and reason for the few']]\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twts = tokenizer.texts_to_sequences(twts)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twts = pad_sequences(twts, maxlen=28, dtype='int32', value=0)\n",
    "print(twts)\n",
    "sentiment = model.predict(twts,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9686854 , 0.03131463], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_senti = []\n",
    "\n",
    "for i in X_val:\n",
    "    #print(i)\n",
    "    Senti = model.predict(i.reshape(1,-1), batch_size = 1)[0]\n",
    "    if np.argmax(Senti) == 0:\n",
    "        pred_senti.append('negative')\n",
    "    else:\n",
    "        pred_senti.append('positive')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative',\n",
       " 'negative']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_senti[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "Building wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py): started\n",
      "  Building wheel for afinn (setup.py): finished with status 'done'\n",
      "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53455 sha256=d94e8fc27c78736475f9e0b3f58ada181443d30effcb9b6e2b167383180a5d63\n",
      "  Stored in directory: c:\\users\\bapan\\appdata\\local\\pip\\cache\\wheels\\f6\\6f\\c3\\b305c5107a17618f2938a067d5ffcbb556909d82398762089e\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from afinn import Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_af, X_val_af = train_test_split(\n",
    "                                   final_X, test_size=0.15, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11790,), (2081,))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_af.shape, X_val_af.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' jgreendc realdonaldtrump in all fairness billclinton owns that phrase gopdebate'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_af[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' rt nancyleegrahn how did everyone feel about the climate change question last night exactly gopdebate'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_af[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = [af.score(tweet) for tweet in X_val_af]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "an = ['positive' if score > 0 else 'negative' for score in sentiment_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i][1] == 1:\n",
    "        actual.append('positive')\n",
    "    else:\n",
    "        actual.append('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['Actual Sentiment'] = actual\n",
    "test_df['LSTM_Sentiment'] = pred_senti\n",
    "test_df['Auto_Sentiment'] = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Sentiment</th>\n",
       "      <th>LSTM_Sentiment</th>\n",
       "      <th>Auto_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Actual Sentiment LSTM_Sentiment Auto_Sentiment\n",
       "0         negative       negative       negative\n",
       "1         negative       positive       positive\n",
       "2         positive       positive       positive\n",
       "3         negative       positive       negative\n",
       "4         positive       negative       negative\n",
       "5         positive       positive       negative\n",
       "6         negative       negative       positive\n",
       "7         negative       positive       negative\n",
       "8         positive       positive       negative\n",
       "9         negative       negative       positive"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df1 = pd.crosstab(test_df['Actual Sentiment'], test_df['LSTM_Sentiment'], rownames=['Actual'], colnames=['predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1010</td>\n",
       "      <td>284</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>308</td>\n",
       "      <td>479</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1318</td>\n",
       "      <td>763</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  negative  positive   All\n",
       "Actual                             \n",
       "negative       1010       284  1294\n",
       "positive        308       479   787\n",
       "All            1318       763  2081"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df2 = pd.crosstab(test_df['Actual Sentiment'], test_df['Auto_Sentiment'], rownames=['Actual'], colnames=['predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>876</td>\n",
       "      <td>418</td>\n",
       "      <td>1294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>418</td>\n",
       "      <td>369</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1294</td>\n",
       "      <td>787</td>\n",
       "      <td>2081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted  negative  positive   All\n",
       "Actual                             \n",
       "negative        876       418  1294\n",
       "positive        418       369   787\n",
       "All            1294       787  2081"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
