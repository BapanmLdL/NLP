{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlM6Wrr1X2Od"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELKoW_4xgr2T"
   },
   "source": [
    "# 1.Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NV-sKoldw8at"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to C:\\Users\\Ankita singh\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ankita singh\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Ankita singh\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from six import string_types\n",
    "from nltk.corpus import reuters\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('reuters') # Downloading corpus\n",
    "nltk.download('stopwords') # Downloading stopwords\n",
    "nltk.download('punkt') # Downloading tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqD5wboL06eJ"
   },
   "source": [
    "# 2.Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8n3VBOcxb4r"
   },
   "source": [
    "We will employ a text categorization dataset based on Reviews. Each article is assigned a specific captegory. \n",
    "#### Implement the code to load the dataset.(Hint: Use the pandas library to load the csv file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-Qf7hD11xC5n"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.read_csv(\"bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohaWN5kbyENg"
   },
   "source": [
    "# Create a function called \"Report\" to store the news text ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rITP99BYxE0Z"
   },
   "outputs": [],
   "source": [
    "report=df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwVN_hQ_09r0"
   },
   "source": [
    "# 3.Proccessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMQDwUEZyl-t"
   },
   "source": [
    "We will use the above function here to create a list of list that will store each complaint tokenized into separate words.(Hint: Use regular expression based tokenizer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPJesTws2BN6"
   },
   "source": [
    "## 3.1.Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6wQK9LWsxGkA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tv', 'future', 'in', 'the', 'hands', 'of', 'viewers', 'with', 'home', 'theatre', 'systems', 'plasma', 'high-definition', 'tvs', 'and', 'digital', 'video', 'recorders', 'moving', 'into', 'the', 'living', 'room', 'the', 'way', 'people', 'watch', 'tv', 'will', 'be', 'radically', 'different', 'in', 'five', 'years', 'time', '.', 'that', 'is', 'according', 'to', 'an', 'expert', 'panel', 'which', 'gathered', 'at', 'the', 'annual', 'consumer', 'electronics', 'show', 'in', 'las', 'vegas', 'to', 'discuss', 'how', 'these', 'new', 'technologies', 'will', 'impact', 'one', 'of', 'our', 'favourite', 'pastimes', '.', 'with', 'the', 'us', 'leading', 'the', 'trend', 'programmes', 'and', 'other', 'content', 'will', 'be', 'delivered', 'to', 'viewers', 'via', 'home', 'networks', 'through', 'cable', 'satellite', 'telecoms', 'companies', 'and', 'broadband', 'service', 'providers', 'to', 'front', 'rooms', 'and']\n"
     ]
    }
   ],
   "source": [
    "word = []\n",
    "for file_id in report:\n",
    "    words = word_tokenize(file_id)\n",
    "    word.extend(words)\n",
    "print(word[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aleHavwG1Ihn"
   },
   "source": [
    "## 3.2.Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_zs1dFOIxJxu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tv', 'future', 'in', 'the', 'hands', 'of', 'viewers', 'with', 'home', 'theatre', 'systems', 'plasma', 'high-definition', 'tvs', 'and', 'digital', 'video', 'recorders', 'moving', 'into', 'the', 'living', 'room', 'the', 'way', 'people', 'watch', 'tv', 'will', 'be', 'radically', 'different', 'in', 'five', 'years', 'time', '.', 'that', 'is', 'according', 'to', 'an', 'expert', 'panel', 'which', 'gathered', 'at', 'the', 'annual', 'consumer', 'electronics', 'show', 'in', 'las', 'vegas', 'to', 'discuss', 'how', 'these', 'new', 'technologies', 'will', 'impact', 'one', 'of', 'our', 'favourite', 'pastimes', '.', 'with', 'the', 'us', 'leading', 'the', 'trend', 'programmes', 'and', 'other', 'content', 'will', 'be', 'delivered', 'to', 'viewers', 'via', 'home', 'networks', 'through', 'cable', 'satellite', 'telecoms', 'companies', 'and', 'broadband', 'service', 'providers', 'to', 'front', 'rooms', 'and']\n"
     ]
    }
   ],
   "source": [
    "# See all the words in the file, lexicographically sorted\n",
    "text_tokens = [w.lower() for w in word]\n",
    "print(text_tokens[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFzCpnAr9Bw0"
   },
   "source": [
    "## 3.3.Removing Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V3POzrb2hfU"
   },
   "source": [
    "### 3.3.1.Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kL6ti-96xK_k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ankita singh\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tv', 'future', 'in', 'the', 'hands', 'of', 'viewers', 'with', 'home', 'theatre', 'systems', 'plasma', 'high-definition', 'tvs', 'and', 'digital', 'video', 'recorders', 'moving', 'into', 'the', 'living', 'room', 'the', 'way', 'people', 'watch', 'tv', 'will', 'be', 'radically', 'different', 'in', 'five', 'years', 'time', '.', 'that', 'is', 'according', 'to', 'an', 'expert', 'panel', 'which', 'gathered', 'at', 'the', 'annual', 'consumer', 'electronics', 'show', 'in', 'las', 'vegas', 'to', 'discuss', 'how', 'these', 'new', 'technologies', 'will', 'impact', 'one', 'of', 'our', 'favourite', 'pastimes', '.', 'with', 'the', 'us', 'leading', 'the', 'trend', 'programmes', 'and', 'other', 'content', 'will', 'be', 'delivered', 'to', 'viewers', 'via', 'home', 'networks', 'through', 'cable', 'satellite', 'telecoms', 'companies', 'and', 'broadband', 'service', 'providers', 'to', 'front', 'rooms', 'and']\n",
      "['tv', 'future', 'in', 'the', 'hands', 'of', 'viewers', 'with', 'home', 'theatre', 'systems', 'plasma', 'high-definition', 'tvs', 'and', 'digital', 'video', 'recorders', 'moving', 'into', 'the', 'living', 'room', 'the', 'way', 'people', 'watch', 'tv', 'will', 'be', 'radically', 'different', 'in', 'five', 'years', 'time', '.', 'that', 'is', 'according', 'to', 'an', 'expert', 'panel', 'which', 'gathered', 'at', 'the', 'annual', 'consumer', 'electronics', 'show', 'in', 'las', 'vegas', 'to', 'discuss', 'how', 'these', 'new', 'technologies', 'will', 'impact', 'one', 'of', 'our', 'favourite', 'pastimes', '.', 'with', 'the', 'us', 'leading', 'the', 'trend', 'programmes', 'and', 'other', 'content', 'will', 'be', 'delivered', 'to', 'viewers', 'via', 'home', 'networks', 'through', 'cable', 'satellite', 'telecoms', 'companies', 'and', 'broadband', 'service', 'providers', 'to', 'front', 'rooms', 'and']\n"
     ]
    }
   ],
   "source": [
    "# Remove Punctuation\n",
    "  \n",
    "#stop_words = set(stopwords.words('english')) \n",
    "puncList = [\";\",\":\",\"!\",\"?\",\"/\",\"\\\\\",\",\",\"#\",\"@\",\"$\",\"&\",\")\",\"(\",\"\\\"\"]\n",
    "\n",
    "#word_tokens = word_tokenize(text_tokens) \n",
    "  \n",
    "filtered_sentence = [w for w in text_tokens if not w in puncList] \n",
    "  \n",
    "Punc_filtered_sentence = [] \n",
    "  \n",
    "for w in text_tokens: \n",
    "    if w not in puncList: \n",
    "        Punc_filtered_sentence.append(w) \n",
    "  \n",
    "print(text_tokens[0:100]) \n",
    "print(Punc_filtered_sentence[0:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdaaR23Z1Kop"
   },
   "source": [
    "### 3.3.2.Removing the Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AOcu1P7ixNX9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ankita singh\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "    \n",
    "stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "filtered_sentence = [w for w in Punc_filtered_sentence if not w in stop_words] \n",
    "  \n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnQytxul1N7Z"
   },
   "source": [
    "## 3.4.Stemming & Lemitization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOCGBspF1VNJ"
   },
   "source": [
    "### 3.4.1.Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XBaiiRIsxRJe"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "filtered_sentence = list(map(lambda x : porter.stem(x),filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBHm5uBT1XAQ"
   },
   "source": [
    "### 3.4.2.Lemitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JaLCbX_IxTH6"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemitization\n",
    "filtered_sentence = list(map(lambda x : lancaster.stem(x),filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiB_pZw61Sb6"
   },
   "source": [
    "## 3.5.PoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xDEl_rnhxVMH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ankita singh S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tv', 'NN'),\n",
       " ('fut', 'NNS'),\n",
       " ('hand', 'NN'),\n",
       " ('view', 'NN'),\n",
       " ('hom', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('system', 'NN'),\n",
       " ('plasm', 'JJ'),\n",
       " ('high-definit', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('digit', 'NN'),\n",
       " ('video', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('mov', 'NN'),\n",
       " ('liv', 'JJ'),\n",
       " ('room', 'NN'),\n",
       " ('way', 'NN'),\n",
       " ('peopl', 'JJ'),\n",
       " ('watch', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('rad', 'NN'),\n",
       " ('diff', 'NN'),\n",
       " ('fiv', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('tim', 'NN'),\n",
       " ('.', '.'),\n",
       " ('accord', 'NN'),\n",
       " ('expert', 'JJ'),\n",
       " ('panel', 'NN'),\n",
       " ('gath', 'NN'),\n",
       " ('an', 'DT'),\n",
       " ('cons', 'NNS'),\n",
       " ('electron', 'VBP'),\n",
       " ('show', 'NN'),\n",
       " ('la', 'NN'),\n",
       " ('veg', 'FW'),\n",
       " ('discuss', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('technolog', 'NN'),\n",
       " ('impact', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('favourit', 'NN'),\n",
       " ('pastim', 'NN'),\n",
       " ('.', '.'),\n",
       " ('us', 'PRP'),\n",
       " ('lead', 'JJ'),\n",
       " ('trend', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('cont', 'JJ'),\n",
       " ('del', 'NN'),\n",
       " ('view', 'NN'),\n",
       " ('via', 'IN'),\n",
       " ('hom', 'NN'),\n",
       " ('network', 'NN'),\n",
       " ('cabl', 'NN'),\n",
       " ('satellit', 'NN'),\n",
       " ('telecom', 'NN'),\n",
       " ('compan', 'NN'),\n",
       " ('broadband', 'VBP'),\n",
       " ('serv', 'NN'),\n",
       " ('provid', 'NN'),\n",
       " ('front', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('port', 'NN'),\n",
       " ('dev', 'NN'),\n",
       " ('.', '.'),\n",
       " ('on', 'IN'),\n",
       " ('talked-about', 'JJ'),\n",
       " ('technolog', 'NN'),\n",
       " ('ce', 'NN'),\n",
       " ('digit', 'JJ'),\n",
       " ('person', 'NN'),\n",
       " ('video', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('dvr', 'NN'),\n",
       " ('pvr', 'NN'),\n",
       " ('.', '.'),\n",
       " ('set-top', 'JJ'),\n",
       " ('box', 'NN'),\n",
       " ('lik', 'VBZ'),\n",
       " ('us', 'PRP'),\n",
       " ('tivo', 'VB'),\n",
       " ('uk', 'JJ'),\n",
       " ('sky+', 'NN'),\n",
       " ('system', 'NN'),\n",
       " ('allow', 'JJ'),\n",
       " ('peopl', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('stor', 'NN'),\n",
       " ('play', 'NN'),\n",
       " ('pau', 'VBZ'),\n",
       " ('forward', 'RB'),\n",
       " ('wind', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('essent', 'JJ'),\n",
       " ('technolog', 'NN'),\n",
       " ('allow', 'VB'),\n",
       " ('much', 'JJ'),\n",
       " ('person', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('.', '.'),\n",
       " ('also', 'RB'),\n",
       " ('built-in', 'JJ'),\n",
       " ('high-definit', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('set', 'VBN'),\n",
       " ('big', 'JJ'),\n",
       " ('bus', 'NN'),\n",
       " ('jap', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('slow', 'JJ'),\n",
       " ('tak', 'NN'),\n",
       " ('europ', 'NN'),\n",
       " ('lack', 'VBP'),\n",
       " ('high-definit', 'JJ'),\n",
       " ('program', 'NN'),\n",
       " ('.', '.'),\n",
       " ('peopl', 'VB'),\n",
       " ('forward', 'RB'),\n",
       " ('wind', 'NN'),\n",
       " ('advert', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('forget', 'VB'),\n",
       " ('abid', 'NN'),\n",
       " ('network', 'NN'),\n",
       " ('channel', 'NN'),\n",
       " ('schedul', 'NN'),\n",
       " ('put', 'VBD'),\n",
       " ('toge', 'JJ'),\n",
       " ('a-la-cart', 'JJ'),\n",
       " ('entertain', 'NN'),\n",
       " ('.', '.'),\n",
       " ('us', 'PRP'),\n",
       " ('network', 'NN'),\n",
       " ('cabl', 'NN'),\n",
       " ('satellit', 'NN'),\n",
       " ('compan', 'NN'),\n",
       " ('worr', 'VBP'),\n",
       " ('mean', 'JJ'),\n",
       " ('term', 'NN'),\n",
       " ('advert', 'NN'),\n",
       " ('revenu', 'NN'),\n",
       " ('wel', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('id', 'NN'),\n",
       " ('view', 'NN'),\n",
       " ('loyalt', 'JJ'),\n",
       " ('channel', 'NN'),\n",
       " ('.', '.'),\n",
       " ('although', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('lead', 'VBP'),\n",
       " ('technolog', 'JJ'),\n",
       " ('mom', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('concern', 'NN'),\n",
       " ('rai', 'JJ'),\n",
       " ('europ', 'NN'),\n",
       " ('particularl', 'NN'),\n",
       " ('grow', 'VB'),\n",
       " ('uptak', 'JJ'),\n",
       " ('serv', 'NN'),\n",
       " ('lik', 'NN'),\n",
       " ('sky+', 'NN'),\n",
       " ('.', '.'),\n",
       " ('hap', 'NN'),\n",
       " ('today', 'NN'),\n",
       " ('see', 'VBP'),\n",
       " ('nin', 'RB'),\n",
       " ('mon', 'JJ'),\n",
       " ('year', 'NN'),\n",
       " ('tim', 'NN'),\n",
       " ('uk', 'JJ'),\n",
       " ('adam', 'NN'),\n",
       " ('hum', 'NN'),\n",
       " ('bbc', 'NN'),\n",
       " ('broadcast', 'NN'),\n",
       " ('futurolog', 'NN'),\n",
       " ('told', 'VBD'),\n",
       " ('bbc', 'JJ'),\n",
       " ('new', 'JJ'),\n",
       " ('websit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('lik', 'JJ'),\n",
       " ('bbc', 'NN'),\n",
       " ('issu', 'NN'),\n",
       " ('lost', 'VBD'),\n",
       " ('advert', 'JJ'),\n",
       " ('revenu', 'NN'),\n",
       " ('yet', 'RB'),\n",
       " ('.', '.'),\n",
       " ('press', 'NN'),\n",
       " ('issu', 'JJ'),\n",
       " ('mom', 'NN'),\n",
       " ('commerc', 'NN'),\n",
       " ('uk', 'JJ'),\n",
       " ('broadcast', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('loyalt', 'NN'),\n",
       " ('import', 'NN'),\n",
       " ('everyon', 'NN'),\n",
       " ('.', '.'),\n",
       " ('talk', 'NN'),\n",
       " ('cont', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('rath', 'NN'),\n",
       " ('network', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('tim', 'JJ'),\n",
       " ('hanlon', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('commun', 'NN'),\n",
       " ('firm', 'NN'),\n",
       " ('starcom', 'VBD'),\n",
       " ('mediavest', 'JJS'),\n",
       " ('.', '.'),\n",
       " ('realit', 'NN'),\n",
       " ('broadband', 'NN'),\n",
       " ('connect', 'NN'),\n",
       " ('anybod', 'NN'),\n",
       " ('produc', 'NN'),\n",
       " ('cont', 'NN'),\n",
       " ('.', '.'),\n",
       " ('ad', 'NN'),\n",
       " ('challeng', 'NN'),\n",
       " ('hard', 'JJ'),\n",
       " ('promot', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('much', 'JJ'),\n",
       " ('cho', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mean', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('stacey', 'JJ'),\n",
       " ('joln', 'NN'),\n",
       " ('seny', 'NN'),\n",
       " ('vic', 'NN'),\n",
       " ('presid', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('guid', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('group', 'NN'),\n",
       " ('way', 'NN'),\n",
       " ('peopl', 'IN'),\n",
       " ('find', 'VBP'),\n",
       " ('cont', 'JJ'),\n",
       " ('want', 'VBP'),\n",
       " ('watch', 'NN'),\n",
       " ('simplif', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('view', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mean', 'NN'),\n",
       " ('network', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('term', 'NN'),\n",
       " ('channel', 'NN'),\n",
       " ('could', 'MD'),\n",
       " ('tak', 'VB'),\n",
       " ('leaf', 'JJ'),\n",
       " ('googl', 'NNS'),\n",
       " ('book', 'NN'),\n",
       " ('search', 'NN'),\n",
       " ('engin', 'VBP'),\n",
       " ('fut', 'VBN'),\n",
       " ('instead', 'RB'),\n",
       " ('schedul', 'VB'),\n",
       " ('help', 'NN'),\n",
       " ('peopl', 'VB'),\n",
       " ('find', 'VB'),\n",
       " ('want', 'JJ'),\n",
       " ('watch', 'NN'),\n",
       " ('.', '.'),\n",
       " ('kind', 'NN'),\n",
       " ('channel', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('work', 'VB'),\n",
       " ('young', 'JJ'),\n",
       " ('ipod', 'NNS'),\n",
       " ('gen', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('tak', 'VB'),\n",
       " ('control', 'NN'),\n",
       " ('gadget', 'NN'),\n",
       " ('play', 'NN'),\n",
       " ('.', '.'),\n",
       " ('might', 'MD'),\n",
       " ('suit', 'VB'),\n",
       " ('everyon', 'JJ'),\n",
       " ('panel', 'NN'),\n",
       " ('recogn', 'NN'),\n",
       " ('.', '.'),\n",
       " ('old', 'JJ'),\n",
       " ('gen', 'NN'),\n",
       " ('comfort', 'NN'),\n",
       " ('famili', 'NN'),\n",
       " ('schedul', 'NN'),\n",
       " ('channel', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('get', 'NN'),\n",
       " ('.', '.'),\n",
       " ('perhap', 'VB'),\n",
       " ('want', 'JJ'),\n",
       " ('much', 'JJ'),\n",
       " ('cho', 'NN'),\n",
       " ('put', 'VBD'),\n",
       " ('hand', 'NN'),\n",
       " ('mr', 'NN'),\n",
       " ('hanlon', 'NN'),\n",
       " ('suggest', 'NN'),\n",
       " ('.', '.'),\n",
       " ('end', 'VB'),\n",
       " ('kid', 'NN'),\n",
       " ('diap', 'NN'),\n",
       " ('push', 'NN'),\n",
       " ('button', 'NN'),\n",
       " ('alread', 'SYM'),\n",
       " ('-', ':'),\n",
       " ('every', 'DT'),\n",
       " ('poss', 'NN'),\n",
       " ('avail', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('mr', 'JJ'),\n",
       " ('hanlon', 'NN'),\n",
       " ('.', '.'),\n",
       " ('ultim', 'JJ'),\n",
       " ('cons', 'NNS'),\n",
       " ('tel', 'VBP'),\n",
       " ('market', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('.', '.'),\n",
       " ('50', 'CD'),\n",
       " ('000', 'CD'),\n",
       " ('new', 'JJ'),\n",
       " ('gadget', 'NN'),\n",
       " ('technolog', 'NN'),\n",
       " ('showca', 'NN'),\n",
       " ('ce', 'NN'),\n",
       " ('man', 'NN'),\n",
       " ('enh', 'VBZ'),\n",
       " ('tv-watch', 'JJ'),\n",
       " ('exper', 'NN'),\n",
       " ('.', '.'),\n",
       " ('high-definit', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('set', 'VBN'),\n",
       " ('everywh', 'RB'),\n",
       " ('man', 'NN'),\n",
       " ('new', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('lcd', 'NN'),\n",
       " ('liquid', 'JJ'),\n",
       " ('cryst', 'NN'),\n",
       " ('display', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('launch', 'NN'),\n",
       " ('dvr', 'NN'),\n",
       " ('cap', 'NN'),\n",
       " ('built', 'VBN'),\n",
       " ('instead', 'RB'),\n",
       " ('extern', 'JJ'),\n",
       " ('box', 'NN'),\n",
       " ('.', '.'),\n",
       " ('on', 'IN'),\n",
       " ('exampl', 'JJ'),\n",
       " ('launch', 'NN'),\n",
       " ('show', 'NN'),\n",
       " ('humax', 'JJ'),\n",
       " ('26-inch', 'JJ'),\n",
       " ('lcd', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('80-hour', 'CD'),\n",
       " ('tivo', 'NN'),\n",
       " ('dvr', 'NN'),\n",
       " ('dvd', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('.', '.'),\n",
       " ('on', 'IN'),\n",
       " ('us', 'PRP'),\n",
       " ('biggest', 'JJS'),\n",
       " ('satellit', 'JJ'),\n",
       " ('tv', 'NN'),\n",
       " ('compan', 'NN'),\n",
       " ('directtv', 'NN'),\n",
       " ('ev', 'NN'),\n",
       " ('launch', 'NN'),\n",
       " ('brand', 'NN'),\n",
       " ('dvr', 'NN'),\n",
       " ('show', 'VB'),\n",
       " ('100-hour', 'JJ'),\n",
       " ('record', 'NN'),\n",
       " ('cap', 'NN'),\n",
       " ('inst', 'VBP'),\n",
       " ('replay', 'NN'),\n",
       " ('search', 'NN'),\n",
       " ('funct', 'NN'),\n",
       " ('.', '.'),\n",
       " ('set', 'VBN'),\n",
       " ('pau', 'NN'),\n",
       " ('rewind', 'NN'),\n",
       " ('tv', 'NN'),\n",
       " ('90', 'CD'),\n",
       " ('hour', 'NN'),\n",
       " ('.', '.'),\n",
       " ('microsoft', 'JJ'),\n",
       " ('chief', 'JJ'),\n",
       " ('bil', 'NN'),\n",
       " ('gat', 'NN'),\n",
       " ('annount', 'NN'),\n",
       " ('pre-show', 'NN'),\n",
       " ('keynot', 'NN'),\n",
       " ('speech', 'NN'),\n",
       " ('partn', 'NN'),\n",
       " ('tivo', 'JJ'),\n",
       " ('cal', 'JJ'),\n",
       " ('tivotogo', 'NN'),\n",
       " ('mean', 'NN'),\n",
       " ('peopl', 'NN'),\n",
       " ('play', 'NN'),\n",
       " ('record', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('window', 'JJ'),\n",
       " ('pc', 'NN'),\n",
       " ('mobl', 'NN'),\n",
       " ('dev', 'NN'),\n",
       " ('.', '.'),\n",
       " ('reflect', 'VB'),\n",
       " ('increa', 'JJ'),\n",
       " ('trend', 'NN'),\n",
       " ('fre', 'NN'),\n",
       " ('multimed', 'VBD'),\n",
       " ('peopl', 'JJ'),\n",
       " ('watch', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('want', 'NN'),\n",
       " ('.', '.'),\n",
       " ('worldcom', 'VB'),\n",
       " ('boss', 'NN'),\n",
       " ('left', 'VBD'),\n",
       " ('book', 'NN'),\n",
       " ('alon', 'NN'),\n",
       " ('form', 'NN'),\n",
       " ('worldcom', 'NN'),\n",
       " ('boss', 'IN'),\n",
       " ('bern', 'JJ'),\n",
       " ('eb', 'NN'),\n",
       " ('acc', 'NN'),\n",
       " ('overs', 'NNS'),\n",
       " ('11bn', 'CD'),\n",
       " ('£5.8bn', 'JJ'),\n",
       " ('fraud', 'NN'),\n",
       " ('nev', 'JJ'),\n",
       " ('mad', 'NN'),\n",
       " ('account', 'NN'),\n",
       " ('dec', 'NN'),\n",
       " ('wit', 'NN'),\n",
       " ('told', 'VBD'),\n",
       " ('jur', 'NN'),\n",
       " ('.', '.'),\n",
       " ('david', 'VB'),\n",
       " ('myer', 'NN'),\n",
       " ('mad', 'JJ'),\n",
       " ('com', 'NN'),\n",
       " ('quest', 'JJS'),\n",
       " ('def', 'NN'),\n",
       " ('lawy', 'NN'),\n",
       " ('argu', 'NN'),\n",
       " ('mr', 'NN'),\n",
       " ('eb', 'VBP'),\n",
       " ('respon', 'NN'),\n",
       " ('worldcom', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('.', '.'),\n",
       " ('phon', 'NN'),\n",
       " ('compan', 'NN'),\n",
       " ('collap', 'NN'),\n",
       " ('2002', 'CD'),\n",
       " ('prosecut', 'NN'),\n",
       " ('claim', 'NN'),\n",
       " ('loss', 'NN'),\n",
       " ('hid', 'NN'),\n",
       " ('protect', 'JJ'),\n",
       " ('firm', 'NN'),\n",
       " ('shar', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mr', 'CC'),\n",
       " ('myer', 'JJ'),\n",
       " ('alread', 'JJ'),\n",
       " ('plead', 'NN'),\n",
       " ('guilt', 'NN'),\n",
       " ('fraud', 'NN'),\n",
       " ('assist', 'NN'),\n",
       " ('prosecut', 'NN'),\n",
       " ('.', '.'),\n",
       " ('monday', 'JJ'),\n",
       " ('def', 'JJ'),\n",
       " ('lawy', 'NN'),\n",
       " ('reid', 'NN'),\n",
       " ('weingart', 'NN'),\n",
       " ('tri', 'NN'),\n",
       " ('dist', 'NN'),\n",
       " ('cli', 'NN'),\n",
       " ('alleg', 'NN'),\n",
       " ('.', '.'),\n",
       " ('cross', 'NN'),\n",
       " ('examin', 'NN'),\n",
       " ('ask', 'NN'),\n",
       " ('mr', 'NN'),\n",
       " ('myer', 'NN'),\n",
       " ('ev', 'VBP'),\n",
       " ('knew', 'VBN'),\n",
       " ('mr', 'JJ'),\n",
       " ('eb', 'NN'),\n",
       " ('mak', 'NN'),\n",
       " ('account', 'NN'),\n",
       " ('dec', 'NN'),\n",
       " ('.', '.'),\n",
       " ('aw', 'JJ'),\n",
       " ('mr', 'JJ'),\n",
       " ('myer', 'NN'),\n",
       " ('repl', 'NN'),\n",
       " ('.', '.'),\n",
       " ('ev', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('mr', 'NN'),\n",
       " ('eb', 'JJ'),\n",
       " ('mak', 'NN'),\n",
       " ('account', 'NN'),\n",
       " ('entr', 'VBD'),\n",
       " ('worldcom', 'JJ'),\n",
       " ('book', 'NN'),\n",
       " ('mr', 'JJ'),\n",
       " ('weingart', 'JJ'),\n",
       " ('press', 'NN'),\n",
       " ('.', '.'),\n",
       " ('repl', 'JJ'),\n",
       " ('wit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mr', 'CC'),\n",
       " ('myer', 'JJ'),\n",
       " ('admit', 'NN'),\n",
       " ('ord', 'NN'),\n",
       " ('fal', 'NN'),\n",
       " ('account', 'NN'),\n",
       " ('entr', 'JJ'),\n",
       " ('request', 'NN'),\n",
       " ('form', 'NN'),\n",
       " ('worldcom', 'NN'),\n",
       " ('chief', 'JJ'),\n",
       " ('financ', 'NN'),\n",
       " ('off', 'IN'),\n",
       " ('scot', 'NN'),\n",
       " ('sul', 'NN'),\n",
       " ('.', '.'),\n",
       " ('def', 'NN'),\n",
       " ('lawy', 'JJ'),\n",
       " ('tri', 'NN'),\n",
       " ('paint', 'NN'),\n",
       " ('mr', 'NN'),\n",
       " ('sul', 'NN'),\n",
       " ('admit', 'NN'),\n",
       " ('fraud', 'NN'),\n",
       " ('testif', 'NN'),\n",
       " ('lat', 'JJ'),\n",
       " ('tri', 'NN'),\n",
       " ('mastermind', 'NN'),\n",
       " ('behind', 'IN'),\n",
       " ('worldcom', 'JJ'),\n",
       " ('account', 'NN'),\n",
       " ('hou', 'JJ'),\n",
       " ('card', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mr', 'NN'),\n",
       " ('eb', 'NN'),\n",
       " ('team', 'NN'),\n",
       " ('meanwhil', 'NN'),\n",
       " ('look', 'NN'),\n",
       " ('portray', 'JJ'),\n",
       " ('aff', 'NN'),\n",
       " ('boss', 'IN'),\n",
       " ('admiss', 'JJ'),\n",
       " ('pe', 'NN'),\n",
       " ('gradu', 'NN'),\n",
       " ('econom', 'NN'),\n",
       " ('.', '.'),\n",
       " ('whatev', 'NN'),\n",
       " ('abl', 'NN'),\n",
       " ('mr', 'NN'),\n",
       " ('eb', 'NN'),\n",
       " ('transform', 'NN'),\n",
       " ('worldcom', 'NN'),\n",
       " ('rel', 'VBD'),\n",
       " ('unknown', 'JJ'),\n",
       " ('160bn', 'CD'),\n",
       " ('telecom', 'NN'),\n",
       " ('giant', 'NN'),\n",
       " ('invest', 'VB'),\n",
       " ('darl', 'NN'),\n",
       " ('lat', 'JJ'),\n",
       " ('1990', 'CD'),\n",
       " ('.', '.'),\n",
       " ('worldcom', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('mount', 'NN'),\n",
       " ('howev', 'NN'),\n",
       " ('competit', 'NN'),\n",
       " ('increa', 'NN'),\n",
       " ('telecom', 'NN'),\n",
       " ('boom', 'NN'),\n",
       " ('pet', 'NN'),\n",
       " ('.', '.'),\n",
       " ('firm', 'NN'),\n",
       " ('fin', 'VBD'),\n",
       " ('collap', 'NNS'),\n",
       " ('sharehold', 'VBD'),\n",
       " ('lost', 'VBD'),\n",
       " ('180bn', 'CD'),\n",
       " ('20', 'CD'),\n",
       " ('000', 'CD'),\n",
       " ('work', 'NN'),\n",
       " ('lost', 'VBN'),\n",
       " ('job', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mr', 'NN'),\n",
       " ('eb', 'NN'),\n",
       " ('tri', 'NN'),\n",
       " ('expect', 'VBP'),\n",
       " ('last', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('mon', 'NN'),\n",
       " ('found', 'VBD'),\n",
       " ('guilt', 'JJ'),\n",
       " ('form', 'NN'),\n",
       " ('ceo', 'NN'),\n",
       " ('fac', 'NN'),\n",
       " ('substant', 'JJ'),\n",
       " ('jail', 'NN'),\n",
       " ('sent', 'NN'),\n",
       " ('.', '.'),\n",
       " ('firml', 'NN'),\n",
       " ('decl', 'NN'),\n",
       " ('innoc', 'NN'),\n",
       " ('.', '.'),\n",
       " ('tig', 'JJ'),\n",
       " ('war', 'NN'),\n",
       " ('farrel', 'NN'),\n",
       " ('gambl', 'NN'),\n",
       " ('leicest', 'JJS'),\n",
       " ('say', 'VBP'),\n",
       " ('rush', 'JJ'),\n",
       " ('mak', 'NN'),\n",
       " ('bid', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('farrel', 'NN'),\n",
       " ('gre', 'NN'),\n",
       " ('britain', 'NN'),\n",
       " ('rugb', 'NN'),\n",
       " ('leagu', 'NN'),\n",
       " ('captain', 'NN'),\n",
       " ('decid', 'JJ'),\n",
       " ('switch', 'NN'),\n",
       " ('cod', 'NN'),\n",
       " ('.', '.'),\n",
       " ('anybod', 'JJ'),\n",
       " ('el', 'JJ'),\n",
       " ('involv', 'NN'),\n",
       " ('process', 'NN'),\n",
       " ('stil', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('away', 'RB'),\n",
       " ('go', 'VBP'),\n",
       " ('next', 'JJ'),\n",
       " ('stag', 'NN'),\n",
       " ('tig', 'NN'),\n",
       " ('boss', 'IN'),\n",
       " ('john', 'NN'),\n",
       " ('wel', 'NN'),\n",
       " ('told', 'VBD'),\n",
       " ('bbc', 'JJ'),\n",
       " ('radio', 'NN'),\n",
       " ('leicest', 'JJS'),\n",
       " ('.', '.'),\n",
       " ('mom', 'NN'),\n",
       " ('stil', 'NN'),\n",
       " ('lot', 'NN'),\n",
       " ('unknown', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('farrel', 'JJ'),\n",
       " ('least', 'NN'),\n",
       " ('med', 'VBD'),\n",
       " ('situ', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('whoev', 'NN'),\n",
       " ('tak', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('tak', 'RB'),\n",
       " ('big', 'JJ'),\n",
       " ('big', 'JJ'),\n",
       " ('gambl', 'NN'),\n",
       " ('.', '.'),\n",
       " ('farrel', 'JJ'),\n",
       " ('persist', 'NN'),\n",
       " ('kne', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('op', 'NN'),\n",
       " ('kne', 'NN'),\n",
       " ('fiv', 'NN'),\n",
       " ('week', 'NN'),\n",
       " ('ago', 'RB'),\n",
       " ('expect', 'VBP'),\n",
       " ('ano', 'NN'),\n",
       " ('three', 'CD'),\n",
       " ('mon', 'NN'),\n",
       " ('.', '.'),\n",
       " ('leicest', 'JJS'),\n",
       " ('sarac', 'NN'),\n",
       " ('believ', 'NN'),\n",
       " ('head', 'NN'),\n",
       " ('list', 'NN'),\n",
       " ('rugb', 'NN'),\n",
       " ('un', 'JJ'),\n",
       " ('club', 'NN'),\n",
       " ('interest', 'NN'),\n",
       " ('sign', 'NN'),\n",
       " ('farrel', 'NN'),\n",
       " ('decid', 'NN'),\n",
       " ('mov', 'VBD'),\n",
       " ('15-man', 'JJ'),\n",
       " ('gam', 'NN'),\n",
       " ('.', '.'),\n",
       " ('mov', 'NN'),\n",
       " ('across', 'IN'),\n",
       " ('un', 'JJ'),\n",
       " ('wel', 'NN'),\n",
       " ('believ', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('bet', 'VB'),\n",
       " ('play', 'VB'),\n",
       " ('back', 'RB'),\n",
       " ('least', 'JJS'),\n",
       " ('init', 'NN'),\n",
       " ('.', '.'),\n",
       " ('sur', 'NN'),\n",
       " ('could', 'MD'),\n",
       " ('mak', 'VB'),\n",
       " ('step', 'VB'),\n",
       " ('leagu', 'JJ'),\n",
       " ('un', 'JJ'),\n",
       " ('involv', 'NN'),\n",
       " ('cent', 'NN'),\n",
       " ('said', 'VBD'),\n",
       " ('wel', 'NN'),\n",
       " ('.', '.'),\n",
       " ('think', 'NN'),\n",
       " ('england', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('pref', 'VB'),\n",
       " ('progress', 'NN'),\n",
       " ('posit', 'NN'),\n",
       " ('back', 'RB'),\n",
       " ('row', 'NN'),\n",
       " ('mak', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('rugb', 'VBP'),\n",
       " ('leagu', 'JJ'),\n",
       " ('skil', 'NN'),\n",
       " ('within', 'IN'),\n",
       " ('forward', 'RB'),\n",
       " ('.', '.'),\n",
       " ('jur', 'NN'),\n",
       " ('wheth', 'VBZ'),\n",
       " ('cross', 'NN'),\n",
       " ('divid', 'NN'),\n",
       " ('.', '.'),\n",
       " ('club', 'NN'),\n",
       " ('bal', 'JJ'),\n",
       " ('struck', 'NN'),\n",
       " ('cost', 'NN'),\n",
       " ('gambl', 'NN'),\n",
       " ('opt', 'IN'),\n",
       " ('bring', 'VBG'),\n",
       " ('ready-mad', 'JJ'),\n",
       " ('replac', 'NN'),\n",
       " ('.', '.'),\n",
       " ('yead', 'JJ'),\n",
       " ('fac', 'NN'),\n",
       " ('newcastl', 'NN'),\n",
       " ('fa', 'JJ'),\n",
       " ('cup', 'NN'),\n",
       " ('premy', 'NN'),\n",
       " ('sid', 'NN'),\n",
       " ('newcastl', 'JJ'),\n",
       " ('unit', 'NN'),\n",
       " ('fac', 'JJ'),\n",
       " ('trip', 'NN'),\n",
       " ('rym', 'NN'),\n",
       " ('premy', 'NN'),\n",
       " ('leagu', 'JJ'),\n",
       " ('lead', 'NN'),\n",
       " ('yead', 'NN'),\n",
       " ('fa', 'JJ'),\n",
       " ('cup', 'NN'),\n",
       " ('third', 'JJ'),\n",
       " ('round', 'NN'),\n",
       " ('.', '.'),\n",
       " ('gam', 'SYM'),\n",
       " ('-', ':'),\n",
       " ('argu', 'NN'),\n",
       " ('highlight', 'NN'),\n",
       " ('draw', 'SYM'),\n",
       " ('-', ':'),\n",
       " ('potent', 'JJ'),\n",
       " ('money-spinn', 'JJ'),\n",
       " ('non-leagu', 'JJ'),\n",
       " ('yead', 'NN'),\n",
       " ('beat', 'VBD'),\n",
       " ('slough', 'JJ'),\n",
       " ('second', 'JJ'),\n",
       " ('round', 'NN'),\n",
       " ('.', '.'),\n",
       " ('conf', 'NN'),\n",
       " ('sid', 'NN'),\n",
       " ('exet', 'NN'),\n",
       " ('cit', 'NN'),\n",
       " ('knock', 'NN'),\n",
       " ('doncast', 'NN'),\n",
       " ('saturday', 'NN'),\n",
       " ('travel', 'VBP'),\n",
       " ('old', 'JJ'),\n",
       " ('trafford', 'NN'),\n",
       " ('meet', 'NN'),\n",
       " ('hold', 'VBP'),\n",
       " ('manchest', 'JJS'),\n",
       " ('unit', 'NN'),\n",
       " ('januar', 'NN'),\n",
       " ('.', '.'),\n",
       " ('ars', 'NNS'),\n",
       " ('drawn', 'VBP'),\n",
       " ('hom', 'JJ'),\n",
       " ('stok', 'NN'),\n",
       " ('chelse', 'JJ'),\n",
       " ('play', 'NN'),\n",
       " ('host', 'NN'),\n",
       " ('scunthorp', 'NN'),\n",
       " ('.', '.'),\n",
       " ('non-leagu', 'JJ'),\n",
       " ('sid', 'NN'),\n",
       " ('draw', 'NN'),\n",
       " ('hinckley', 'NN'),\n",
       " ('unit', 'NN'),\n",
       " ('held', 'VBD'),\n",
       " ('brentford', 'JJ'),\n",
       " ('goalless', 'NN'),\n",
       " ('draw', 'NN'),\n",
       " ('sunday', 'NN'),\n",
       " ('.', '.'),\n",
       " ('meet', 'VB'),\n",
       " ('leagu', 'JJ'),\n",
       " ('on', 'IN'),\n",
       " ('lead', 'JJ'),\n",
       " ('luton', 'NN'),\n",
       " ('win', 'VBP'),\n",
       " ('replay', 'NN'),\n",
       " ('martin', 'NN'),\n",
       " ('al', 'NN'),\n",
       " ('team', 'NN'),\n",
       " ('griffin', 'NN'),\n",
       " ('park', 'NN'),\n",
       " ('.', '.'),\n",
       " ('numb', 'JJ'),\n",
       " ('premy', 'NN'),\n",
       " ('team', 'NN'),\n",
       " ('fac', 'NN'),\n",
       " ('difficult', 'JJ'),\n",
       " ('away', 'RB'),\n",
       " ('gam', 'JJ'),\n",
       " ('champ', 'NN'),\n",
       " ('sid', 'NN'),\n",
       " ('weekend', 'NN'),\n",
       " ('8/9', 'CD'),\n",
       " ('januar', 'NN'),\n",
       " ('.', '.'),\n",
       " ('third-plac', 'JJ'),\n",
       " ('everton', 'JJ'),\n",
       " ('visit', 'NN'),\n",
       " ('plymou', 'NN'),\n",
       " ('liverpool', 'NN'),\n",
       " ('travel', 'NN'),\n",
       " ('burnley', 'NN'),\n",
       " ('cryst', 'NN'),\n",
       " ('palac', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('sunderland', 'NN'),\n",
       " ('fulham', 'NN'),\n",
       " ('fac', 'VBP'),\n",
       " ('carl', 'JJ'),\n",
       " ('cup', 'NN'),\n",
       " ('semi-finalist', 'JJ'),\n",
       " ('watford', 'NN'),\n",
       " ('bolton', 'NN'),\n",
       " ('meet', 'NN'),\n",
       " ('ipswich', 'JJ'),\n",
       " ('aston', 'NN'),\n",
       " ('vill', 'NN'),\n",
       " ('drawn', 'VBN'),\n",
       " ('sheffield', 'JJ'),\n",
       " ('unit', 'NN'),\n",
       " ('.', '.'),\n",
       " ('premy', 'JJ'),\n",
       " ('struggler', 'NN'),\n",
       " ('norwich', 'JJ'),\n",
       " ('blackburn', 'NN'),\n",
       " ('west', 'JJS'),\n",
       " ('brom', 'IN'),\n",
       " ('away', 'RB'),\n",
       " ('west', 'JJ'),\n",
       " ('ham', 'NN'),\n",
       " ('cardiff', 'NN'),\n",
       " ('preston', 'NN'),\n",
       " ('nor', 'CC'),\n",
       " ('end', 'JJ'),\n",
       " ('respect', 'NN'),\n",
       " ('.', '.'),\n",
       " ('southampton', 'JJ'),\n",
       " ('visit', 'IN'),\n",
       " ('northampton', 'JJ'),\n",
       " ('alread', 'JJ'),\n",
       " ('beat', 'NN'),\n",
       " ('leagu', 'JJ'),\n",
       " ('two', 'CD'),\n",
       " ('sid', 'NN'),\n",
       " ('carl', 'NNS'),\n",
       " ('cup', 'VBP'),\n",
       " ('ear', 'JJ'),\n",
       " ('season', 'NN'),\n",
       " ('.', '.'),\n",
       " ('middlesbrough', 'JJ'),\n",
       " ('drawn', 'NN'),\n",
       " ('away', 'RB'),\n",
       " ('eith', 'JJ'),\n",
       " ('swindon', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('count', 'VB'),\n",
       " ('spur', 'RB'),\n",
       " ('entertain', 'JJ'),\n",
       " ('brighton', 'NN'),\n",
       " ('whit', 'VBD'),\n",
       " ('hart', 'JJ'),\n",
       " ('lan', 'NN'),\n",
       " ('.', '.'),\n",
       " ('ars', 'NNS'),\n",
       " ('v', 'VBP'),\n",
       " ('stok', 'JJ'),\n",
       " ('swindon/nott', 'NN'),\n",
       " ('co', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('middlesbrough', 'IN'),\n",
       " ('man', 'NN'),\n",
       " ('utd', 'JJ'),\n",
       " ('v', 'NN'),\n",
       " ('exet', 'NN'),\n",
       " ('plymou', 'NN'),\n",
       " ('v', 'IN'),\n",
       " ('everton', 'NN'),\n",
       " ('leicest', 'JJS'),\n",
       " ('v', 'NN'),\n",
       " ('blackpool', 'NN'),\n",
       " ('derb', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('wig', 'NN'),\n",
       " ('sunderland', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('cryst', 'NN'),\n",
       " ('palac', 'NN'),\n",
       " ('wolv', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('millw', 'NN'),\n",
       " ('yead', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('newcastl', 'JJ'),\n",
       " ('hul', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('colchest', 'NN'),\n",
       " ('tottenham', 'NN'),\n",
       " ('v', 'IN'),\n",
       " ('brighton', 'NN'),\n",
       " ('read', 'VBN'),\n",
       " ('v', 'IN'),\n",
       " ('stockport/swansea', 'NN'),\n",
       " ('birmingham', 'NN'),\n",
       " ('v', 'NN'),\n",
       " ('lee', 'JJ'),\n",
       " ('hartlepool', 'NN'),\n",
       " ('v', 'IN'),\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-E-qr5NnLc0"
   },
   "source": [
    "## 3.6..Create a word vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "irlSfwqBxWhD"
   },
   "outputs": [],
   "source": [
    "vocabulary= set(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYwBOmda1Bz3"
   },
   "source": [
    "# 4.TF & IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDYmHvCz1lnq"
   },
   "source": [
    "## 4.1.TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "sG6kGU70xX7Z"
   },
   "outputs": [],
   "source": [
    "from six import string_types\n",
    " \n",
    "def word_tf(word, token): \n",
    "    return float(token.count(word)) / len(token)\n",
    " \n",
    "def tf_idf(word, token): \n",
    "    if word not in word_index:\n",
    "        return .0\n",
    "    return word_tf(word, token) * word_idf[word_index[word]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.418342593897672e-05"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tf('town',filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSjxTG6n1u5U"
   },
   "source": [
    "## 4.2.IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MN6w8P7WxZZ-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22039 10788\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary in one pass\n",
    "vocabulary = set(filtered_sentence)\n",
    "word_index = {w: index for index, w in enumerate(vocabulary)}\n",
    "\n",
    "VOCABULARY_SIZE = len(vocabulary)\n",
    "DOCUMENTS_COUNT = len(reuters.fileids())\n",
    " \n",
    "print(VOCABULARY_SIZE, DOCUMENTS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  2. 14. ...  8. 11. 74.]\n",
      "5.572617617555313\n",
      "3.0246979999385784\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_doc_count = np.zeros(VOCABULARY_SIZE)\n",
    "\n",
    "for word in filtered_sentence : \n",
    "  indexes = [word_index[word]] \n",
    "  word_doc_count[indexes] += 1.0\n",
    "\n",
    "print(word_doc_count) \n",
    "\n",
    "word_idf = np.log(DOCUMENTS_COUNT / (1 + word_doc_count).astype(float))\n",
    "\n",
    "print(word_idf[word_index['town']])\n",
    "print(word_idf[word_index['tv']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdMSUxI61wVy"
   },
   "source": [
    "## 4.3.TF & IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NvtFGx03xa89"
   },
   "outputs": [],
   "source": [
    "def tf_idf(word, token): \n",
    "    if word not in word_index:\n",
    "        return .0\n",
    "    return word_tf(word, token) * word_idf[word_index[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00041339586631815143"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf('town',filtered_sentence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Session_1_question_Inclass.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
