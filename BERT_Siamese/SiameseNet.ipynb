{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404351, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404348, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapan\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['is_duplicate'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, random_state=111).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69072</td>\n",
       "      <td>137298</td>\n",
       "      <td>137299</td>\n",
       "      <td>What is cruelest thing your ex has said to you...</td>\n",
       "      <td>What is the kindest thing an ex has said to yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254515</td>\n",
       "      <td>500994</td>\n",
       "      <td>500995</td>\n",
       "      <td>What are the benefits of 8GB RAM over 4GB RAM?</td>\n",
       "      <td>Which laptop is better, one with 1.8ghz and 8G...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191430</td>\n",
       "      <td>377918</td>\n",
       "      <td>377919</td>\n",
       "      <td>How does the StartupBootCamp accelerator partn...</td>\n",
       "      <td>How do accelerate ourselves in a corporate world?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300855</td>\n",
       "      <td>590864</td>\n",
       "      <td>590865</td>\n",
       "      <td>Which is the best gadget to be released in 2016?</td>\n",
       "      <td>What are the best gadgets of 2016?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201376</td>\n",
       "      <td>397382</td>\n",
       "      <td>397383</td>\n",
       "      <td>What is the QuickBooks payroll tech support nu...</td>\n",
       "      <td>What is the QuickBooks technical support phone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0   69072  137298  137299  What is cruelest thing your ex has said to you...   \n",
       "1  254515  500994  500995     What are the benefits of 8GB RAM over 4GB RAM?   \n",
       "2  191430  377918  377919  How does the StartupBootCamp accelerator partn...   \n",
       "3  300855  590864  590865   Which is the best gadget to be released in 2016?   \n",
       "4  201376  397382  397383  What is the QuickBooks payroll tech support nu...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the kindest thing an ex has said to yo...             0  \n",
       "1  Which laptop is better, one with 1.8ghz and 8G...             0  \n",
       "2  How do accelerate ourselves in a corporate world?             0  \n",
       "3                 What are the best gadgets of 2016?             1  \n",
       "4  What is the QuickBooks technical support phone...             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[['question1', 'question2']]\n",
    "# y = data['is_duplicate']\n",
    "\n",
    "X, X_valid, y, y_valid = train_test_split(data[['question1', 'question2']], data['is_duplicate'],\n",
    "                                                    test_size=0.05, \n",
    "                                                    stratify=data['is_duplicate'].values, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384130, 2), (20218, 2), (384130,), (20218,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_valid.shape, y.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.053, \n",
    "                                                    stratify=y.values, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363771, 2), (20359, 2), (363771,), (20359,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data)\n",
    "del(X)\n",
    "del(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363771, 2), (20218, 2), (20359, 2), (363771,), (20218,), (20359,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace = True, drop = True)\n",
    "X_valid.reset_index(inplace = True, drop = True)\n",
    "X_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reset_index(inplace = True, drop=True)\n",
    "y_valid.reset_index(inplace = True, drop=True)\n",
    "y_test.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "363766    1\n",
       "363767    1\n",
       "363768    1\n",
       "363769    1\n",
       "363770    0\n",
       "Name: is_duplicate, Length: 363771, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What do Croats think of Turks?</td>\n",
       "      <td>What do Turks think of Croats?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How will a Trump presidency affect the student...</td>\n",
       "      <td>How will Trump’s presidency affect internation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the best startups ideas in India?</td>\n",
       "      <td>What are some of the best startups ideas for I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I add Instagram stories from Gallery o...</td>\n",
       "      <td>How do you upload pictures from your PC to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By what age should I have had my first kiss?</td>\n",
       "      <td>How do I have my first kiss?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363766</th>\n",
       "      <td>What is the best way to ask a girl out on a date?</td>\n",
       "      <td>How should I ask this girl out?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363767</th>\n",
       "      <td>Is time travel possible in next 5 years?</td>\n",
       "      <td>Is it possible to travel back or forward in time?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363768</th>\n",
       "      <td>I am looking for website promotion. How can I ...</td>\n",
       "      <td>How do I find the best SEO company in Delhi?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363769</th>\n",
       "      <td>What are the good books which will help to kno...</td>\n",
       "      <td>What are some good books to learn more about S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363770</th>\n",
       "      <td>Food and Recipe Websites and Apps: What is an ...</td>\n",
       "      <td>How do recipe apps make money?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363771 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "0                          What do Croats think of Turks?   \n",
       "1       How will a Trump presidency affect the student...   \n",
       "2              What are the best startups ideas in India?   \n",
       "3       How can I add Instagram stories from Gallery o...   \n",
       "4            By what age should I have had my first kiss?   \n",
       "...                                                   ...   \n",
       "363766  What is the best way to ask a girl out on a date?   \n",
       "363767           Is time travel possible in next 5 years?   \n",
       "363768  I am looking for website promotion. How can I ...   \n",
       "363769  What are the good books which will help to kno...   \n",
       "363770  Food and Recipe Websites and Apps: What is an ...   \n",
       "\n",
       "                                                question2  \n",
       "0                          What do Turks think of Croats?  \n",
       "1       How will Trump’s presidency affect internation...  \n",
       "2       What are some of the best startups ideas for I...  \n",
       "3       How do you upload pictures from your PC to you...  \n",
       "4                            How do I have my first kiss?  \n",
       "...                                                   ...  \n",
       "363766                    How should I ask this girl out?  \n",
       "363767  Is it possible to travel back or forward in time?  \n",
       "363768       How do I find the best SEO company in Delhi?  \n",
       "363769  What are some good books to learn more about S...  \n",
       "363770                     How do recipe apps make money?  \n",
       "\n",
       "[363771 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How will a Trump presidency affect the students presently in US or planning to study in US?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['question1'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bapan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vocabulary is:  129822\n"
     ]
    }
   ],
   "source": [
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1\n",
    "\n",
    "Q1_train, Q2_train = [], []\n",
    "for i in range(len(X_train)):\n",
    "    \n",
    "    v = nltk.word_tokenize(X_train['question1'][i])\n",
    "    w = nltk.word_tokenize(X_train['question2'][i])\n",
    "    q = v + w\n",
    "    Q1_train.append(v)\n",
    "    Q2_train.append(w)\n",
    "  \n",
    "    for word in q:\n",
    "        \n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab) + 1\n",
    "print('The length of the vocabulary is: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'will', 'a', 'Trump', 'presidency', 'affect', 'the', 'students', 'presently', 'in', 'US', 'or', 'planning', 'to', 'study', 'in', 'US', '?'] ['How', 'will', 'Trump', '’', 's', 'presidency', 'affect', 'international', 'students', 'in', 'the', 'US', '?']\n"
     ]
    }
   ],
   "source": [
    "print(Q1_train[1], Q2_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9484\n",
      "20084\n",
      "899\n"
     ]
    }
   ],
   "source": [
    "print(vocab['<PAD>'])\n",
    "print(vocab['Astrology'])\n",
    "print(vocab['Astronomy'])\n",
    "print(vocab['Bangalore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_valid, Q2_valid = [], []\n",
    "for i in range(len(X_valid)):\n",
    "    \n",
    "    Q1_valid.append(nltk.word_tokenize(X_valid['question1'][i]))\n",
    "    Q2_valid.append(nltk.word_tokenize(X_valid['question2'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20218, 20218)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q1_valid), len(Q2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Are', 'there', 'actually', 'any', 'legit', 'work', 'at', 'home', 'jobs', '?']\n"
     ]
    }
   ],
   "source": [
    "print(Q1_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_test, Q2_test = [], []\n",
    "for i in range(len(X_test)):\n",
    "    \n",
    "    Q1_test.append(nltk.word_tokenize(X_test['question1'][i]))\n",
    "    Q2_test.append(nltk.word_tokenize(X_test['question2'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20359, 20359)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q1_test), len(Q2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting questions to array of integers\n",
    "for i in range(len(Q1_train)):\n",
    "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n",
    "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n",
    "    \n",
    "for i in range(len(Q1_valid)):\n",
    "    Q1_valid[i] = [vocab[word] for word in Q1_valid[i]]\n",
    "    Q2_valid[i] = [vocab[word] for word in Q2_valid[i]]\n",
    "\n",
    "        \n",
    "for i in range(len(Q1_test)):\n",
    "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n",
    "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = Q1_train[0:4], Q2_train[0:4], y_train[0:4].values\n",
    "# v1 = shuffle(v)\n",
    "# v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 5, 6, 7, 8],\n",
       " [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 18, 19, 8],\n",
       " [2, 27, 15, 28, 29, 30, 18, 31, 8],\n",
       " [9, 34, 35, 36, 37, 38, 39, 40, 20, 41, 42, 8]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_train[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "maxlen = -10000\n",
    "for arr in Q1_train:\n",
    "    if len(arr) > maxlen:\n",
    "        maxlen = len(arr)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "maxlen = -10000\n",
    "for arr in Q2_train:\n",
    "    if len(arr) > maxlen or len(arr) > 270:\n",
    "        maxlen = len(arr)\n",
    "        c = c+1\n",
    "print(maxlen)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def data_generator(Q1, Q2, label, batch_size = 32, pad = vocab['<PAD>']):\n",
    "    \n",
    "    num_samples = len(Q1)\n",
    "    max_len = 272\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            samples_Q1 = Q1[offset : offset + batch_size]\n",
    "            samples_Q2 = Q2[offset : offset + batch_size]\n",
    "            samples_label = label[offset : offset + batch_size]\n",
    "            \n",
    "            Q1_batch, Q2_batch = [], []\n",
    "            \n",
    "            for q1, q2 in zip(samples_Q1, samples_Q2):\n",
    "                \n",
    "                q1 = q1 + [pad] * (max_len - len(q1))\n",
    "                q2 = q2 + [pad] * (max_len - len(q2)) \n",
    "                \n",
    "                Q1_batch.append(q1)\n",
    "                Q2_batch.append(q2)\n",
    "            \n",
    "            Q1_batch = np.array(Q1_batch).astype(np.float32)\n",
    "            Q2_batch = np.array(Q2_batch).astype(np.float32)\n",
    "            \n",
    "            X_batch = Q1_batch, Q2_batch\n",
    "            y_batch = samples_label.values.astype(np.float32)\n",
    "            \n",
    "            yield X_batch, y_batch\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2,  3,  4, ...,  1,  1,  1],\n",
       "        [ 9, 10, 11, ...,  1,  1,  1],\n",
       "        [ 2, 27, 15, ...,  1,  1,  1],\n",
       "        [ 9, 34, 35, ...,  1,  1,  1]]),\n",
       " array([[ 2,  3,  7, ...,  1,  1,  1],\n",
       "        [ 9, 10, 12, ...,  1,  1,  1],\n",
       "        [ 2, 27, 32, ...,  1,  1,  1],\n",
       "        [ 9,  3, 43, ...,  1,  1,  1]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Embedding, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "vocab_size = len(vocab)\n",
    "maxlen = 272\n",
    "def initialize_base_network():\n",
    "    input = Input(shape=(maxlen, ))\n",
    "    x = Embedding(vocab_size, embed_dim,\n",
    "                  input_length = maxlen)(input)\n",
    "    \n",
    "    x = LSTM(128)(x)\n",
    "    return Model(inputs=input, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 272)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 272, 256)          35045120  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               197120    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,242,240\n",
      "Trainable params: 35,242,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_network = initialize_base_network()\n",
    "base_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the left input and point to the base network\n",
    "input_a = Input(shape=(maxlen,), name=\"left_input\")\n",
    "vect_output_a = base_network(input_a)\n",
    "\n",
    "# create the right input and point to the base network\n",
    "input_b = Input(shape=(maxlen,), name=\"right_input\")\n",
    "vect_output_b = base_network(input_b)\n",
    "\n",
    "# measure the similarity of the two vector outputs\n",
    "output = Lambda(euclidean_distance, name=\"output_layer\", output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = Model([input_a, input_b], output)\n",
    "\n",
    "# # plot model graph\n",
    "# plot_model(model, show_shapes=True, show_layer_names=True, to_file='outer-model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " left_input (InputLayer)        [(None, 272)]        0           []                               \n",
      "                                                                                                  \n",
      " right_input (InputLayer)       [(None, 272)]        0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 128)          35242240    ['left_input[0][0]',             \n",
      "                                                                  'right_input[0][0]']            \n",
      "                                                                                                  \n",
      " output_layer (Lambda)          (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,242,240\n",
      "Trainable params: 35,242,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        '''Contrastive loss from Hadsell-et-al.'06\n",
    "        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "        '''\n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return (y_true * square_pred + (1 - y_true) * margin_square)\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, y_train_ = next(data_generator(Q1_train, Q2_train, y_train, batch_size=64, pad=vocab['<PAD>']))\n",
    "X_valid_, y_valid_ = next(data_generator(Q1_valid, Q2_valid, y_valid, batch_size=64, pad=vocab['<PAD>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(Q1_train, Q2_train, y_train, batch_size=64, pad=vocab['<PAD>']):\n",
    "                    \n",
    "    return data_generator(Q1_train, Q2_train, y_train, batch_size=64, pad=vocab['<PAD>'])\n",
    "\n",
    "# Create the validation data generator\n",
    "def val_generator(Q1_valid, Q2_valid, y_valid, batch_size=64, pad=vocab['<PAD>']):\n",
    "                    \n",
    "    return data_generator(Q1_valid, Q2_valid, y_valid, batch_size=64, pad=vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = Adam(learning_rate = 0.001)\n",
    "model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer=adm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-4d3f16872e81>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-4d3f16872e81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# batch_size = 64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<PAD>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ1_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2207\u001b[0m         \u001b[1;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m         stacklevel=2)\n\u001b[1;32m-> 2209\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   2210\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# batch_size = 64\n",
    "model.fit_generator(\n",
    "        train_generator(Q1_train, Q2_train, y_train, batch_size=64, pad=vocab['<PAD>']),\n",
    "        steps_per_epoch = len(Q1_train) // batch_size,\n",
    "        epochs=1,\n",
    "        validation_data = val_generator(Q1_valid, Q2_valid, y_valid, batch_size=64, pad=vocab['<PAD>']),\n",
    "        validation_steps=len(Q1_valid) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1_train = np.array(Q1_train)\n",
    "# Q1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_train = 300000\n",
    "# N_test  = 10*1024\n",
    "# data_train = data[:N_train]\n",
    "# data_test  = data[N_train:N_train+N_test]\n",
    "# print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
    "# del(data) # remove to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td_index = (data_train['is_duplicate'] == 1).to_numpy()\n",
    "# td_index = [i for i, x in enumerate(td_index) if x] \n",
    "# print('number of duplicate questions: ', len(td_index))\n",
    "# print('indexes of first ten duplicate questions:', td_index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_train['question1'][5])  #  Example of question duplicates (first one in data)\n",
    "# print(data_train['question2'][5])\n",
    "# print('is_duplicate: ', data_train['is_duplicate'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1_train_words = np.array(data_train['question1'][td_index])\n",
    "# Q2_train_words = np.array(data_train['question2'][td_index])\n",
    "# y_train = np.array(data_train['is_duplicate'])\n",
    "# Q1_test_words = np.array(data_test['question1'])\n",
    "# Q2_test_words = np.array(data_test['question2'])\n",
    "# y_test  = np.array(data_test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('TRAINING QUESTIONS:\\n')\n",
    "# print('Question 1: ', Q1_train_words[0])\n",
    "# print('Question 2: ', Q2_train_words[0], '\\n')\n",
    "# print('Question 1: ', Q1_train_words[5])\n",
    "# print('Question 2: ', Q2_train_words[5], '\\n')\n",
    "# print('is_duplicate =', y_train[5], '\\n')\n",
    "# print('TESTING QUESTIONS:\\n')\n",
    "# print('Question 1: ', Q1_test_words[0])\n",
    "# print('Question 2: ', Q2_test_words[0], '\\n')\n",
    "# print('is_duplicate =', y_test[0], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1_train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2_train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Q1_train_words[0])\n",
    "# print(Q2_train_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Q1_train[0])\n",
    "# print(Q2_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Train set has reduced to: ', len(Q1_train) ) \n",
    "# print('Test set length: ', len(Q1_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How', 'do', 'I', 'prepare', 'for', 'interviews', 'for', 'cse', '?']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first question in the train set:\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
      "\n",
      "encoded version:\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
      "\n",
      "first question in the test set:\n",
      "\n",
      "How do I prepare for interviews for cse? \n",
      "\n",
      "encoded version:\n",
      "[32, 38, 4, 107, 65, 1015, 65, 11509, 21]\n"
     ]
    }
   ],
   "source": [
    "print('first question in the train set:\\n')\n",
    "print(Q1_train_words[0], '\\n') \n",
    "print('encoded version:')\n",
    "print(Q1_train[0],'\\n')\n",
    "\n",
    "print('first question in the test set:\\n')\n",
    "print(Q1_test_words[0], '\\n')\n",
    "print('encoded version:')\n",
    "print(Q1_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 38, 4, 107, 65, 1015, 65, 11509, 21], [30, 156, 78, 216, 8908, 39, 716, 286, 8317, 21], [32, 38, 4, 521, 1340, 735, 0, 65, 47, 1476, 1341, 735, 21], [161, 31, 1597, 302, 21]]\n",
      "[[30, 156, 78, 216, 375, 39, 107, 65, 11509, 21], [283, 156, 78, 216, 6085, 28, 28, 31082, 39, 716, 28, 288, 8317, 21], [32, 38, 4, 521, 1341, 735, 31317, 65, 47, 1476, 1341, 735, 21], [18505, 3, 161, 31, 1597, 302, 21]]\n"
     ]
    }
   ],
   "source": [
    "print(Q1_test[0:4])\n",
    "print(Q2_test[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "The length of the training set is:   89188\n",
      "The length of the validation set is:  22298\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "cut_off = int(len(Q1_train)*0.8)\n",
    "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
    "val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n",
    "print('Number of duplicate questions: ', len(Q1_train))\n",
    "print(\"The length of the training set is:  \", len(train_Q1))\n",
    "print(\"The length of the validation set is: \", len(val_Q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
    "    \"\"\"Generator function that yields batches of data\n",
    "\n",
    "    Args:\n",
    "        Q1 (list): List of transformed (to tensor) questions.\n",
    "        Q2 (list): List of transformed (to tensor) questions.\n",
    "        batch_size (int): Number of elements per batch.\n",
    "        pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
    "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
    "    Yields:\n",
    "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
    "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
    "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
    "    \"\"\"\n",
    "\n",
    "    input1 = []\n",
    "    input2 = []\n",
    "    idx = 0\n",
    "    len_q = len(Q1)\n",
    "    question_indexes = [*range(len_q)]\n",
    "    \n",
    "    if shuffle:\n",
    "        rnd.shuffle(question_indexes)\n",
    "    \n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    while True:\n",
    "        if idx >= len_q:\n",
    "            # if idx is greater than or equal to len_q, set idx accordingly \n",
    "            # (Hint: look at the instructions above)\n",
    "            idx = len_q - 1\n",
    "            # shuffle to get random batches if shuffle is set to True\n",
    "            if shuffle:\n",
    "                rnd.shuffle(question_indexes) \n",
    "        \n",
    "        # get questions at the `question_indexes[idx]` position in Q1 and Q2\n",
    "        q1 = Q1[question_indexes[idx]]\n",
    "        q2 = Q2[question_indexes[idx]]\n",
    "        \n",
    "        # increment idx by 1\n",
    "        idx += 1\n",
    "        # append q1\n",
    "        input1.append(q1)\n",
    "        # append q2\n",
    "        input2.append(q2)\n",
    "        if len(input1) == batch_size:\n",
    "            # determine max_len as the longest question in input1 & input 2\n",
    "            # Hint: use the `max` function. \n",
    "            # take max of input1 & input2 and then max out of the two of them.\n",
    "            max_len =  max(max([len(q) for q in input1]),max([len(q) for q in input2]))\n",
    "            # pad to power-of-2 (Hint: look at the instructions above)\n",
    "            max_len = 2**int(np.ceil(np.log2(max_len)))\n",
    "            b1 = [] \n",
    "            b2 = [] \n",
    "            for q1, q2 in zip(input1, input2):\n",
    "                # add [pad] to q1 until it reaches max_len\n",
    "                q1 = q1 + [pad] * (max_len - len(q1))\n",
    "                # add [pad] to q2 until it reaches max_len\n",
    "                q2 = q2 + [pad] * (max_len - len(q2))               \n",
    "                # append q1\n",
    "                b1.append(q1)\n",
    "                # append q2\n",
    "                b2.append(q2)\n",
    "            # use b1 and b2\n",
    "            yield np.array(b1), np.array(b2)\n",
    "\n",
    "            input1, input2 = [], [] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch1 :  \n",
      " [[  219  6801   922  6799    21     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [   32    16   111   521  4658    21     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [  244   156   134   135    39    34  2584   131    78  2282  2283    72\n",
      "   1675  8671    25   614    21     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [  219     6   704  1317   363  1315    65     6  4579    81   386  9551\n",
      "     28   547 14563    21     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]] \n",
      "\n",
      "Batch2 :  \n",
      " [[  219  6801   922 17843    21    86    81   176   363    21     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [   32    16   111   521  4658    28  3616   764    21     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [  244    76    34  1677   131    78  8145  8146    21     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [  149   224  1958    65     6   704  1317    39   447   386  9551    28\n",
      "  14563    21     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n",
    "print(\"Batch1 : \",'\\n', res1, '\\n')\n",
    "print(\"Batch2 : \",'\\n', res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_network = initialize_base_network()\n",
    "# plot_model(base_network, show_shapes=True, show_layer_names=True, to_file='base-model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
